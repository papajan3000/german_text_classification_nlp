{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 5 - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Kapitelübersicht <a class=\"anchor\" id=\"5-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Evaluation eines Klassifizierungsverfahren ist notwendig, um es bewerten und mit anderen Klassifizierungsverfahren vergleichen zu können. TODO\n",
    "\n",
    "<b>Abschnittsübersicht</b><br>\n",
    "\n",
    "[5.1. Kapitelübersicht](#5-1)<br>\n",
    "[5.2. ...](#5-2)<br>\n",
    "[5.3. ...](#5-3)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Trainings- und Testdatensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO?: WIEDERHOLUNG: wie funktioniert machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei den meisten Evaluationstechniken wird eine Bewertung für ein Textklassifikation berechnet, indem der Datensatz in einen <b>Trainings- und Testdatensatz</b> (auch Evaluationsdatensatz genannt) unterteilt wird. Das Klassifikationsverfahren wird dabei wie gewohnt auf den Trainingsdatensatz angewendet. Beim Testdatensatz werden die <i>Labels</i> (deutsch: Beschriftungen; im unseren Fall die Wikipediakategorien) entfernt und das Klassifikationsmodell muss diese Labels generieren. Die generierten Labels werden dann mit den tatsächlichen Labels des Testdatensatzes verglichen. Basierend darauf wird ein <b>score</b> (deutsch: Punktzahl) berechnet, der angibt, wie gut ein erlerntes Klassifikationsmodell neue Daten klassifizieren kann.<br>\n",
    "Der Testdatensatz muss dabei das gleiche Format wie der Trainingsdatensatz haben. Inhaltlich muss sich der Testdatensatz jedoch von dem Trainingsdatensatz unterscheiden, d.h. es sollen keine Teildatensätze im Testdatensatz wiederverwendet werden. Im schlimmsten Fall würden wir den Trainingsdatensatz einfach als Testdatensatz wiederverwenden und das Klassifikationsmodell würde sich einfach die Datensätze \"merken\". Der zentrale und wichtige Schritt der Verallgemeinerung entfällt. Dies würde zu einem sehr guten <b>score</b> führen, der jedoch verfälscht ist. Bei der Voraussage von neuen Datensätze würde unser Klassifikationsmodell dann vermutlich sehr schlechte Voraussagen treffen, obwohl der score sehr gut war."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden des Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>length</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3470</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>1050</td>\n",
       "      <td>All the Best ! ( englisch Alles Gute ! ) ist d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3611</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>525</td>\n",
       "      <td>Let It Roll : Songs by George Harrison ist das...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3612</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>251</td>\n",
       "      <td>Lieder wie Orkane ist das dritte offizielle Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3613</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>756</td>\n",
       "      <td>Long Stick Goes Boom : The Anthology ist eine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3614</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>260</td>\n",
       "      <td>Los Grandes Éxitos en Español ( spanisch für D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        category  length  \\\n",
       "0  3470  Album nach Typ    1050   \n",
       "1  3611  Album nach Typ     525   \n",
       "2  3612  Album nach Typ     251   \n",
       "3  3613  Album nach Typ     756   \n",
       "4  3614  Album nach Typ     260   \n",
       "\n",
       "                                                text  \n",
       "0  All the Best ! ( englisch Alles Gute ! ) ist d...  \n",
       "1  Let It Roll : Songs by George Harrison ist das...  \n",
       "2  Lieder wie Orkane ist das dritte offizielle Be...  \n",
       "3  Long Stick Goes Boom : The Anthology ist eine ...  \n",
       "4  Los Grandes Éxitos en Español ( spanisch für D...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\", index_col=0)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teilung in Trainings- und Testdatensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt kodieren und vektorisieren wir unsere Labels und unsere Textdaten. Hierbei wurde der Code dafür etwas abgekürzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "labels = LabelEncoder().fit_transform(corpus[\"category\"])\n",
    "vector = TfidfVectorizer().fit_transform(corpus[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun schauen wir uns die Dimensionen der Matrix unseres vektorisierten Textes an. `shape` gibt uns die Dimensionen der Matrix als Tupel `(n,m)` zurück. `n` steht für die Zeilen der Matrix, `m` für die Spalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 281396)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wollen wir diese Daten teilen. Da eine Zeile für einen Wikipediaartikel steht, müssen wir uns an der ersten Zahl im Tupel orientieren. Das Verhältnis, wie wir die Daten teilen, soll hier 80% Trainingsdaten und 20% Testdaten sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exkurs:</b> Verhältnis von Trainings- und Testdaten\n",
    "    \n",
    "- 80/20: https://de.wikipedia.org/wiki/Paretoprinzip\n",
    "- allgemein: https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio\n",
    "- variance: https://machinelearningmastery.com/how-to-reduce-model-variance/\n",
    "- bias/variance: https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: HIER WEITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train = \n",
    "#y_train = \n",
    "#X_test =\n",
    "#y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "labels = LabelEncoder().fit_transform(corpus[\"category\"])\n",
    "vector  = TfidfVectorizer().fit_transform(corpus[\"text\"])\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "classifier = MultinomialNB()\n",
    "mnb = classifier.fit(vector, labels)\n",
    "\n",
    "# Unser Testsatz\n",
    "vector2 = vectorizer.transform([\"Ein sehr knappes Spiel\"])\n",
    "\n",
    "# Die Voraussage\n",
    "prediction = mnb.predict(vector2)\n",
    "#print(prediction)\n",
    "original_predicted_category = encoder.inverse_transform(prediction)\n",
    "print(str(original_predicted_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orientieren an: https://monkeylearn.com/text-classification/ (metrics and evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnb.score(vector, labels) #nächstes kapitel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vllt. hilfreich?:\n",
    "\n",
    "- vorteil one hot encoding: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "https://stackabuse.com/text-classification-with-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
