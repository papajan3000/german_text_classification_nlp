{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusatzkapitel 2 - Neuronale Netze mit PyTorchText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.1. Kapitelübersicht <a class=\"anchor\" id=\"Z-2-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Kapitel zeige ich, wie man einfache Neuronale Netze mit der Deep-Learning-Bibliothek **PyTorch** und **TorchText** erstellt. Dieses Kapitel baut auf den Kapiteln 10 bis 13 auf, d.h. das Konzept von Neuronalen Netzen, gängige Deep Learning Begriffe und erste Praxiserfahrungen sollten bekannt sein. Weiterhin sollte das Konzept der objektorientierten Programmierung in Python geläufig sein, da PyTorch eine Klassenarchitektur zur Erstellung von Modellen benutzt sowie die Benutzung von Iteratoren in Python. Auch wird die Benutzung einer GPU wie bei Kapitel 12 dringend empfohlen (auch hier kann wieder **Google Colab** benutzt werden).\n",
    "\n",
    "**Hinweis**: Das PyTorch-Modul befindet sich <u>nicht</u> in der bei dieser Tutorialreihe beigelegten `requirements.txt` Datei. Es muss eigenständig installiert werden, was jedoch im Gegensatz zu Keras oder Tensorflow weitaus unkomplizierter ist. Die Webseite von <a href=\"https://pytorch.org/\">PyTorch</a> ist hier sehr hilfreich. <a href=\"https://github.com/pytorch/text\">TorchText</a> muss ebenfalls noch installiert werden.\n",
    "\n",
    "<b>Abschnittsübersicht</b>:<br>\n",
    "[Z.2.1. Kapitelübersicht](#Z-2-1)<br>\n",
    "[Z.2.2. Übersicht zu PyTorch](#Z-2-2)<br>\n",
    "[Z.2.3. Implementierung in PyTorch](#Z-2-3)<br>\n",
    "[Z.2.3.1. Aufteilung des Korpus](#Z-2-3-1)<br>\n",
    "[Z.2.3.2. Laden der JSON-Dateien](#Z-2-3-2)<br>\n",
    "[Z.2.3.3. Erstellung eines sequentiellen Modells](#Z-2-3-3)<br>\n",
    "[Z.2.3.4. Training eines sequentiellen Modells](#Z-2-3-4)<br>\n",
    "\n",
    "Am Ende dieses Kapitel werden wir folgende Themen behandelt und/oder vertieft haben:\n",
    "- Implementierung eines Neuronalen Netz mit PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.2. Übersicht zu PyTorch <a class=\"anchor\" id=\"Z-2-2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie auch **Keras** ist **PyTorch** eine Deep-Learning-Bibliothek, anders als Keras jedoch basiert PyTorch nicht auf der Bibliothek **Tensorflow**, sondern auf der Bibliothek **Torch**. PyTorch erfordert zudem eine stärkere Auseinandersetzung mit den Mechaniken von Deep Learning, weshalb auch mehr Code als bei Keras benötigt wird, in welchem meist mit nur wenigen Zeilen Code ein Neuronales Netz erstellt werden konnte. Im akademischen Bereich wird PyTorch aktuell (Stand März 2020) jedoch viel häufiger als Keras verwendet, da es eine bessere Performance und die Erstellung von komplexeren Neuronalen Netzwerkarchitekturen ermöglicht. Keras selbst wird anders als Tensorflow oder PyTorch aufgrund seiner Simplizität meistens nur zur Erstellung von Prototypen genutzt, abseits von Tutorials ist es deshalb seltener zu finden. Sollte man mit Textdaten arbeiten, empfiehlt es sich, neben PyTorch noch die ebenfalls von PyTorch bereitgestelle Bibliothek **TorchText** zu verwenden. Diese vereinfacht typische Vorverarbeitungsschritte für die Arbeit mit Textdaten ungemein. \n",
    "\n",
    "TODO:<br>\n",
    "- grund dinge wie torch modul & ähnliches erklären\n",
    "- tabelle unten überpfüen und ggbf ergänzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch vs. Keras\n",
    "\n",
    "\n",
    " <table align=\"left\"> \n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th style=\"text-align:center;\">Keras</th>\n",
    "    <th style=\"text-align:center;\">PyTorch</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td><b>Vorteile</b></td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Einsteigerfreundlich</li>\n",
    "          <li>Simple Architektur</li>\n",
    "          <li>Einfache Erstellung von Prototypen</li>\n",
    "          <li>Gut für kleine Datensätze</li>\n",
    "          <li>wenige Zeilen Code</li>\n",
    "          <li>Debugging kaum notwendig</li>\n",
    "        </ul> \n",
    "    </td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Sehr flexibel</li>\n",
    "            <li>Höhere Perfomance</li>\n",
    "            <li>Ermöglicht komplexere Neuronale Netzwerke</li>\n",
    "            <li>Nutzt Python-Syntax</li>\n",
    "            <li>Eignet sich gut fürs Debugging</li>\n",
    "            <li>Gute Peformance auch für größere Datensätze</li>\n",
    "            <li>Großer Community-Support</li>\n",
    "            <li>Forschung nutzt vorrangig PyTorch, d.h. Paper nutzen PyTorch-Architektur</li>\n",
    "        </ul>   \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nachteile</b></td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Langsamer als PyTorch</li>\n",
    "          <li>Benutzung der eigenen GPU kann umständlich werden</li>\n",
    "            <li><i>Subjektiv:</i> Abgewandelte Python-Syntax</li>\n",
    "            <li>Weniger Community-Support</li>\n",
    "        </ul> \n",
    "    </td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Weniger einsteigerfreundlich als Keras</li>\n",
    "          <li>Braucht viel mehr Code</li>\n",
    "        </ul>    \n",
    "    </td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.3. Implementierung in PyTorch <a class=\"anchor\" id=\"Z-2-3\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "punctuation = ['!', '#','$','%','&', \"'\", '(',')','*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', \n",
    "               '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '`', '``', 'wurde', 'wurden']\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2.3.1. Aufteilung des Korpus <a class=\"anchor\" id=\"Z-2-3-1\"/>\n",
    "\n",
    "Das Einlesen des Korpus und die Aufteilung des Korpus unterscheidet sich von dem Vorgehen in den anderen Kapiteln. Viele Klassen und Methoden von PyTorch und TorchText erwarten verschiedene Dateien für den Trainings-, Test- und Validierungsdatensatz. Mithilfe der uns bereits bekannten `train_test_split`-Funktion von Scikit-learn können wir diese Dateien erstellen, da die Funktion als Eingabe neben numpy-Matrizen auch DataFrames erlaubt. Bis jetzt hatten wir den Datei-Typ **csv** verwendet. Dieser ist jedoch für die Nutzung mit TorchText problematisch, die JSON Variante <a href=\"http://jsonlines.org/\">JSON Lines</a> eignet sich hier besser.[<sup>1</sup>](#fn1) Beim **JSON Line** Format ist jede Zeile ein valider JSON Wert. Die gesplitteten Datensätze des Wikipedia-Korpus wandeln wir mit einer selbstgeschriebenen Funktion `df_to_jsonl` in das JSON Line Format um. Zuvor wurden für dieses Tutorial die Spalten \"id\" und \"length\" aus dem Korpus entfernt.\n",
    "\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<span id=\"fn1\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">1</sup> &nbsp; \n",
    "Unter anderem liegt das daran, dass csv-Dateien mit Kommas (oder Semikolons) voneinander getrennt werden und TorchText Probleme hat, diese Trennungskommas von Kommas in der \"Text\"-Spalte zu unterschieden. Für weitere Erklärungen zum Vorteil von JSON-Dateien gegenüber csv-Dateien siehe dieses <a href=\"https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/A%20-%20Using%20TorchText%20with%20Your%20Own%20Datasets.ipynb\">TorchText-Tutorial</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\", index_col = 0)\n",
    "corpus = corpus.drop(\"id\", axis=1)\n",
    "corpus = corpus.drop(\"length\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>All the Best ! ( englisch Alles Gute ! ) ist d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>Let It Roll : Songs by George Harrison ist das...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>Lieder wie Orkane ist das dritte offizielle Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>Long Stick Goes Boom : The Anthology ist eine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>Los Grandes Éxitos en Español ( spanisch für D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                               text\n",
       "0  Album nach Typ  All the Best ! ( englisch Alles Gute ! ) ist d...\n",
       "1  Album nach Typ  Let It Roll : Songs by George Harrison ist das...\n",
       "2  Album nach Typ  Lieder wie Orkane ist das dritte offizielle Be...\n",
       "3  Album nach Typ  Long Stick Goes Boom : The Anthology ist eine ...\n",
       "4  Album nach Typ  Los Grandes Éxitos en Español ( spanisch für D..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c898e509b3c3>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.apply(lambda row: word_tokenize(row[column]), axis=1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_remain = train_test_split(corpus, \n",
    "                                     test_size=0.4, \n",
    "                                     train_size=0.6,\n",
    "                                     random_state=42,\n",
    "                                     stratify=corpus[\"category\"])\n",
    "X_val = X_remain[:1200]\n",
    "X_test = X_remain[1200:]\n",
    "\n",
    "\n",
    "def df_to_jsonl(df, filename, column=\"text\", path=\"tutorialdata/pytorch_data/\"):\n",
    "    \"\"\" DataFrame with text column to Json Line Format. \"\"\"\n",
    "\n",
    "    df[column] = df.apply(lambda row: word_tokenize(row[column]), axis=1)\n",
    "    df.to_json(f\"{path}{filename}.json\", orient='records', lines=True)\n",
    "    \n",
    "    \n",
    "df_to_jsonl(X_train, \"train\")\n",
    "df_to_jsonl(X_val, \"val\")\n",
    "df_to_jsonl(X_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2.3.2. Laden der JSON-Dateien <a class=\"anchor\" id=\"Z-2-3-2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eines der Hauptkonzepte von TorchText ist das sogenannte **`Field`**. Dadurch wird definiert, wie Daten verarbeitet werden sollen. So kann z.B. angegeben werden, ob Texte in diesem `Field` tokenisiert werden sollen und nur kleingeschrieben verarbeitet werden sollen. Im `Field` TEXT wurde als Tokenizer *toktok* angegeben, eine Tokenizer der NLP-Bibliothek **NLTK** (andere mögliche Werte finden sich <a href=\"https://pytorch.org/text/_modules/torchtext/data/utils.html\">hier</a>). In unserem Fall ändert sich durch die Angabe des Tokenizers nichts an den Texten der Datensatz-Dateien, da diese bereits vorher wegen der Konvertierung ins JSON Lines Format tokenisiert wurden.[<sup>2</sup>](#fn2) Weiterhin haben wir alle Wörter mit dem Argument `lower` in Kleinbuchstaben konvertiert.[<sup>3</sup>](#fn3) Auch Stoppwörter sowie viele Satzzeichen wurden ignoriert.<br>\n",
    "Neben der Übergabe von Argumenten gibt es von `Field` noch verschiedene Varianten. Für die Spalte mit den Klassen verwenden wir beispielsweise die Variante `LabelField`. Im Grunde unterscheidet diese sich nicht groß von `Field`, jedoch sind die Argumente `sequential` und `unk_token` automatisch auf `None` gesetzt. Dies macht Sinn, da es sich bei unseren Labeln nicht um sequentielle Daten (*hier*: keine ganzen Texte) handelt und es auch nicht zu einem Out-of-Vocabulary (OOV) Fehler kommen kann. Anders ist dies jedoch bei unserem TEXT-`Field`. Weiter unten geben wir die maximale Größe unseres Vokabulars an, d.h. wir begrenzen die von unserem Modell zu verarbeitenden Wörter auf die 25.000 häufigsten Wörter. Geben wir jedoch die tatsächliche Größe unseres Vokabulars aus, nachdem wir es mit `build_vocab` erstellt haben, erhalten wir den Wert 25.002. Dies liegt daran, dass noch die zwei zusätzlichen Vokabeln `<unk>` und `<pad>` hinzugefügt. Da wir nur das Vokabular unseres Trainingsdatensatzes kennen, kann es sein, dass es im Validierungs- oder Testdatensatz Wörter gibt, die nicht in unserem Vokabular vorkommen. Um nicht den OOV-Fehler zu erhalten, wird von PyTorch die Vokabel `<unk>` verwendet (= unknown). Der `<pad>`-Token (= padding) wird zum \"Auffüllen\" von Batches verwendet.[<sup>4</sup>](#fn4) <br>\n",
    "\n",
    "Mit der Funktion `data.TabularDataset.splits` rufen wir die verschiedenen JSON-Dateien als Tabellen-Datensatz auf. Dem Argument `fields` übergeben wir ein Dictionary `assigned_fields`, in welchen wir unseren erstellten `Fields` TEXT und CATEGORIES die entsprechenden zugehörigen Spalten unserer Datensätze zuordnen. In der späteren Trainingsschleife können wir uns das zu Nutze machen und z.B. über `batch.category` auf die Kategorien zugreifen. Mit dem `skip_header = True` geben wir an, dass die Spaltenbezeichnungen ignoriert werden.\n",
    "\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<span id=\"fn2\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">2</sup> &nbsp; Texte sollten im besten Fall vorher tokenisiert werden, da ansonsten TorchText jedes Mal, wenn die Datensätze geladen werden, diese neu tokenisiert. Dies kann bei großen Datensätzen sehr viel Zeit kosten.<br>\n",
    "<span id=\"fn3\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">3</sup> &nbsp; Dies ist für die deutsche Sprache nicht immer sinnvoll, wurde hier jedoch verwendet, um eine diverseres Vokabular zu erhalten.<br>\n",
    "<span id=\"fn4\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">4</sup> &nbsp; Die GPU (oder CPU) verarbeitet die Trainingsdaten beim Training des Neuronalen Netzes in <b>batches</b> (= Stapel), die alle eine gewisse Länge haben. Ist ein Batch zu klein, wird er mit Padding-Tokens aufgefüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('german') + punctuation \n",
    "\n",
    "TEXT = data.Field(tokenize = \"toktok\",\n",
    "                  lower = True,\n",
    "                  stop_words = stop_words)\n",
    "CATEGORIES = data.LabelField()\n",
    "assigned_fields = {\"text\": ('text', TEXT), \n",
    "                   \"category\": ('category', CATEGORIES)}\n",
    "\n",
    "train_data, val_data, test_data = data.TabularDataset.splits(path='tutorialdata/pytorch_data/', \n",
    "                                                              train='train.json',\n",
    "                                                              validation='val.json', \n",
    "                                                              test='test.json', \n",
    "                                                              format='json',\n",
    "                                                              fields=assigned_fields,\n",
    "                                                              skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['satz', 'trachtenbrot', 'benannt', 'boris', 'trachtenbrot', 'satz', 'mathematischen', 'logik', '1950', 'bewiesen', 'besagt', 'endlichen', 'modellen', 'allgemeingültigen', 'sätze', 'prädikatenlogik', 'erster', 'stufe', 'rekursiv', 'aufzählbar']\n"
     ]
    }
   ],
   "source": [
    "example = vars(train_data.examples[1])\n",
    "print(example[\"text\"][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begrenzung des Vokabulars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "CATEGORIES.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einzigarte Tokens im TEXT-Vokabular: 25002\n",
      "Einzigarte Tokens im CATEGORIES-Vokabular: 30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Einzigarte Tokens im TEXT-Vokabular: {len(TEXT.vocab)}\")\n",
    "print(f\"Einzigarte Tokens im CATEGORIES-Vokabular: {len(CATEGORIES.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jedoch', 2720), ('sowie', 2706), ('jahr', 2678), ('the', 2566), ('2', 2385), ('seit', 2320), ('zwei', 2272), ('1', 2258), ('stadt', 2243), ('ab', 2203), ('jahre', 2103), ('mehr', 2056), ('etwa', 1994), ('zeit', 1963), ('of', 1826), ('ersten', 1820), ('dabei', 1712), ('jahren', 1677), ('drei', 1671), ('a', 1659)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Vokabular kann auch direkt angezeigt werden, indem wir die Funktionen `stoi` (= string to int) oder `itos` (= int to string) verwenden. Da alle unsere Daten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'jedoch', 'sowie', 'jahr', 'the', '2', 'seit', 'zwei', '1']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der letzte Schritt bei der Vorbereitung der Daten ist die Erstellung der **Iteratoren**. Ein Datensatz-Iterator ermöglicht das einfache Laden von Daten in Neuronalen Netzwerke und hilft bei der Organisation von Stapelverarbeitung (= batching), Maskierung und Konvertierung (z.B. die Wörter durch die Indexnummer der Wörter zu ersetzen). Wir iterieren über diese Iteratoren in der Trainings-/Evaluierungsschleife und sie geben bei jeder Iteration einen Batch von Daten zurück (indiziert und in Tensoren umgewandelt). Dafür verwenden wir den sogenannten `BucketIterator`, der einen Batch von Daten zurückgibt, bei der jeder Datenpunkt eine ähnliche Länge hat. Somit wird der Gebrauch von Padding (*hier*: den `<pad>` Tokens) minimiert. Sollte eine GPU vorhanden und CUDA erfolgreich installiert worden sein, kann mithilfe von `torch.device` diese genutzt werden, indem sie `device` dem `BucketIterator` übergeben wird. Zuletzt geben wir ähnlich wie bei Keras noch die Größe der Batches an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: argumente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, val_iterator, test_iterator = data.BucketIterator.splits((train_data, val_data, test_data), \n",
    "                                                                         batch_size = BATCH_SIZE,\n",
    "                                                                         device = device,\n",
    "                                                                         sort_key = lambda x: len(x.text),\n",
    "                                                                         sort = False,\n",
    "                                                                         sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf diese Iteratoren können wir nun zugreifen. Wir erstellen hier zu Demonstrationszwecken einen Batch des `train_iterator` außerhalb der eigentlichen Schleife. Mithilfe von `batch.text` können wir uns nun unsere umgewandelten Textdaten anzeigen lassen, die indiziert wurden und in einem Tensor gespeichert wurden. Dabei wird auf das erstellte Dictionary `assigned_fields` zugegriffen, genauer auf den Namen im Tuple zum Key \"text\". Wir konnten dort einen beliebigen Namen wählen, auf den wir jetzt zugreifen. Mit `batch.category` können wir auch auf unsere Kategorien zugreifen, die ebenfalls indiziert und in Tensoren umgewandelt wurden. Das dies erfolgreich war, können wir daran erkennen, dass nur Zahlen zwischen 0 und 29 in unserem Tensor vorkommen, also 30 verschiedene Indizes. Da wir 30 verschiedene Kategorien haben, passt dies überein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  6517,  4760,  ...,    56,     0,     0],\n",
      "        [    0,  2016,  2815,  ...,   309,  2388, 15679],\n",
      "        [    0,     0,     0,  ...,   409,     0,   580],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iterator))\n",
    "print(batch.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  1, 19, 14,  9, 16, 13, 15, 11, 29, 18, 11,  3, 18, 24,  6,  8,  3,\n",
      "         4, 15,  3, 24, 21,  6,  3, 17, 17, 10, 16,  6, 18, 28, 16,  8, 19, 24,\n",
      "         2, 23, 13, 13, 26, 19, 22, 23,  5,  4,  6, 10, 10, 29, 12,  9, 18,  9,\n",
      "         0, 12,  6, 23,  9, 29, 14, 21,  1,  5], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2.3.3. Erstellung eines sequentiellen Modells <a class=\"anchor\" id=\"Z-2-3-3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anders als bei Keras stützt sich das Erstellen von Modellen auf Klassen, die wir selbst erstellen müssen. Dadurch wird die Menge an Code im Gegensatz zu Keras erhöht, dafür können wir auch viel besser unser Neuronales Netz auf unsere Bedürfnisse anpassen. Wir erhalten hier <a href=\"https://en.wikipedia.org/wiki/Boilerplate_code\">Boilerplate Code</a>. Für die Erstellung eines einfachen sequentiellen Modells in Keras brauchten wir nur folgenden Code:<br>\n",
    "\n",
    "```\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\", input_shape=(len(vocab),)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(len(np.unique(labels)), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```\n",
    "\n",
    "Für ... TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ansatz: `nn.Sequential()`\n",
    "\n",
    "Dieser erste Ansatz ähnelt sehr dem Aufbau des Keras-Modells. In der Praxis wird dieser Ansatz seltener benutzt, weshalb wir uns eher auf den nächsten Ansatz fokussieren werden. Für eine ersten Einstieg in die Modell-Architektur von PyTorch ist es aber sehr hilfreich. Ähnlich wie bei Keras definieren wir das sequentielle Modell mit `nn.Sequential`. Diesem übergeben wir eine Liste von Layern, in Keras wurden diese nach und nach hinzugefügt. Bei den Layern gibt es jedoch einige Unterschiede zu Keras. Das Äquivalent zum Dense-Layer in Keras ist in PyTorch der Linear-Layer. Die Aktivierungslayer werden anders als im oben gezeigten Keras-Code nicht innerhalb des Dense-Layer angegeben, sondern als eigenständiger Layer. Jeder Linear-Layer hat zwei Parameter: Die Dimension der Eingabedaten und die Dimension der Ausagebdaten. Im ersten Layer ist die Eingabedimension gleich der Größe unseres Text-Vokabulars, im letzten Layer ist die Ausgabedimension gleich der Anzahl unserer Kategorien. Die anderen Parameter beziehen sich auf die Dimensionen des vorherigen bzw. nächsten Layers. So muss die Eingabedimension eines Layers immer gleich der Ausgabedimension des vorherigen Layers sein. Dies wurde von Keras automatisch verwaltet, in PyTorch müssen wir dies selbst angeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25002, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=30, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "output_dim = len(CATEGORIES.vocab)\n",
    "\n",
    "layers = []\n",
    "layers.append(nn.Linear(input_dim, 64))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(64, 64))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(64, output_dim))\n",
    "layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "model_1_1 = nn.Sequential(*layers)\n",
    "print(model_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variante\n",
    "Wir können alternativ dem sequentiellen Modell auch direkt unsere Layer übergeben. In der folgenden Variante wurden zwei Dinge verändert. Zum einen wurde ein **Embedding** Layer hinzugefügt. Dieses Layer fungiert als eine Art \"Nachschlagewerk\", wobei anhand von Indizes die Vektoren nachgeschlagen werden. Zudem wandelt er Eingabedaten, die *sparse* sind, in eine **dense** Repräsentation um. Der Embedding-Layer beinhaltet einen Tensor mit der Dimension *(Größe des Vokabulars, Dimension jedes Vektor Embeddings)*. Bei der Erstellung des Layers wird der Tensor mit zufälligen Werten initialisiert. Im Verlauf des Trainings werden diese Werte ebenfalls trainiert. Das führt zu sehr schlechten anfänglichen Werten. Später in diesem Tutorial werden wir vortrainierte Word Embeddings verwenden, bei denen wir deren Gewichte übernehmen.\n",
    "\n",
    "TODO: überprüfen, ergänzen, korrigieren\n",
    "\n",
    "Neben dem Embedding Layer übergeben wir nun nicht mehr die Größe der *hidden_units* wie in der vorherigen Variante direkt, sondern speichern diese in der Variable `hidden_dim`. Die Dimension des Vektor Embeddings wird ebenfalls in einer Variable (`embedding_dim`) gespeichert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "output_dim = len(CATEGORIES.vocab)\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "\n",
    "\n",
    "model_1_2 = nn.Sequential(\n",
    "            nn.Embedding(input_dim, embedding_dim),\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ansatz: `torch.nn.Model` Klasse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der zweite Ansatz bettet den ersten Ansatz in eine Klassenstruktur ein. Diese Klassenstruktur enthält zwei notwendige Funktionen: `__init__()` und `forward()`.<br>\n",
    "\n",
    "**`__init__()`**<br>\n",
    "\n",
    "In dieser Methode definieren wir die **Layer** der Klasse. Als Argumente übergeben wir die zuvor festgelegten Dimensionsparameter. Die Layer können hier entweder einzeln definiert werden (wie wir in der nächsten Variante sehen werden) oder wir können sie wie im ersten Ansatz im sequentiellen Modell definieren. Den abschließenden Softmax-Layer geben wir jedoch einzeln an.\n",
    "\n",
    "**`forward()`**<br>\n",
    "\n",
    "Diese Methode wird automatisch aufgerufen, sobald Daten dem Modell übergeben werden. Der Aufbau ähnelt hier der funktionalen API von Keras (siehe Kapitel 7 von Chollets Buch). Die Daten werden hier dem Objektattribut `self.layers` und somit den entsprechenden Layern aus der `__init__()`-Methode übergeben. Bevor das Resultat mit dem Softmax-Layer übergeben werden, muss der ausgegeben Tensor mithilfe von Tensor-Slicing in die richtige Form gebracht werden. Hier wird aus der Tensordimension `[1462, 64, 30]` die Tensordimension `[64, 30]`. Dies ist notwendig, da im späteren Training aus einem Batch sowohl die Kategorien mit `batch.category` als auch die Textdaten mit `batch.text` aufgerufen werden. `batch.category` hat jedoch die Dimension 1, während `batch.text` die Dimension 2 hat. Die richtige Form und Dimension eines Tensors zu erhalten ist m.E. eines der zeitaufwendigsten Aufgaben bei der Erstellung von Modellen und eine der häufigsten Fehlerquellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Form von batch.category ist 'torch.Size([64])' (= 1 Dimension(en)).\n",
      "Die Form von batch.text ist 'torch.Size([1462, 64])' (= 2 Dimension(en)).\n"
     ]
    }
   ],
   "source": [
    "print(f\"Die Form von batch.category ist '{batch.category.size()}' (= {batch.category.ndim} Dimension(en)).\")\n",
    "print(f\"Die Form von batch.text ist '{batch.text.size()}' (= {batch.text.ndim} Dimension(en)).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionsparameter\n",
    "input_dim = len(TEXT.vocab)\n",
    "output_dim = len(CATEGORIES.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "\n",
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim):\n",
    "        \n",
    "        super(SequentialModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Embedding(input_dim, embedding_dim),\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x[-1,:,:]\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dem Modell können wir unsere Dimensionen übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Embedding(25002, 100)\n",
      "    (1): Linear(in_features=100, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=64, out_features=30, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "output_dim = len(CATEGORIES.vocab)\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "\n",
    "model_2_1 = SequentialModel(input_dim, \n",
    "                            embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            output_dim)\n",
    "print(model_2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variante\n",
    "Eine Variante dieses Ansatzes ist es, die verschiedenen Layer als einzelne Objektattribute in der `__init()__`-Methode zu definieren, wie wir es zuvor nur mit dem Softmax-Layer getan hatten. Ebenfalls neu ist die Verwendung des PyTorch-Moduls `torch.nn.functional`, welches hier als `F` abgekürzt ist. Damit können wir ein Layer direkt in die Aktivierungsfunktion einbetten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel2(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim):\n",
    "        \n",
    "        super(SequentialModel2, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_shape, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.output(x)\n",
    "        \n",
    "        x = x[-1,:,:]\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialModel2(\n",
      "  (embedding): Embedding(25002, 100)\n",
      "  (linear1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=30, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "output_dim = len(CATEGORIES.vocab)\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "\n",
    "model_2_2 = SequentialModel2(input_dim, \n",
    "                            embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            output_dim)\n",
    "print(model_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2.3.4. Training eines sequentiellen Modells <a class=\"anchor\" id=\"Z-2-3-4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor die eigentliche Trainingsfunktion geschrieben werden kann, muss ein Optimizer festgelegt werden. Wir nutzen hier **Adam**. Als Loss-Funktion nutzen wir den **Cross Entropy Loss**. Da dieser eine Softmax-Funktion auf die Ausgabe unseres Modells ausführt, können wir für das Training den Softmax-Layer entfernen. Mit `.to(device)` können wir die Loss-Funktion und das Modell auf eine GPU auslagern, sofern eine genutzt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionsparameter\n",
    "input_dim = len(TEXT.vocab)\n",
    "output_dim = len(CATEGORIES.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "\n",
    "model = SequentialModel2(input_dim, \n",
    "                         embedding_dim, \n",
    "                         hidden_dim, \n",
    "                         output_dim)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiterhin brauchen wir noch eine Funktion, die die Classification Accuracy berechnet. Diese müssen wir selbst definieren (diese Funktion wurde von diesem <a href=\"https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/5%20-%20Multi-class%20Sentiment%20Analysis.ipynb\">Tutorial</a> entnommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) \n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun erstellen wir die eigentliche Trainingsfunktion. Diese bekommt unser Modell mit den angegeben Dimensionsparametern, einen Iterator (*genauer*: `train_iterator`), einen Optimizer und eine Loss-Funktion übergeben. Innherhalb der Funktion aktualisiern wir nach jedem Durchlauf eines Batches den Loss- und Accuracy-Score (*hier*: `epoch_loss` und `epoch_acc`). Diese werden auch von der Trainingsfunktion zurückgegeben. Zuvor werden sie noch durch die Gesamtanzahl an Batches, die sich im Iterator befinden, geteilt. Mit `model.train()` \"sagen\" wir unserem Modell, dass es nun trainiert wird. Das Äquivalent dazu ist `model.eval()`, bei dem wir Modell sagen, dass wir nun evaluieren (siehe unten bei der Funktion `evaluate()`).\n",
    "\n",
    "\n",
    "Hauptteil der Trainingsfunktion ist der Durchlauf aller Batches des Iterators. Mit `optimizer.zero_grad()` werden die Gradienten der vorherigen Iteration auf Null gesetzt, da dies durch PyTorch nicht automatisch durchgeführt wird.[<sup>5</sup>](#fn5) Im nächsten Schritt übergeben wir die Textdaten des aktuellen Batches an unser Modell. Es wird automatisch die `forward()`-Methode aufgerufen, wir müssen dies nicht extra angeben. Die Voraussagen übergeben wir zusammen mit den Kategorien des aktuellen Batches einmal der Loss-Funktion und unserer selbstdefinierten Accuracy-Funktion, um den Loss- und Accuracy-Score zu berechnen. Mit `loss.backward()` wird der Gradient jedes Parameters berechnet und `optimizer.step()` nutzt diese Gradienten, um die Parameter zu aktualisieren. Zuletzt extrahieren wir mit `.item()` die Skalarwerte aus den `loss`- und `acc`-Tensoren.\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<span id=\"fn5\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">5</sup> &nbsp; Mehr dazu z.B. unter folgendem <a href=\"https://discuss.pytorch.org/t/why-do-we-need-to-set-the-gradients-manually-to-zero-in-pytorch/4903\">Link</a>.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        # Gradienten werden auf Null gesetzt\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Berechnung des Loss- und Accuracy-Scores anhand der predictions\n",
    "        predictions = model(batch.text)\n",
    "        loss = criterion(predictions, batch.category)\n",
    "        acc = categorical_accuracy(predictions, batch.category)\n",
    "       \n",
    "        # Gradientenberechung und -aktualisierung\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    \n",
    "    epoch_loss = epoch_loss / len(iterator)\n",
    "    epoch_acc = epoch_acc / len(iterator)\n",
    "    return epoch_loss , epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.39138546742891, 0.04448099421304569)\n"
     ]
    }
   ],
   "source": [
    "print(train(model, train_iterator, optimizer, criterion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun brauchen wir noch eine Evaluierungsfunktion, die anstatt dem Trainings-Iterator den Validierungs-Iterator übergeben bekommt. Diese Funktion ähnelt der Trainings-Funktion stark, es entfällt jedoch die Gradientenberechung und -aktualisierung. Dies geben wir mit dem Ausdruck `with torch.no_grad():` an, wodurch auch der Speicherverbrauch reduziert wird und die Berechnungen beschleunigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text)\n",
    "            loss = criterion(predictions, batch.category)\n",
    "            acc = categorical_accuracy(predictions, batch.category)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    epoch_loss = epoch_loss / len(iterator)\n",
    "    epoch_acc = epoch_acc / len(iterator)\n",
    "    return epoch_loss , epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt benötigen wir noch eine `fit()`-Methode, die unsere Trainings- und Evaluierungsfunktionen zusammenführt und diese über mehrere Epochen ausführen kann. Diese Methode ist hier sehr simpel gehalten, viele weitere Verbesserungen wie die Ausgabe der Zeit nach jeder Epoche sind möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, \n",
    "        train_iterator, \n",
    "        val_iterator, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        epochs = 1000,\n",
    "        verbose = True):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        val_loss, val_acc = evaluate(model, val_iterator, criterion)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch: {epoch+1} ')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    \n",
    "    results = {\"train_loss\": train_loss,\n",
    "              \"val_loss\": val_loss,\n",
    "              \"train_acc\": train_acc,\n",
    "              \"val_acc\": val_acc}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modell + Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel2(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim):\n",
    "        \n",
    "        super(SequentialModel2, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_shape, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.output(x)\n",
    "        \n",
    "        x = x[-1,:,:]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionsparameter\n",
    "input_dim = len(TEXT.vocab)\n",
    "output_dim = len(CATEGORIES.vocab)\n",
    "embedding_dim = 10\n",
    "hidden_dim = 64\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "model = SequentialModel2(input_dim, \n",
    "                         embedding_dim, \n",
    "                         hidden_dim, \n",
    "                         output_dim)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "results = fit(model, train_iterator, val_iterator, optimizer, criterion, epochs=EPOCHS, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': 3.38750576136405,\n",
       " 'val_loss': 3.3931306035895097,\n",
       " 'train_acc': 0.033168859649122806,\n",
       " 'val_acc': 0.043655515109237875}"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Werte sind ziemlich schlecht. Mit einer gleichen Architektur und gleichen Parametern konnte bei Keras eine Trainings-Accuracy von 100% und eine Validierungs-Accuracy von 92% erreicht werden, hier sind es gerade einmal 4%. Dies liegt wohl vorrangig am Embedding-Layer, mit dem gleichzeitig auch Embedding-Vektoren mittrainiert werden. Wir werden uns deshalb in den nächsten Abschnitten andere Architekturen sowie vortrainierte Word Embeddings anschauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: RNN, word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))\n",
    "    \n",
    "model2 = RNN(input_shape, 100, 256, output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/5%20-%20Multi-class%20Sentiment%20Analysis.ipynb\n",
    "- acc berechnen\n",
    "- train funktion erstellen\n",
    "- evaluate funktion erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO word embeddings: https://www.innoq.com/en/blog/handling-german-text-with-torchtext/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
