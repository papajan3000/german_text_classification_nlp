{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusatzkapitel 2 - Neuronale Netze mit PyTorchText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.1. Kapitelübersicht <a class=\"anchor\" id=\"Z-2-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Kapitel zeige ich, wie man einfache Neuronale Netze mit der Deep-Learning-Bibliothek **PyTorch** und **TorchText** erstellt. Dieses Kapitel baut auf den Kapiteln 10 bis 13 auf, d.h. das Konzept von Neuronalen Netzen, gängige Deep Learning Begriffe und erste Praxiserfahrungen sollten bekannt sein. Weiterhin sollte das Konzept der objektorientierten Programmierung in Python geläufig sein, da PyTorch eine Klassenarchitektur zur Erstellung von Modellen benutzt sowie die Benutzung von Iteratoren in Python. Auch wird die Benutzung einer GPU wie bei Kapitel 12 dringend empfohlen (auch hier kann wieder **Google Colab** benutzt werden).\n",
    "\n",
    "**Hinweis**: Das PyTorch-Modul befindet sich <u>nicht</u> in der bei dieser Tutorialreihe beigelegten `requirements.txt` Datei. Es muss eigenständig installiert werden, was jedoch im Gegensatz zu Keras oder Tensorflow weitaus unkomplizierter ist. Die Webseite von <a href=\"https://pytorch.org/\">PyTorch</a> ist hier sehr hilfreich. <a href=\"https://github.com/pytorch/text\">TorchText</a> muss ebenfalls noch installiert werden.\n",
    "\n",
    "<b>Abschnittsübersicht</b>:<br>\n",
    "[Z.2.1. Kapitelübersicht](#Z-2-1)<br>\n",
    "[Z.2.2. Übersicht zu PyTorch](#Z-2-2)<br>\n",
    "[Z.2.3. Implementierung in PyTorch](#Z-2-3)<br>\n",
    "[Z.2.3.1. Aufteilung des Korpus](#Z-2-3-1)<br>\n",
    "[Z.2.3.2. Laden der JSON-Dateien](#Z-2-3-2)<br>\n",
    "[Z.2.3.3. Erstellung eines sequentiellen Modells](#Z-2-3-3)<br>\n",
    "\n",
    "Am Ende dieses Kapitel werden wir folgende Themen behandelt und/oder vertieft haben:\n",
    "- Implementierung eines Neuronalen Netz mit PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.2. Übersicht zu PyTorch <a class=\"anchor\" id=\"Z-2-2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie auch **Keras** ist **PyTorch** eine Deep-Learning-Bibliothek, anders als Keras jedoch basiert PyTorch nicht auf der Bibliothek **Tensorflow**, sondern auf der Bibliothek **Torch**. PyTorch erfordert zudem eine stärkere Auseinandersetzung mit den Mechaniken von Deep Learning, weshalb auch mehr Code als bei Keras benötigt wird, in welchem meist mit nur wenigen Zeilen Code ein Neuronales Netz erstellt werden konnte. Im akademischen Bereich wird PyTorch aktuell (Stand März 2020) jedoch viel häufiger als Keras verwendet, da es eine bessere Performance und die Erstellung von komplexeren Neuronalen Netzwerkarchitekturen ermöglicht. Keras selbst wird anders als Tensorflow oder PyTorch aufgrund seiner Simplizität meistens nur zur Erstellung von Prototypen genutzt, abseits von Tutorials ist es deshalb seltener zu finden. Sollte man mit Textdaten arbeiten, empfiehlt es sich, neben PyTorch noch die ebenfalls von PyTorch bereitgestelle Bibliothek **TorchText** zu verwenden. Diese vereinfacht typische Vorverarbeitungsschritte für die Arbeit mit Textdaten ungemein. \n",
    "\n",
    "TODO:<br>\n",
    "- grund dinge wie torch modul & ähnliches erklären\n",
    "- tabelle unten überpfüen und ggbf ergänzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch vs. Keras\n",
    "\n",
    "\n",
    " <table align=\"left\"> \n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th style=\"text-align:center;\">Keras</th>\n",
    "    <th style=\"text-align:center;\">PyTorch</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td><b>Vorteile</b></td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Einsteigerfreundlich</li>\n",
    "          <li>Simple Architektur</li>\n",
    "          <li>Einfache Erstellung von Prototypen</li>\n",
    "          <li>Gut für kleine Datensätze</li>\n",
    "          <li>wenige Zeilen Code</li>\n",
    "          <li>Debugging kaum notwendig</li>\n",
    "        </ul> \n",
    "    </td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Sehr flexibel</li>\n",
    "            <li>Höhere Perfomance</li>\n",
    "            <li>Ermöglicht komplexere Neuronale Netzwerke</li>\n",
    "            <li>Nutzt Python-Syntax</li>\n",
    "            <li>Eignet sich gut fürs Debugging</li>\n",
    "            <li>Gute Peformance auch für größere Datensätze</li>\n",
    "            <li>Großer Community-Support</li>\n",
    "            <li>Forschung nutzt vorrangig PyTorch, d.h. Paper nutzen PyTorch-Architektur</li>\n",
    "        </ul>   \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nachteile</b></td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Langsamer als PyTorch</li>\n",
    "          <li>Benutzung der eigenen GPU kann umständlich werden</li>\n",
    "            <li><i>Subjektiv:</i> Abgewandelte Python-Syntax</li>\n",
    "            <li>Weniger Community-Support</li>\n",
    "        </ul> \n",
    "    </td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Weniger einsteigerfreundlich als Keras</li>\n",
    "          <li>Braucht viel mehr Code</li>\n",
    "        </ul>    \n",
    "    </td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.3. Implementierung in PyTorch <a class=\"anchor\" id=\"Z-2-3\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "punctuation = ['!', '#','$','%','&', \"'\", '(',')','*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', \n",
    "               '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '`', '``', 'wurde', 'wurden']\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2.3.1. Aufteilung des Korpus <a class=\"anchor\" id=\"Z-2-3-1\"/>\n",
    "\n",
    "Das Einlesen des Korpus und die Aufteilung des Korpus unterscheidet sich von dem Vorgehen in den anderen Kapiteln. Viele Klassen und Methoden von PyTorch und TorchText erwarten verschiedene Dateien für den Trainings-, Test- und Validierungsdatensatz. Mithilfe der uns bereits bekannten `train_test_split`-Funktion von Scikit-learn können wir diese Dateien erstellen, da die Funktion als Eingabe neben numpy-Matrizen auch DataFrames erlaubt. Bis jetzt hatten wir den Datei-Typ **csv** verwendet. Dieser ist jedoch für die Nutzung mit TorchText problematisch, die JSON Variante <a href=\"http://jsonlines.org/\">JSON Lines</a> eignet sich hier besser.[<sup>1</sup>](#fn1) Beim **JSON Line** Format ist jede Zeile ein valider JSON Wert. Die gesplitteten Datensätze des Wikipedia-Korpus wandeln wir mit einer selbstgeschriebenen Funktion `df_to_jsonl` in das JSON Line Format um. Zuvor wurden für dieses Tutorial die Spalten \"id\" und \"length\" aus dem Korpus entfernt.\n",
    "\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<span id=\"fn1\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">1</sup> &nbsp; \n",
    "Unter anderem liegt das daran, dass csv-Dateien mit Kommas (oder Semikolons) voneinander getrennt werden und TorchText Probleme hat, diese Trennungskommas von Kommas in der \"Text\"-Spalte zu unterschieden. Für weitere Erklärungen zum Vorteil von JSON-Dateien gegenüber csv-Dateien siehe dieses <a href=\"https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/A%20-%20Using%20TorchText%20with%20Your%20Own%20Datasets.ipynb\">TorchText-Tutorial</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\", index_col = 0)\n",
    "corpus = corpus.drop(\"id\", axis=1)\n",
    "corpus = corpus.drop(\"length\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>All the Best ! ( englisch Alles Gute ! ) ist d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>Let It Roll : Songs by George Harrison ist das...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>Lieder wie Orkane ist das dritte offizielle Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>Long Stick Goes Boom : The Anthology ist eine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Album nach Typ</td>\n",
       "      <td>Los Grandes Éxitos en Español ( spanisch für D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                               text\n",
       "0  Album nach Typ  All the Best ! ( englisch Alles Gute ! ) ist d...\n",
       "1  Album nach Typ  Let It Roll : Songs by George Harrison ist das...\n",
       "2  Album nach Typ  Lieder wie Orkane ist das dritte offizielle Be...\n",
       "3  Album nach Typ  Long Stick Goes Boom : The Anthology ist eine ...\n",
       "4  Album nach Typ  Los Grandes Éxitos en Español ( spanisch für D..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_remain = train_test_split(corpus, \n",
    "                                     test_size=0.4, \n",
    "                                     train_size=0.6,\n",
    "                                     random_state=42,\n",
    "                                     stratify=corpus[\"category\"])\n",
    "X_val = X_remain[:1200]\n",
    "X_test = X_remain[1200:]\n",
    "\n",
    "\n",
    "def df_to_jsonl(df, filename, column=\"text\", path=\"tutorialdata/pytorch_data/\"):\n",
    "    \"\"\" DataFrame with text column to Json Line Format. \"\"\"\n",
    "\n",
    "    df[column] = df.apply(lambda row: word_tokenize(row[column]), axis=1)\n",
    "    df.to_json(f\"{path}{filename}.json\", orient='records', lines=True)\n",
    "    \n",
    "    \n",
    "df_to_jsonl(X_train, \"train\")\n",
    "df_to_jsonl(X_val, \"val\")\n",
    "df_to_jsonl(X_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2.3.2. Laden der JSON-Dateien <a class=\"anchor\" id=\"Z-2-3-2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eines der Hauptkonzepte von TorchText ist das sogenannte **`Field`**. Dadurch wird definiert, wie Daten verarbeitet werden sollen. So kann z.B. angegeben werden, ob Texte in diesem `Field` tokenisiert werden sollen und nur kleingeschrieben verarbeitet werden sollen. Im `Field` TEXT wurde als Tokenizer *toktok* angegeben, eine Tokenizer der NLP-Bibliothek **NLTK** (andere mögliche Werte finden sich <a href=\"https://pytorch.org/text/_modules/torchtext/data/utils.html\">hier</a>). In unserem Fall ändert sich durch die Angabe des Tokenizers nichts an den Texten der Datensatz-Dateien, da diese bereits vorher wegen der Konvertierung ins JSON Lines Format tokenisiert wurden.[<sup>2</sup>](#fn2) Weiterhin haben wir alle Wörter mit dem Argument `lower` in Kleinbuchstaben konvertiert.[<sup>3</sup>](#fn3) Auch Stoppwörter sowie viele Satzzeichen wurden ignoriert.<br>\n",
    "Neben der Übergabe von Argumenten gibt es von `Field` noch verschiedene Varianten. Für die Spalte mit den Klassen verwenden wir beispielsweise die Variante `LabelField`. Im Grunde unterscheidet diese sich nicht groß von `Field`, jedoch sind die Argumente `sequential` und `unk_token` automatisch auf `None` gesetzt. Dies macht Sinn, da es sich bei unseren Labeln nicht um sequentielle Daten (*hier*: keine ganzen Texte) handelt und es auch nicht zu einem Out-of-Vocabulary (OOV) Fehler kommen kann. Anders ist dies jedoch bei unserem TEXT-`Field`. Weiter unten geben wir die maximale Größe unseres Vokabulars an, d.h. wir begrenzen die von unserem Modell zu verarbeitenden Wörter auf die 25.000 häufigsten Wörter. Geben wir jedoch die tatsächliche Größe unseres Vokabulars aus, nachdem wir es mit `build_vocab` erstellt haben, erhalten wir den Wert 25.002. Dies liegt daran, dass noch die zwei zusätzlichen Vokabeln `<unk>` und `<pad>` hinzugefügt. Da wir nur das Vokabular unseres Trainingsdatensatzes kennen, kann es sein, dass es im Validierungs- oder Testdatensatz Wörter gibt, die nicht in unserem Vokabular vorkommen. Um nicht den OOV-Fehler zu erhalten, wird von PyTorch die Vokabel `<unk>` verwendet (= unknown). Der `<pad>`-Token (= padding) wird zum \"Auffüllen\" von Batches verwendet.[<sup>4</sup>](#fn4) <br>\n",
    "\n",
    "Mit der Funktion `data.TabularDataset.splits` rufen wir die verschiedenen JSON-Dateien als Tabellen-Datensatz auf. Dem Argument `fields` übergeben wir ein Dictionary `assigned_fields`, in welchen wir unseren erstellten `Fields` TEXT und CATEGORIES die entsprechenden zugehörigen Spalten unserer Datensätze zuordnen. In der späteren Trainingsschleife können wir uns das zu Nutze machen und z.B. über `batch.category` auf die Kategorien zugreifen. Mit dem `skip_header = True` geben wir an, dass die Spaltenbezeichnungen ignoriert werden.\n",
    "\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<span id=\"fn2\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">2</sup> &nbsp; Texte sollten im besten Fall vorher tokenisiert werden, da ansonsten TorchText jedes Mal, wenn die Datensätze geladen werden, diese neu tokenisiert. Dies kann bei großen Datensätzen sehr viel Zeit kosten.<br>\n",
    "<span id=\"fn3\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">3</sup> &nbsp; Dies ist für die deutsche Sprache nicht immer sinnvoll, wurde hier jedoch verwendet, um eine diverseres Vokabular zu erhalten.<br>\n",
    "<span id=\"fn4\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">4</sup> &nbsp; Die GPU (oder CPU) verarbeitet die Trainingsdaten beim Training des Neuronalen Netzes in <b>batches</b> (= Stapel), die alle eine gewisse Länge haben. Ist ein Batch zu klein, wird er mit Padding-Tokens aufgefüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('german') + punctuation \n",
    "\n",
    "TEXT = data.Field(tokenize = \"toktok\",\n",
    "                  lower = True,\n",
    "                  stop_words=stop_words)\n",
    "CATEGORIES = data.LabelField()\n",
    "assigned_fields = {\"text\": ('text', TEXT), \n",
    "                   \"category\": ('category', CATEGORIES)}\n",
    "\n",
    "train_data, val_data, test_data = data.TabularDataset.splits(path='tutorialdata/pytorch_data/', \n",
    "                                                              train='train.json',\n",
    "                                                              validation='val.json', \n",
    "                                                              test='test.json', \n",
    "                                                              format='json',\n",
    "                                                              fields=assigned_fields,\n",
    "                                                              skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['satz', 'trachtenbrot', 'benannt', 'boris', 'trachtenbrot', 'satz', 'mathematischen', 'logik', '1950', 'bewiesen', 'besagt', 'endlichen', 'modellen', 'allgemeingültigen', 'sätze', 'prädikatenlogik', 'erster', 'stufe', 'rekursiv', 'aufzählbar']\n"
     ]
    }
   ],
   "source": [
    "example = vars(train_data.examples[1])\n",
    "print(example[\"text\"][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begrenzung des Vokabulars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "CATEGORIES.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einzigarte Tokens im TEXT-Vokabular: 25002\n",
      "Einzigarte Tokens im CATEGORIES-Vokabular: 30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Einzigarte Tokens im TEXT-Vokabular: {len(TEXT.vocab)}\")\n",
    "print(f\"Einzigarte Tokens im CATEGORIES-Vokabular: {len(CATEGORIES.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jedoch', 2720), ('sowie', 2706), ('jahr', 2678), ('the', 2566), ('2', 2385), ('seit', 2320), ('zwei', 2272), ('1', 2258), ('stadt', 2243), ('ab', 2203), ('jahre', 2103), ('mehr', 2056), ('etwa', 1994), ('zeit', 1963), ('of', 1826), ('ersten', 1820), ('dabei', 1712), ('jahren', 1677), ('drei', 1671), ('a', 1659)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Vokabular kann auch direkt angezeigt werden, indem wir die Funktionen `stoi` (= string to int) oder `itos` (= int to string) verwenden. Da alle unsere Daten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'jedoch', 'sowie', 'jahr', 'the', '2', 'seit', 'zwei', '1']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der letzte Schritt bei der Vorbereitung der Daten ist die Erstellung der **Iteratoren**. Ein Datensatz-Iterator ermöglicht das einfache Laden von Daten in Neuronalen Netzwerke und hilft bei der Organisation von Stapelverarbeitung (= batching), Maskierung und Konvertierung (z.B. die Wörter durch die Indexnummer der Wörter zu ersetzen). Wir iterieren über diese Iteratoren in der Trainings-/Evaluierungsschleife und sie geben bei jeder Iteration einen Batch von Daten zurück (indiziert und in Tensoren umgewandelt). Dafür verwenden wir den sogenannten `BucketIterator`, der einen Batch von Daten zurückgibt, bei der jeder Datenpunkt eine ähnliche Länge hat. Somit wird der Gebrauch von Padding (*hier*: den `<pad>` Tokens) minimiert. Sollte eine GPU vorhanden und CUDA erfolgreich installiert worden sein, kann mithilfe von `torch.device` diese genutzt werden, indem sie `device` dem `BucketIterator` übergeben wird. Zuletzt geben wir ähnlich wie bei Keras noch die Größe der Batches an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: argumente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, val_iterator, test_iterator = data.BucketIterator.splits((train_data, val_data, test_data), \n",
    "                                                                         batch_size = BATCH_SIZE,\n",
    "                                                                         device = device,\n",
    "                                                                         sort_key = lambda x: len(x.text),\n",
    "                                                                         sort = False,\n",
    "                                                                         sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf diese Iteratoren können wir nun zugreifen. Wir erstellen hier zu Demonstrationszwecken einen Batch des `train_iterator` außerhalb der eigentlichen Schleife. Mithilfe von `batch.text` können wir uns nun unsere umgewandelten Textdaten anzeigen lassen, die indiziert wurden und in einem Tensor gespeichert wurden. Dabei wird auf das erstellte Dictionary `assigned_fields` zugegriffen, genauer auf den Namen im Tuple zum Key \"text\". Wir konnten dort einen beliebigen Namen wählen, auf den wir jetzt zugreifen. Mit `batch.category` können wir auch auf unsere Kategorien zugreifen, die ebenfalls indiziert und in Tensoren umgewandelt wurden. Das dies erfolgreich war, können wir daran erkennen, dass nur Zahlen zwischen 0 und 29 in unserem Tensor vorkommen, also 30 verschiedene Indizes. Da wir 30 verschiedene Kategorien haben, passt dies überein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4562, 18480,  2720,  ..., 24238,     0,     0],\n",
      "        [   33,  6649,  3559,  ...,    70,  3494,  5612],\n",
      "        [  122,  3725,     0,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iterator))\n",
    "print(batch.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  4, 25, 24,  0, 17, 17,  7,  4, 22,  5, 25,  4, 17, 16,  6,  8, 23,\n",
      "         9,  9, 18,  5, 10,  5, 22,  3, 27,  2, 21, 21, 28,  2,  8,  4, 11,  7,\n",
      "        12, 10, 18, 26, 19, 20, 25, 28,  6, 22, 25,  3, 28, 27, 19, 13, 15, 11,\n",
      "        26,  7, 23,  2, 11,  8, 10, 28, 12,  6])\n"
     ]
    }
   ],
   "source": [
    "print(batch.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2.3.3. Erstellung eines sequentiellen Modells <a class=\"anchor\" id=\"Z-2-3-3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anders als bei Keras stützt sich das Erstellen von Modellen auf Klassen, die wir selbst erstellen müssen. Dadurch wird die Menge an Code im Gegensatz zu Keras erhöht, dafür können wir auch viel besser unser Neuronales Netz auf unsere Bedürfnisse anpassen. Wir erhalten hier <a href=\"https://en.wikipedia.org/wiki/Boilerplate_code\">Boilerplate Code</a>. Für die Erstellung eines einfachen sequentiellen Modells in Keras brauchten wir nur folgenden Code:<br>\n",
    "\n",
    "```\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\", input_shape=(len(vocab),)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(len(np.unique(labels)), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```\n",
    "\n",
    "Für ... TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = len(TEXT.vocab)\n",
    "output_shape = len(CATEGORIES.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Ansatz: `nn.Sequential()`\n",
    "\n",
    "Dieser erste Ansatz ähnelt sehr dem Aufbau des Keras-Modells. In der Praxis wird dieser Ansatz seltener benutzt, weshalb wir uns eher auf den nächsten Ansatz fokussieren werden. Für eine ersten Einstieg in die Modell-Architektur von PyTorch ist es aber sehr hilfreich. Ähnlich wie bei Keras definieren wir das sequentielle Modell mit `nn.Sequential`. Diesem übergeben wir eine Liste von Layern, in Keras wurden diese nach und nach hinzugefügt. Wir können alternativ dem sequentiellen Modell auch direkt unsere Layer übergeben, etwa so:<br>\n",
    "\n",
    "```\n",
    "model = nn.Sequential(nn.Linear(input_shape, 64),\n",
    "                      nn.ReLU(),\n",
    "                      ...)\n",
    "```\n",
    "\n",
    "Die Übergabe einer Liste von Layern ist m.E. jedoch übersichtlicher. Bei den Layern gibt es jedoch einige Unterschiede zu Keras. Das Äquivalent zum Dense-Layer in Keras ist in PyTorch der Linear-Layer. Die Aktivierungslayer werden anders als im oben gezeigten Keras-Code nicht innerhalb des Dense-Layer angegeben, sondern als eigenständiger Layer. Jeder Linear-Layer hat zwei Parameter: Die Dimension der Eingabedaten und die Dimension der Ausagebdaten. Im ersten Layer ist die Eingabedimension gleich der Größe unseres Text-Vokabulars, im letzten Layer ist die Ausgabedimension gleich der Anzahl unserer Kategorien. Die anderen Parameter beziehen sich auf die Dimensionen des vorherigen bzw. nächsten Layers. So muss die Eingabedimension eines Layers immer gleich der Ausgabedimension des vorherigen Layers sein. Dies wurde von Keras automatisch verwaltet, in PyTorch müssen wir dies selbst angeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25002, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=30, bias=True)\n",
      "  (5): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "layers.append(nn.Linear(input_shape, 64))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(64, 64))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(64, output_shape))\n",
    "layers.append(nn.Softmax())\n",
    "\n",
    "model = nn.Sequential(*layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Ansatz: `nn.Sequential()` + `torch.nn.Model` Klasse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_shape):\n",
    "        #super(SequentialModel, self).__init__()\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        self.layers = nn.Sequential(nn.Linear(input_shape, hidden_dim1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm1d(hidden_dim1),\n",
    "                                    nn.Linear(hidden_dim1, hidden_dim2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm1d(hidden_dim2),\n",
    "                                    nn.Linear(hidden_dim2, output_shape),\n",
    "                                    nn.Softmax(dim=output_shape)\n",
    "                                   )\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(input_shape, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # TODO: fixen\n",
    "        \n",
    "        #x = nn.Softmax(self.layers)\n",
    "        #return x\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        # return self.layers(x)\n",
    "        \"\"\"\n",
    "        print(f\"linear1 weights: {self.linear1.weight.size()}\")\n",
    "        x = self.linear1(x)\n",
    "        hidden_relu = nn.functional.relu(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(f\"x shape: {x.shape}\")\n",
    "        embedded = self.embedding(x)\n",
    "        linear = self.linear1(embedded)\n",
    "        #output, hidden = self.linear1(embedded)\n",
    "        \n",
    "        #assert torch.equal(linear[-1,:,:], linear.squeeze(0))\n",
    "        \n",
    "        return self.out(linear.squeeze(0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #print(text.shape)\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SequentialModel(input_shape, 100, 64, output_shape)\n",
    "model = RNN(input_shape, 100, 256, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(25002, 100)\n",
      "  (rnn): RNN(100, 256)\n",
      "  (fc): Linear(in_features=256, out_features=30, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# RuntimeError: Expected object of device type cuda \n",
    "# but got device type cpu for argument #1 'self' in call to _th_addmm\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text)\n",
    "        \n",
    "        loss = criterion(predictions, batch.category)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.category)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text)\n",
    "            \n",
    "            loss = criterion(predictions, batch.category)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.category)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "\tTrain Loss: 3.441 | Train Acc: 3.00%\n",
      "\t Val. Loss: 3.419 |  Val. Acc: 3.43%\n",
      "Epoch: 2 \n",
      "\tTrain Loss: 3.426 | Train Acc: 3.37%\n",
      "\t Val. Loss: 3.412 |  Val. Acc: 3.60%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-f8714b71d024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-206-3566e64ea10c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 4\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, val_iterator, criterion)\n",
    "    \n",
    "    \n",
    "    print(f'Epoch: {epoch+1} ')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# RuntimeError: Expected object of device type cuda \n",
    "# but got device type cpu for argument #1 'self' in call to _th_addmm\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "for epoch in range(2):\n",
    "    \n",
    "    model.train()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    \n",
    "    \n",
    "    for batch in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(batch.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,606,302 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/5%20-%20Multi-class%20Sentiment%20Analysis.ipynb\n",
    "- acc berechnen\n",
    "- train funktion erstellen\n",
    "- evaluate funktion erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text.float())\n",
    "        \n",
    "        loss = criterion(predictions, batch.category)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.category)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text)\n",
    "            \n",
    "            loss = criterion(predictions, batch.category)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.category)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1270 x 64], m2: [25002 x 64] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:290",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7353678ed527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-e5ac868a3ec9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d01bc52ecfc1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1270 x 64], m2: [25002 x 64] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:290"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, val_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    \"\"\"\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = len(TEXT.vocab)\n",
    "output_shape = len(CATEGORIES.vocab)\n",
    "model = SequentialModel(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO word embeddings: https://www.innoq.com/en/blog/handling-german-text-with-torchtext/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
