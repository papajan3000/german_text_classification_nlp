{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>ACHTUNG</b>: Das Kapitel befindet sich noch in Arbeit und ist nicht fertig.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusatzkapitel 2 - Neuronale Netze mit PyTorch und TorchText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.1. Kapitelübersicht <a class=\"anchor\" id=\"Z-2-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Kapitel wird gezeigt, wie man einfache Neuronale Netze mit der Deep-Learning-Bibliothek **PyTorch** und **TorchText** erstellt. Dieses Kapitel baut auf den Kapiteln 10 bis 13 auf, d.h. das Konzept von Neuronalen Netzen, gängige Deep Learning Begriffe und erste Praxiserfahrungen mit Keras sollten bekannt und vorhanden sein. Weiterhin sollte die Benutzung von Iteratoren in Python sowie das Konzept der objektorientierten Programmierung in Python geläufig sein, da PyTorch eine Klassenarchitektur zur Erstellung von Modellen benutzt. Auch wird die Benutzung einer GPU wie bei Kapitel 12 dringend empfohlen (auch hier kann wieder **Google Colab** benutzt werden).\n",
    "\n",
    "TODO: Word Embeddings als Pflicht?\n",
    "\n",
    "**Hinweis**: Das PyTorch-Modul befindet sich <u>nicht</u> in der bei dieser Tutorialreihe beigelegten `requirements.txt` Datei. Es muss eigenständig installiert werden, was jedoch im Gegensatz zu Keras oder Tensorflow weitaus unkomplizierter ist. Die Webseite von <a href=\"https://pytorch.org/\">PyTorch</a> ist hier sehr hilfreich. <a href=\"https://github.com/pytorch/text\">TorchText</a> muss ebenfalls noch installiert werden.\n",
    "\n",
    "<b>Abschnittsübersicht</b>:<br>\n",
    "[Z.2.1. Kapitelübersicht](#Z-2-1)<br>\n",
    "[Z.2.2. Übersicht zu PyTorch](#Z-2-2)<br>\n",
    "[Z.2.3. Vorverarbeitung des Korpus mit TorchText](#Z-2-3)<br>\n",
    "[Z.2.3.1. Aufteilung des Korpus](#Z-2-3-1)<br>\n",
    "[Z.2.3.2. Laden der Train-Val-Test-Dateien](#Z-2-3-2)<br>\n",
    "[Z.2.3.3. Erstellung eines einfachen sequentiellen Modells TODO](#Z-2-4)<br>\n",
    "[Z.2.3.2. Laden der JSON-Dateien](#Z-2-3-2)<br>\n",
    "[Z.2.3.3. Erstellung eines sequentiellen Modells](#Z-2-3-3)<br>\n",
    "[Z.2.3.4. Training eines sequentiellen Modells](#Z-2-3-4)<br>\n",
    "\n",
    "Am Ende dieses Kapitel werden wir folgende Themen behandelt und/oder vertieft haben:\n",
    "- Implementierung eines Neuronalen Netz mit PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "punctuation = ['!', '#','$','%','&', \"'\", '(',')','*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', \n",
    "               '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '`', '``', 'wurde', 'wurden']\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.2. Übersicht zu PyTorch <a class=\"anchor\" id=\"Z-2-2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Aufgabe:</b> Deep Learning with PyTorch <br>\n",
    "    \n",
    "Für das folgende Tutorial ist es hilfreich, begleitend das Buch von Eli Stevens et. al. \"Deep Learning with PyTorch\" zu lesen, welches einen guten Einstieg zu PyTorch liefert. \n",
    "    \n",
    "<br><u>Das Buch</u>: STEVENS, Eli et. al., Deep Learning with PyTorch, July 2020 (englische Ausgabe).\n",
    "<br><br>\n",
    "    \n",
    "Es eignet sich sehr gut für Leser, die bereits ersten Einblicke im Deep Learning gewonnen haben, wie etwa durch das Buch von Chollet (siehe Kapitel 10-12). Anders als bei dem Buch von Chollet wird das Buch von Stevens et. al. nicht für die Benutzung dieses Tutorials vorausgesetzt, es dient eher als Begleitlektüre mit vertiefenden, erweiterenden und ausführlicheren Behandlung von Themen. Die Autoren scheinen bei den Themen einen Fokus auf die Arbeit mit Bilddateien zu legen, weshalb ich im folgenden Kapitel hervorheben möchte, die für die Arbeit mit Textdaten hilfreich sind oder diese als Thema haben. Sollte man das Buch also nur überfliegen, sollten diese Kapitel mindestens oder ausführlicher gelesen werden:\n",
    "- Kapitel 3: \"It starts with a tensor\". Gute Einführung zum Datentyp <b>Tensor</b>, der für PyTorch eine wichtige Rolle spielt.\n",
    "- Kapitel 4.5: \"Representing text\". Zeigt, wie Textdaten mit PyTorch verarbeitet werden können und greift auch das Thema <b>Embeddings</b> auf.\n",
    "- Kapitel 5: \"The mechanics of learning\". Hier werden noch einmal die Grundlagen von Neuronalen Netzen erklärt, aber auch einige PyTorch Eigenheiten, die wichtig sind.\n",
    "- TODO\n",
    "- ...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie auch **Keras** ist **PyTorch** eine Deep-Learning-Bibliothek, anders als Keras basiert PyTorch jedoch nicht auf der Bibliothek **Tensorflow**, sondern auf der Bibliothek **Torch**. PyTorch erfordert zudem eine stärkere Auseinandersetzung mit den Mechaniken von Deep Learning, weshalb auch mehr Code als bei Keras benötigt wird, in welchem meist mit nur wenigen Zeilen Code ein Neuronales Netz erstellt werden kann. Im akademischen Bereich wird PyTorch aktuell (Stand August 2020) jedoch viel häufiger als Keras verwendet, da es eine bessere Performance liefert und die Erstellung von komplexeren Neuronalen Netzwerkarchitekturen ermöglicht. Keras selbst wird anders als Tensorflow oder PyTorch aufgrund seiner Simplizität meistens nur zur Erstellung von Prototypen genutzt, abseits von Tutorials ist es deshalb seltener zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch vs. Keras\n",
    "\n",
    "\n",
    "<table align=\"left\"> \n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th style=\"text-align:center;\">Keras</th>\n",
    "    <th style=\"text-align:center;\">PyTorch</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td><b>Vorteile</b></td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Einsteigerfreundlich</li>\n",
    "          <li>Simple Architektur</li>\n",
    "          <li>Einfache Erstellung von Prototypen</li>\n",
    "          <li>Gut für kleine Datensätze</li>\n",
    "          <li>wenige Zeilen Code</li>\n",
    "          <li>Debugging kaum notwendig</li>\n",
    "        </ul> \n",
    "    </td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Sehr flexibel</li>\n",
    "            <li>Höhere Perfomance</li>\n",
    "            <li>Ermöglicht komplexere Neuronale Netzwerke</li>\n",
    "            <li>Nutzt Python-Syntax</li>\n",
    "            <li>Eignet sich gut fürs Debugging</li>\n",
    "            <li>Gute Peformance auch für größere Datensätze</li>\n",
    "            <li>Großer Community-Support</li>\n",
    "            <li>Forschung nutzt vorrangig PyTorch, d.h. Paper nutzen PyTorch-Architektur</li>\n",
    "        </ul>   \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nachteile</b></td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Langsamer als PyTorch</li>\n",
    "          <li>Benutzung der eigenen GPU kann umständlich werden</li>\n",
    "            <li><i>Subjektiv:</i> Abgewandelte Python-Syntax</li>\n",
    "            <li>Weniger Community-Support</li>\n",
    "        </ul> \n",
    "    </td>\n",
    "    <td>\n",
    "        <ul style=\"text-align:left;\">\n",
    "          <li>Weniger einsteigerfreundlich als Keras</li>\n",
    "          <li>Braucht viel mehr Code</li>\n",
    "        </ul>    \n",
    "    </td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu Beginn ist es recht nützlich, sich einen kurzen Überblick über die wichtigsten Module von PyTorch zu verschaffen, die im folgenden aufgelistet sind:\n",
    "\n",
    "- `torch.nn`: Die Kern-Module, die zur Erstellung eines Neuronalen Netzes benötigt werden, befinden sich in diesem übergeordneten Modul. Vorwiegend befinden sich hier Module zur Erstellung von unterschieden **Layer** eines NN (z.B. fully connected Layer oder Convolutional Layer), aber auch **Aktivierungsfunktionen** und **Verlustfunktionen** können hiermit aufgerufen werden.\n",
    "- `torch.optim`: Hier befinden sich Module zur Implementierung von **Optimierungsverfahren**. In Kapitel 12.5 wurden die Optimierungsverfahren *Adam*, *RMSprop* und *SGD* zur Hyperparameteroptimierung verwendet, diese stehen bei PyTorch ebenfalls zur Verfügung und können z.B. mit `from torch.optim as RMSprop` aufgerufen werden.\n",
    "- `torch.tensor`: Dieses Modul befasst sich mit der Datenstruktur **Tensor**.\n",
    "- `torch.utils.data`: Dieses Modul enthält die Klasse **`DataLoader`**, mithilfe derer Datensätze für die Verwendung von PyTorch geladen werden können.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TODO:<br>\n",
    "- grund dinge wie torch modul & ähnliches erklären\n",
    "- tabelle unten überpfüen und ggbf ergänzen\n",
    "\n",
    "\n",
    "\n",
    "Sollte man mit Textdaten arbeiten, empfiehlt es sich, neben PyTorch noch die ebenfalls von PyTorch bereitgestelle Bibliothek **`TorchText`** zu verwenden. Diese vereinfacht typische Vorverarbeitungsschritte für die Arbeit mit Textdaten ungemein. Das Pendant für Bilddaten heißt **`TorchVision`** und das Pendant für Audiodaten heißt **`TorchAudio`**, beide Bibliotheken werden in diesem Tutorial jedoch nicht behandelt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.2.3. Vorverarbeitung des Korpus mit TorchText <a class=\"anchor\" id=\"Z-2-3\"/>\n",
    "\n",
    "Das Einlesen und die Aufteilung des Korpus unterscheidet sich von dem Vorgehen in den anderen Kapiteln. PyTorch erfordert mehr noch als Keras eine ausführlichere Vorverarbeitung des Korpus. Für das Einlesen und für die Vorverarbeitung von Textdaten ist es daher sinnvoll, die Bibliothek **`TorchText`** zu verwenden. `TorchText` hilft bei den folgenden Operationen[<sup>1</sup>](#fn1):\n",
    "\n",
    "- **Laden von Dateien**: Laden in das Korpus aus verschiedenen Formaten\n",
    "- **Tokenisierung**: Sätze in Wortlisten aufteilen\n",
    "- **Vokabular erstellen**: Erstellen einer Vokabelliste\n",
    "- **Numerisieren/Indexifizieren**: Wörter eines Korpus als Ganzzahlen darstellen\n",
    "- **Wortvektoren**: entweder das Vokabular zufällig initialisieren oder aus einem vortrainierten Embedding laden (dieses muss jedoch \"getrimmt\" werden, d.h. speichern nur Wörter aus den Vokabular werden auch gespeichert).\n",
    "- **Batching**: Erzeugen von Batches von Trainingsdaten\n",
    "\n",
    "\n",
    "Leider übernimmt TorchText nicht die folgenden Aufgaben, die manuell oder mit anderen Hilfsbibliotheken durchgeführt werden müssen:\n",
    "\n",
    "- **Train-Val-Test-Split**: Korpus in Trainings-, Validierungs und Testdaten aufteilen\n",
    "- **Embedding Lookup**: Zuordnung jedes Satzes (der Wortindizes enthält) zu Wortvektoren einer festen Dimension, welches für Word Embeddings relevant ist\n",
    "\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<div id=\"fn1\" style=\"font-size:8pt; line-height:1; padding-left: 1em; text-indent: -1em\"><sup style=\"font-size:5pt\">1</sup>&nbsp; Die Liste wurde von diesem <a href=\"https://anie.me/On-Torchtext/\"> Blogpost</a> entnommen.</div>import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false,
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
