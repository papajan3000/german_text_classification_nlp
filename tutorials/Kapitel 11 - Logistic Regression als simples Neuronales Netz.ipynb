{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 11 - Logistic Regression als simples Neuronales Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. Kapitelübersicht <a class=\"anchor\" id=\"11-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir uns mit der Implementierung von Neuronalen Netzen in Keras widmen, werden wir in diesem Kapitel das Klassifizierungsverfahren <b>Logistic Regression</b> als Neuronales Netz implementieren. Der eigentliche <a href=\"https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb\">Code</a> wurde aus dem Coursera Kurs \"Deep Learning\" entnommen. Dort wurde in der ersten <a href=\"https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb\">Programmieraufgabe</a> ein Datensatz mit Katzenbildern klassifiziert, wobei Bilder die Klassen \"Katze\" oder \"Keine Katze\" besaßen. Logistic Regression wurde dort als einfaches simples Neuronales Netz interpretiert. Der Code funktioniert sehr gut mit unserem Korpus, jedoch musste dieser vorher auf zwei Kategorien reduziert werden, da eine Multiclass Klassifizierung als Anschauungsbeispiel zu komplex wäre. Die Idee dieses Kapitels ist es, einen Einblick in die Implementation eines Neuronalen Netzes zu erhalten. Neben einem Einblick soll dieses Kapitel die Grundschritte der Neuronalen Netze wie Forward Propagation und Backward Propagation verdeutlichen(?). Später werden wir auf die Deep-Learning-Bibliothek <b>Keras</b> zurückgreifen, bei der jedoch die zentralen Schritten des Trainings eines Neuronalen Netzes nicht so präsent sind. \n",
    "\n",
    "<b>Abschnittsübersicht</b><br>\n",
    "\n",
    "[11.1. Kapitelübersicht](#11-1)<br>\n",
    "\n",
    "\n",
    "Am Ende dieses Kapitel werden wir folgende Themen behandelt und/oder vertieft haben:\n",
    "- Implementierungen Neuronaler Netze in numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ?.2. Reduzierung des Korpus auf 2 Klassen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um unser Korpus mit dem später entwickelten binären Classifier trainieren zu können, müssen wir es auf zwei Klassen reduzieren. Dazu wählen wir die Kategorien \"Computerspiel nach Plattform\" und \"Internet\" aus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden und Reduzierung des Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>length</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2646</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>353</td>\n",
       "      <td>Ballyhoo ist ein Computerspiel der US-amerikan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2644</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>379</td>\n",
       "      <td>Balance of Power ist ein Computer-Strategiespi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2645</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>415</td>\n",
       "      <td>Ballblazer ist ein Zweispieler-Computer-Sports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2647</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>417</td>\n",
       "      <td>Barbarian : The Ultimate Warrior und Barbarian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2652</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>359</td>\n",
       "      <td>Beyond Zork ( kompletter Titel Beyond Zork : T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2649</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>445</td>\n",
       "      <td>BattleTech : The Crescent Hawk ' s Inception i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2650</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>1188</td>\n",
       "      <td>Battletoads ist ein Videospiel des Spieleentwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2651</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>1008</td>\n",
       "      <td>Beneath a Steel Sky ( Deutsch etwa \" Unter ein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2643</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>344</td>\n",
       "      <td>Badlands ist ein Arcadespiel , das Atari Games...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2648</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>1338</td>\n",
       "      <td>Battle Isle ist eine Reihe von rundenbasierten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2642</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>870</td>\n",
       "      <td>Bad Dudes ist ein Arcade-Spiel aus dem Jahr 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2630</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>374</td>\n",
       "      <td>Amberstar ist ein von der Firma Thalion Softwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2640</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>139</td>\n",
       "      <td>Aufschwung Ost ist ein Computerspiel im Stil v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2639</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>318</td>\n",
       "      <td>Atomino ist ein Puzzle-Computerspiel von Blue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2638</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>685</td>\n",
       "      <td>Arthur : The Quest for Excalibur ist ein Texta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2637</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>254</td>\n",
       "      <td>Arkanoid ist ein Computerspiel des Unternehmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2636</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>1171</td>\n",
       "      <td>Archon : The Light and the Dark ist ein 1983 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2635</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>670</td>\n",
       "      <td>Die Arche des Captain Blood ( frz . Originalti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2634</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>408</td>\n",
       "      <td>Apidya ist ein horizontal scrollendes Shoot ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2633</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>1323</td>\n",
       "      <td>Another World ( US-Titel : Out of this World )...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2632</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>575</td>\n",
       "      <td>Angband ist ein Rogue-ähnliches Computer-Rolle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2631</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>390</td>\n",
       "      <td>Ancient Domains of Mystery ( kurz ADOM ) ist e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2629</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>391</td>\n",
       "      <td>Ambermoon ist ein Rollenspiel der Firma Thalio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2641</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>425</td>\n",
       "      <td>Die Rituale der Azteken ( engl . Originaltitel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2653</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>874</td>\n",
       "      <td>Biing ! - Sex , Intrigen und Skalpelle ist ein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2665</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>410</td>\n",
       "      <td>Budokan - The Martial Spirit ist ein Kampfspor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2655</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>612</td>\n",
       "      <td>The Black Cauldron ist ein Adventurespiel des ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2680</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>2246</td>\n",
       "      <td>Civilization ist ein 1991 erschienenes Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2679</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>508</td>\n",
       "      <td>City Bomber ist ein frühes Computerspiel für H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2678</td>\n",
       "      <td>Computerspiel nach Plattform</td>\n",
       "      <td>351</td>\n",
       "      <td>Christoph Kolumbus ist ein von Software 2000 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>248</td>\n",
       "      <td>Internet</td>\n",
       "      <td>120</td>\n",
       "      <td>Das CSNET ( Computer Science Network ) war ein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>436</td>\n",
       "      <td>Internet</td>\n",
       "      <td>121</td>\n",
       "      <td>Cloudevo ist eine Software , die verschiedene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>289</td>\n",
       "      <td>Internet</td>\n",
       "      <td>205</td>\n",
       "      <td>Click-to-call ( CTC ) ist ein Verfahren , welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>291</td>\n",
       "      <td>Internet</td>\n",
       "      <td>1065</td>\n",
       "      <td>Club Penguin war ein Browserspiel ( MMORPG ) f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>321</td>\n",
       "      <td>Internet</td>\n",
       "      <td>412</td>\n",
       "      <td>Eine Netzgeschichte ( engl . netstory ) oder a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>322</td>\n",
       "      <td>Internet</td>\n",
       "      <td>2279</td>\n",
       "      <td>Netzkunst ist ein Sammelbegriff für künstleris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>323</td>\n",
       "      <td>Internet</td>\n",
       "      <td>1105</td>\n",
       "      <td>Als Newsletter [ njuzlt ] ( engl . für Mitteil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>324</td>\n",
       "      <td>Internet</td>\n",
       "      <td>1646</td>\n",
       "      <td>Ning ist eine Online-Plattform zur Erstellung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>325</td>\n",
       "      <td>Internet</td>\n",
       "      <td>548</td>\n",
       "      <td>Die Online-Beratung gegen Rechtsextremismus is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>326</td>\n",
       "      <td>Internet</td>\n",
       "      <td>1607</td>\n",
       "      <td>Online-Journalismus ( auch Onlinejournalismus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>327</td>\n",
       "      <td>Internet</td>\n",
       "      <td>2147</td>\n",
       "      <td>Ein Online-Musikdienst ( auch Musikportal gena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>328</td>\n",
       "      <td>Internet</td>\n",
       "      <td>295</td>\n",
       "      <td>Eine Online-Pressemitteilung ist eine Pressemi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>329</td>\n",
       "      <td>Internet</td>\n",
       "      <td>676</td>\n",
       "      <td>Online-Rechtsberatung ist eine neuere Form der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>330</td>\n",
       "      <td>Internet</td>\n",
       "      <td>1922</td>\n",
       "      <td>Der Begriff Onlineberatung ( auch : Internetbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>331</td>\n",
       "      <td>Internet</td>\n",
       "      <td>454</td>\n",
       "      <td>Als Online-Publikationen oder Netzpublikatione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>320</td>\n",
       "      <td>Internet</td>\n",
       "      <td>1286</td>\n",
       "      <td>Netcat , auch nc genannt , ist ein einfaches W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>332</td>\n",
       "      <td>Internet</td>\n",
       "      <td>326</td>\n",
       "      <td>Onlinespiele ( häufig auch bekannt als Interne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>334</td>\n",
       "      <td>Internet</td>\n",
       "      <td>410</td>\n",
       "      <td>OpenLDAP ist eine Implementierung des LDAP , d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>335</td>\n",
       "      <td>Internet</td>\n",
       "      <td>488</td>\n",
       "      <td>Der Begriff Over-the-top content ( OTT ) bezei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>336</td>\n",
       "      <td>Internet</td>\n",
       "      <td>359</td>\n",
       "      <td>Pandanet ( ursprünglich und manchmal auch als ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>337</td>\n",
       "      <td>Internet</td>\n",
       "      <td>1123</td>\n",
       "      <td>Eine Pennyauktion ist eine Onlineversion der A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>338</td>\n",
       "      <td>Internet</td>\n",
       "      <td>1648</td>\n",
       "      <td>Ein Schachserver ( engl . Internet chess serve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>339</td>\n",
       "      <td>Internet</td>\n",
       "      <td>564</td>\n",
       "      <td>Shibboleth ist ein vom Internet2/MACE entwicke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>340</td>\n",
       "      <td>Internet</td>\n",
       "      <td>259</td>\n",
       "      <td>Sighter ist ein dem Geocaching ähnliches Schni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>341</td>\n",
       "      <td>Internet</td>\n",
       "      <td>819</td>\n",
       "      <td>Ein Social Intranet ist eine Softwareplattform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>342</td>\n",
       "      <td>Internet</td>\n",
       "      <td>182</td>\n",
       "      <td>Soribada ( koreanisch  'Ton herunterladen ' ) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>343</td>\n",
       "      <td>Internet</td>\n",
       "      <td>766</td>\n",
       "      <td>Streetspotr ist eine Plattform für standortbas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>344</td>\n",
       "      <td>Internet</td>\n",
       "      <td>158</td>\n",
       "      <td>The Real News ist ein globaler Online-Videonac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>333</td>\n",
       "      <td>Internet</td>\n",
       "      <td>930</td>\n",
       "      <td>OnLive war eine interaktive Kompressionsmethod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>290</td>\n",
       "      <td>Internet</td>\n",
       "      <td>396</td>\n",
       "      <td>Clickjacking ist eine Technik , bei der ein Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                      category  length  \\\n",
       "0    2646  Computerspiel nach Plattform     353   \n",
       "1    2644  Computerspiel nach Plattform     379   \n",
       "2    2645  Computerspiel nach Plattform     415   \n",
       "3    2647  Computerspiel nach Plattform     417   \n",
       "4    2652  Computerspiel nach Plattform     359   \n",
       "5    2649  Computerspiel nach Plattform     445   \n",
       "6    2650  Computerspiel nach Plattform    1188   \n",
       "7    2651  Computerspiel nach Plattform    1008   \n",
       "8    2643  Computerspiel nach Plattform     344   \n",
       "9    2648  Computerspiel nach Plattform    1338   \n",
       "10   2642  Computerspiel nach Plattform     870   \n",
       "11   2630  Computerspiel nach Plattform     374   \n",
       "12   2640  Computerspiel nach Plattform     139   \n",
       "13   2639  Computerspiel nach Plattform     318   \n",
       "14   2638  Computerspiel nach Plattform     685   \n",
       "15   2637  Computerspiel nach Plattform     254   \n",
       "16   2636  Computerspiel nach Plattform    1171   \n",
       "17   2635  Computerspiel nach Plattform     670   \n",
       "18   2634  Computerspiel nach Plattform     408   \n",
       "19   2633  Computerspiel nach Plattform    1323   \n",
       "20   2632  Computerspiel nach Plattform     575   \n",
       "21   2631  Computerspiel nach Plattform     390   \n",
       "22   2629  Computerspiel nach Plattform     391   \n",
       "23   2641  Computerspiel nach Plattform     425   \n",
       "24   2653  Computerspiel nach Plattform     874   \n",
       "25   2665  Computerspiel nach Plattform     410   \n",
       "26   2655  Computerspiel nach Plattform     612   \n",
       "27   2680  Computerspiel nach Plattform    2246   \n",
       "28   2679  Computerspiel nach Plattform     508   \n",
       "29   2678  Computerspiel nach Plattform     351   \n",
       "..    ...                           ...     ...   \n",
       "370   248                      Internet     120   \n",
       "371   436                      Internet     121   \n",
       "372   289                      Internet     205   \n",
       "373   291                      Internet    1065   \n",
       "374   321                      Internet     412   \n",
       "375   322                      Internet    2279   \n",
       "376   323                      Internet    1105   \n",
       "377   324                      Internet    1646   \n",
       "378   325                      Internet     548   \n",
       "379   326                      Internet    1607   \n",
       "380   327                      Internet    2147   \n",
       "381   328                      Internet     295   \n",
       "382   329                      Internet     676   \n",
       "383   330                      Internet    1922   \n",
       "384   331                      Internet     454   \n",
       "385   320                      Internet    1286   \n",
       "386   332                      Internet     326   \n",
       "387   334                      Internet     410   \n",
       "388   335                      Internet     488   \n",
       "389   336                      Internet     359   \n",
       "390   337                      Internet    1123   \n",
       "391   338                      Internet    1648   \n",
       "392   339                      Internet     564   \n",
       "393   340                      Internet     259   \n",
       "394   341                      Internet     819   \n",
       "395   342                      Internet     182   \n",
       "396   343                      Internet     766   \n",
       "397   344                      Internet     158   \n",
       "398   333                      Internet     930   \n",
       "399   290                      Internet     396   \n",
       "\n",
       "                                                  text  \n",
       "0    Ballyhoo ist ein Computerspiel der US-amerikan...  \n",
       "1    Balance of Power ist ein Computer-Strategiespi...  \n",
       "2    Ballblazer ist ein Zweispieler-Computer-Sports...  \n",
       "3    Barbarian : The Ultimate Warrior und Barbarian...  \n",
       "4    Beyond Zork ( kompletter Titel Beyond Zork : T...  \n",
       "5    BattleTech : The Crescent Hawk ' s Inception i...  \n",
       "6    Battletoads ist ein Videospiel des Spieleentwi...  \n",
       "7    Beneath a Steel Sky ( Deutsch etwa \" Unter ein...  \n",
       "8    Badlands ist ein Arcadespiel , das Atari Games...  \n",
       "9    Battle Isle ist eine Reihe von rundenbasierten...  \n",
       "10   Bad Dudes ist ein Arcade-Spiel aus dem Jahr 19...  \n",
       "11   Amberstar ist ein von der Firma Thalion Softwa...  \n",
       "12   Aufschwung Ost ist ein Computerspiel im Stil v...  \n",
       "13   Atomino ist ein Puzzle-Computerspiel von Blue ...  \n",
       "14   Arthur : The Quest for Excalibur ist ein Texta...  \n",
       "15   Arkanoid ist ein Computerspiel des Unternehmen...  \n",
       "16   Archon : The Light and the Dark ist ein 1983 e...  \n",
       "17   Die Arche des Captain Blood ( frz . Originalti...  \n",
       "18   Apidya ist ein horizontal scrollendes Shoot ' ...  \n",
       "19   Another World ( US-Titel : Out of this World )...  \n",
       "20   Angband ist ein Rogue-ähnliches Computer-Rolle...  \n",
       "21   Ancient Domains of Mystery ( kurz ADOM ) ist e...  \n",
       "22   Ambermoon ist ein Rollenspiel der Firma Thalio...  \n",
       "23   Die Rituale der Azteken ( engl . Originaltitel...  \n",
       "24   Biing ! - Sex , Intrigen und Skalpelle ist ein...  \n",
       "25   Budokan - The Martial Spirit ist ein Kampfspor...  \n",
       "26   The Black Cauldron ist ein Adventurespiel des ...  \n",
       "27   Civilization ist ein 1991 erschienenes Compute...  \n",
       "28   City Bomber ist ein frühes Computerspiel für H...  \n",
       "29   Christoph Kolumbus ist ein von Software 2000 e...  \n",
       "..                                                 ...  \n",
       "370  Das CSNET ( Computer Science Network ) war ein...  \n",
       "371  Cloudevo ist eine Software , die verschiedene ...  \n",
       "372  Click-to-call ( CTC ) ist ein Verfahren , welc...  \n",
       "373  Club Penguin war ein Browserspiel ( MMORPG ) f...  \n",
       "374  Eine Netzgeschichte ( engl . netstory ) oder a...  \n",
       "375  Netzkunst ist ein Sammelbegriff für künstleris...  \n",
       "376  Als Newsletter [ njuzlt ] ( engl . für Mitteil...  \n",
       "377  Ning ist eine Online-Plattform zur Erstellung ...  \n",
       "378  Die Online-Beratung gegen Rechtsextremismus is...  \n",
       "379  Online-Journalismus ( auch Onlinejournalismus ...  \n",
       "380  Ein Online-Musikdienst ( auch Musikportal gena...  \n",
       "381  Eine Online-Pressemitteilung ist eine Pressemi...  \n",
       "382  Online-Rechtsberatung ist eine neuere Form der...  \n",
       "383  Der Begriff Onlineberatung ( auch : Internetbe...  \n",
       "384  Als Online-Publikationen oder Netzpublikatione...  \n",
       "385  Netcat , auch nc genannt , ist ein einfaches W...  \n",
       "386  Onlinespiele ( häufig auch bekannt als Interne...  \n",
       "387  OpenLDAP ist eine Implementierung des LDAP , d...  \n",
       "388  Der Begriff Over-the-top content ( OTT ) bezei...  \n",
       "389  Pandanet ( ursprünglich und manchmal auch als ...  \n",
       "390  Eine Pennyauktion ist eine Onlineversion der A...  \n",
       "391  Ein Schachserver ( engl . Internet chess serve...  \n",
       "392  Shibboleth ist ein vom Internet2/MACE entwicke...  \n",
       "393  Sighter ist ein dem Geocaching ähnliches Schni...  \n",
       "394  Ein Social Intranet ist eine Softwareplattform...  \n",
       "395  Soribada ( koreanisch  'Ton herunterladen ' ) ...  \n",
       "396  Streetspotr ist eine Plattform für standortbas...  \n",
       "397  The Real News ist ein globaler Online-Videonac...  \n",
       "398  OnLive war eine interaktive Kompressionsmethod...  \n",
       "399  Clickjacking ist eine Technik , bei der ein Co...  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_computer = corpus[corpus.category == \"Computerspiel nach Plattform\"]\n",
    "corpus_internet = corpus[corpus.category == \"Internet\"]\n",
    "tinycorpus = corpus_computer.append(corpus_internet, ignore_index=True)\n",
    "tinycorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufteilung in Trainings- und Testdatensätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein wichtige Veränderung ist hier die Umwandlung der Sparse Matrix `vector` in eine Dense Matrix. Dies erfolgt mit `toarray()`. Ohne diese würde das Neuronale Netz nicht arbeiten können (der erste Fehler würde schon bei der Implementierung der Sigmoid-Funktion erfolgen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = LabelEncoder().fit_transform(tinycorpus[\"category\"])\n",
    "vector  = TfidfVectorizer().fit_transform(tinycorpus[\"text\"]).toarray()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Umformung der Trainingsdatensätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eines der häufigsten Fehler, die bei der Arbeit mit Neuronalen Netzen gemacht wird, ist die falsche Benutzung von Matrix- und Vektordimensionen. Schauen wir uns die Dimensionen der Trainings- und Testdatensätze an. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 31654)\n",
      "(80, 31654)\n",
      "(320,)\n",
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X_train` hat die Dimension `(320, 31654)`. Diese hat die Form `(n,m)`, wobei `n` für die Anzahl der Zeilen und `m` für die Anzahl der Spalten steht. Die Matrix hat also 320 Zeilen und 31654 Spalten. Um unser Modell nutzen zu können, muss jede Spalte einen Datensatz repräsentieren. Bis jetzt repräsentiert jedoch die Zeilen einen Datensatz, weshalb wir die Matrix <u>transponieren</u> (= Zeilen werden zu Spalten und umgekehrt) müssen. Dies können wir mit `.T` machen. Da die Testdatensätze eindimensionale Matrizen, also Vektoren sind, müssen wir diese nicht transponieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31654, 320)\n",
      "(31654, 80)\n",
      "(320,)\n",
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ?.3. Implementierung des Neuronalen Netzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden nun Logistic Regression als simples Neuronales Netz mit numpy implementieren. Dazu brauchen wir nur fünf Funktionen. Diese werden ausführlich erklärt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?.3.1. Die Sigmoid-Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir in Kapitel 6 gesehen haben, basiert Logistic Regression auf der <b>Sigmoid-Funktion</b> (oder <b>Logistische Funktion</b>). Diese wandelt jeden Eingabewert in eine Zahl zwischen 0 und 1 um.<br>\n",
    "\n",
    "$ f(x) = \\frac{1}{1\\ +\\ e^{-x}}$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999546021312976\n",
      "0.5002499999791666\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(10))\n",
    "print(sigmoid(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Implementation ist ziemlich simpel. Bereits hier zeigt sich jedoch, wieso wir die Daten gerne als Dense-Matrix vorliegen hätten. Versuchen wir nun einmal, die Daten als Sparse Matrix zu übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "exp not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-5616ccd47d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msparse_vector\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtinycorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-b683d5dd8fa4>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: exp not found"
     ]
    }
   ],
   "source": [
    "sparse_vector  = TfidfVectorizer().fit_transform(tinycorpus[\"text\"])\n",
    "sigmoid(sparse_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten eine Fehlermeldung, da die numpy-Funktion `exp` nicht mit Sparse Matrizen arbeiten kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?.3.2. Parameterinitalisierung mit Nullen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes müssen wir die Parameter `w` und `b` mit Nullen initalisieren. Dafür müssen wir jedoch zunächst klären, was `w` und `b` überhaupt sind. Schauen wir uns noch einmal die Formel für Logistic Regression aus Kapitel 6 an:<br>\n",
    "\n",
    "$ y = \\frac{e^{(B0\\ +\\ B1 \\cdot x)}}{1\\ +\\ e^{(B0\\ +\\ B1 \\cdot x)}}$<br>\n",
    "\n",
    "Diese Formel ist eine Erweiterung der Formel für <b>Linear Regression</b>, die folgendermaßen aussieht:<br>\n",
    "\n",
    "$ y = B0 + B1 \\cdot x $<br>\n",
    "\n",
    "$y$ war der Output, der vorausgesagt werden soll und $x$ der Input. $B0$ war der Bias Koeffizient und $B1$ der Koeffizient für $x$. Diese Formel kann auch etwas anders geschrieben werden:<br>\n",
    "\n",
    "$ y = w^T \\cdot x\\ +\\ b $<br>\n",
    "\n",
    "$b$ ist hier der Biaskoeffizient $B0$. $B1$ wird durch eine transponierte Gewichtsmatrix $w$ repräsentiert. Wie in Kapitel 6 sind diese Koeffizienten die Werte, die vom unseren Modell erlernt werden. In Kapitel 6 hatten wir diesen Lernprozess ausgeblendet, in diesem Kapitel werden wir genauer auf ihn eingehen, doch dazu später mehr (AF?). Die Formel ist nun aber die Formel für die Lineare Regression. Die Formel für die Logistic Regression sieht folgendermaßen aus:<br>\n",
    "\n",
    "$ y = \\frac{e^{(w^T \\cdot x\\ +\\ b)}}{1\\ +\\ e^{(w^T \\cdot x\\ +\\ b)}}$<br>\n",
    "\n",
    "\n",
    "Etwas allgemeiner können wir die Formel folgendermaßen formulieren ($\\sigma$ steht für Sigmoid-Funktion):<br>\n",
    "\n",
    "$ y = \\sigma(w^T \\cdot x\\ +\\ b) $<br>\n",
    "\n",
    "$\\sigma$ ist eine sogenannten <b>Aktivierungsfunktion</b>. Neben der Sigmoid-Funktion hatten wir noch die <b>Softmax-Funktion</b> als Aktivierungsfunktion für <b>Multinomial Logistic Regression</b> kennengelernt. Noch allgemeiner könnten wir die Funktion folgendermaßen schreiben, wobei $a$ für eine beliebige Aktivierungsfunktion steht.\n",
    "\n",
    "$ y = a(w^T \\cdot x\\ +\\ b) $<br>\n",
    "\n",
    "Diese Formel wird in jedem Neuron unseres Neuronalen Netzwerks angewendet. Graphisch können wir uns das folgendermaßen vorstellen, wobei $a$ die Aktivierungsfunktion ist und $y$ die Funktion:\n",
    "\n",
    "<img src=\"tutorialdata/img/nn4_2_edit.png\" alt=\"Neural Network with 2 layers and Neuron labeling\" align=\"center\" width=\"600px;\"><br>\n",
    "\n",
    "`w` und `b` sind also Koeffizienten, die mithilfe eines Neuronalen Netzes erlernt werden. Jedoch müssen wir mit irgendwelchen Werten beginnen, weshalb wir sie hier mit Nullen initalisieren. `b` können wir dabei einfach gleich Null setzen, da bei ein Skalar (= einzelner Wert) ist. `w` ist jedoch kein Skalar, sondern ein Vektor, dessen Länge bzw. Dimension wir mit `dim` angeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros(shape=(dim, 1))\n",
    "    b = 0\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(initialize_with_zeros(320))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden später dieser Funktion `dim = 320` übergeben, da wir für jeden Trainingsdatensatz einen Eintrag mit einer Null erstellen wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize_with_zeros(320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?.3.3. Forward und Backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun haben wir unsere Gewichte `w` und `b` initalisiert. Diese müssen jedoch angepasst werden, damit unser Modell sinnvolle Repräsentation liefert. Würden wir sie nicht verändern, würden unsere Ergebnisse immer gleich bleiben und unser Modell wäre sinnlos. Das Modell muss die Gewichte `w` und `b` also <u>lernen</u>. Dieses findet in der sogenannten <b>Trainingsschleife</b> (englisch: training loop) statt. Diese lässt sich am beste mit der folgenden Grafik beschreiben:<br>\n",
    "\n",
    "<img src=\"tutorialdata/img/neuronal_network.png\" alt=\"Neuronal network\" align=\"center\" width=\"300px;\"><br><div style=\"text-align: center; font-size:10px;\">CHOLLET, Francois, Deep Learning mit Python und Keras, übers. von Knut LORENZEN, New York 2018, S. 31.</div></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst geben wir unsere Daten ein (<b>Eingabe X</b>). Dies ist eine Matrix, bei der jede Spalte für ein Trainingsbeispiel steht. In unserem Fall sind die 320 Spalten für 320 Trainingsbeispiele. Unser Input Layer hat also 320 Dimension, also auch 320 Neuronen. Nun bestimmten wir `w` und `b`, am Anfang noch mit Nullen oder zufälligen Werten. Das Ergebnis ist die Funktion $y$. Diese leiten wir an unsere Neuronen weiter, wo sie in eine Aktivierungsfunktion gesteckt(?) werden. Das können wir hier sehen:<br>\n",
    "<img src=\"tutorialdata/img/nn4_2_edit.png\" alt=\"Neural Network with 2 layers and Neuron labeling\" align=\"center\" width=\"400px;\">\n",
    "\n",
    "Am Ende dieses Durchlaufs erhalten wir eine Voraussage $\\hat{Y}$ (bis jetzt nannten wir dies `y_pred`). Stimmt diese mit den tatsächlichen Label $Y$ überein, hat unser Modell das Label richtig vorausgesagt. Zu Beginn ist es jedoch sehr unwahrscheinlich, dass unser Modell mit zufälligen Gewichten oder Gewichten bestehend aus Nullen das richtige Label voraussagt. Wir müssen also berechnen, wie sehr das Modell mit der Voraussage falsch gelegen hat. Dies wird mit der <b>Loss Function</b> (deutsch: <b>Verlustfunktion</b>) berechnet. Eine Loss Function berechnet jedoch nur den <b>Loss score</b> (deutsch: Verlustscore) von einem einzigen Trainingsbeispiel. Um die Loss scores aller Trainingsbeispiele zu berechnen, brauchen wir eine <b>Cost Function</b>, die den Durschnitt aller Loss scores für den gesamten Trainingsdatensatz berechnet.<br> Dieser gesamte Schritt wird <b>Forward Propagation</b> gennant. Eine gute Visualisierung bietet diese <a href=\"https://www.youtube.com/watch?v=UJwK6jAStmg\">Video</a>.<br>\n",
    "\n",
    "Anhand des Loss scores können nun die Koeffizienten `w` und `b` aktualisiert werden. Diesen Vorgang nennt man <b>Backward Propagation</b>. Wie genau diese Backward Propagation funktioniert, wird in Chollets Buch Kapiteln 2.4.1 - 2.4.4 sehr gut erklärt. MEHR STEIGUNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun jedoch zur Funktion `propagate`. Sie nimmt als Input die Gewichtsmatrix `w`, den Biaskoeffizienten `b`, die Trainingsdaten `X_train` und die Trainingslabel `Y_train`. Wir bestimmten zunächst die Anzahl der Trainingsbeispiele `m`. Danach berechnen wir die Aktivierungsfunktion `A`. Nach dem ersten Aufruf sind die Matrix `A` folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = initialize_with_zeros(X_train.shape[0])\n",
    "A = sigmoid(np.dot(w.T, X_train) + b)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir brauchen nun also eine Cost Function, die den Loss score für alle Trainingsbeispiele berechnet. Die Auswahl der Loss Function bzw. der Cost Function hängt von der jeweiligen Klassifizierung ab:\n",
    "- <b>binary cross entropy</b> für binäre Klassifizierung\n",
    "- <b>cross entropy</b> für Multiclass Klassifizierung\n",
    "\n",
    "Da wir hier eine binäre Klassifikation durchführen, verwenden wir die <b>binary cross entropy</b>. Die Formel dafür lautet: <br>\n",
    "\n",
    "$ \\text{binary cross entropy} = - (y\\ \\cdot log(\\hat{y}) + (1−y)\\ \\cdot log(1−\\hat{y}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Aufgabe:</b> Cross entropy\n",
    "    \n",
    "Cross entropy ist uns in einer anderen Form bereits in Kapitel 6 begegnet und zwar in Form der <b>Maximum likehood estimation</b>-Methode. Lesen Sie den <a href=\"https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/\">Blog-Eintrag</a> von Jason Brownlee zu <b>Cross entropy</b>. Schauen Sie sich danach die Formel für <b>binary cross entropy</b> an:<br>\n",
    "    \n",
    "$ \\text{binary cross entropy} = - (y\\ \\cdot log(\\hat{y}) + (1−y)\\ \\cdot log(1−\\hat{y}))$<br>\n",
    "\n",
    "$y$: das wahre Label<br>\n",
    "$\\hat{y}$: das vorgesagte Label<br>\n",
    "\n",
    "Setzen Sie folgende Werte für $y$ und $\\text{y}$ ein. Was beobachten Sie? Gehen Sie davon aus, dass $log(0)$ berechnet werden kann und $log(0) = -14$. <i>Tipp</i>: $log(1) = 0$.<br>\n",
    "\n",
    "a) $y = 0$; $\\hat{y} = 0$<br>\n",
    "b) $y = 1$; $\\hat{y} = 1$<br>\n",
    "c) $y = 0$; $\\hat{y} = 1$<br>\n",
    "d) $y = 1$; $\\hat{y} = 0$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Loss Function für binary cross entropy ist:<br>\n",
    "\n",
    "$ L(\\hat{y}, y) = - (y\\ \\cdot log(\\hat{y}) + (1−y)\\ \\cdot log(1−\\hat{y}))$.<br><br>\n",
    "\n",
    "Die Formel für die Cost Function ist:<br>\n",
    "\n",
    "$ J(w, b) = -\\frac{1}{m} \\sum_{i=1}^m \\cdot\\ L(\\hat{y}, y) \\\\ \n",
    "= -\\frac{1}{m} \\sum_{i=1}^m \\cdot\\ (y^{(i)}\\ \\cdot log(\\hat{y}^{(i)}) + (1−y^{(i)})\\ \\cdot log(1−\\hat{y}^{(i)}))$.<br><br>\n",
    "\n",
    "Diese wird in der Funktion `propagate` in der Variable `cost` gespeichert. (TODO np.squeeze?) Damit sind wir mit der Forward Propagation fertig. Nun implementieren wir die partielle Ableitungen für `w` und `b` (TODO: warum nicht genauer!). Die Formeln dafür lauten folgendermaßen:<br>\n",
    "\n",
    "\n",
    "$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}\\text{X_train}\\ \\cdot(A-\\text{Y_train})^T$<br>\n",
    "\n",
    "$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m \\cdot\\ (a^{(i)}-y^{(i)})$<br>\n",
    "\n",
    "Diese speichern wir im Dictionary `grads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X_train, Y_train):\n",
    "   \n",
    "    # m: Anzahl der Trainingsbeispiele\n",
    "    m = X_train.shape[1]\n",
    "    \n",
    "    ### Forward Propagation ###\n",
    "    \n",
    "    # Aktivierungsfunktion / Formel für Logistic Regression\n",
    "    A = sigmoid(np.dot(w.T, X_train) + b) \n",
    "    \n",
    "    # Cost Function\n",
    "    cost = (- 1 / m) * np.sum(Y_train * np.log(A) + (1 - Y_train) * (np.log(1 - A)))\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    \n",
    "    ### Backward Propagation ###\n",
    "    \n",
    "    dw = (1 / m) * np.dot(X_train, (A - Y_train).T)\n",
    "    db = (1 / m) * np.sum(A - Y_train)\n",
    "\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?.3.4. Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben nun mit `propagate` eine Funktion implementiert, die Forward und Backward Propagation implementiert. Jetzt müssen wir die `optimize` Funktion implementieren, die für mehrere Dinge verantwortlich ist:\n",
    "- Optimieren über mehrere Iterationen (durch `num_iterations`). Eine Iteration ist ein Durchlaufen der Trainingsschleife.\n",
    "- Aktualisierung von `w` und `b` mithilfe einer <b>Learning Rate</b> (deutsch: Lernrate). Diese Learning Rate ist ein Hyperparameter, der angibt, wie sehr wir die Gewichtsmatrix `w` und den Bias-Koeffizienten `b` in unserem Neuronalen Netz anpassen wollen.\n",
    "- Dokumentation des Cost-Wertes alle hundert Iterationen.\n",
    "- Ausgabe des Cost-Wertes alle hundert Trainingsbeispiele. Dies kann über `print_cost` gesteuert und \"abgeschaltet\" werden.\n",
    "- Speicherung von `w` und `b` in einem Parameter-Dictionary `params`, nachdem die Iterationen abgeschlossen sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False):\n",
    "\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        grads, cost = propagate(w, b, X_train, Y_train)\n",
    "\n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        \n",
    "        # Aktualisierung von w und b\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        # Dokumentiert die costs in einer Liste\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Bei jedem 100ten Trainingsbeispiel wird die cost ausgegeben\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?.3.5. Voraussage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt muss noch eine `predict`-Funktion implementiert werden, die wie die `predict`-Funktion von <b>Scikit learn</b> funktioniert. Wie Voraussagen mithilfe von Logistic Regression berechnet werden, hatten wir uns bereits in Kapitel 6.3.2 angeschaut. Alle Werte unserer Matrix `A`, die größer als $0.5$ sind, werden zu einer $1$ umgewandelt und alle anderen Werte zu einer $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X_train):\n",
    "    \n",
    "    m = X_train.shape[1]\n",
    "    y_pred = np.zeros((1, m))\n",
    "    w = w.reshape(X_train.shape[0], 1)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X_train) + b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        y_pred[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "    \n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?.3.6. Das Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt werden alle Funktionen zusammengeführt in der Funktion `lr_model` zusammengeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    model = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.660603\n",
      "Cost after iteration 200: 0.630567\n",
      "Cost after iteration 300: 0.602745\n",
      "Cost after iteration 400: 0.576946\n",
      "Cost after iteration 500: 0.552993\n",
      "Cost after iteration 600: 0.530725\n",
      "Cost after iteration 700: 0.509992\n",
      "Cost after iteration 800: 0.490660\n",
      "Cost after iteration 900: 0.472607\n",
      "Cost after iteration 1000: 0.455722\n",
      "Cost after iteration 1100: 0.439904\n",
      "Cost after iteration 1200: 0.425065\n",
      "Cost after iteration 1300: 0.411122\n",
      "Cost after iteration 1400: 0.398001\n",
      "Cost after iteration 1500: 0.385638\n",
      "Cost after iteration 1600: 0.373970\n",
      "Cost after iteration 1700: 0.362945\n",
      "Cost after iteration 1800: 0.352514\n",
      "Cost after iteration 1900: 0.342631\n",
      "train accuracy: 99.6875 %\n",
      "test accuracy: 98.75 %\n"
     ]
    }
   ],
   "source": [
    "model = lr_model(X_train, \n",
    "          y_train, \n",
    "          X_test, \n",
    "          y_test, \n",
    "          num_iterations = 2000, \n",
    "          learning_rate = 0.1, \n",
    "          print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun visualisieren wir den Lernverlauf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Iterations (pro Hunderte)')\n",
    "plt.title(\"Learning rate = \" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umso länger wir trainierten, umso geringer wurde der Cost score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Aufgabe:</b> Anspassung der Learning Rate und Iterationenanzahl\n",
    "    \n",
    "Probieren Sie Werte für die Learning Rate aus und passen sie die Iterationenanzahl beliebig an. Visualiseren Sie für jede Anpassung und vergleichen Sie die Graphen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ?.? Mögliche Fehler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fehlercode mit \"sparse\" in der Beschreibung → Daten wurden nicht mithilfe von `toarray()` in eine Dense Matrix transformiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
