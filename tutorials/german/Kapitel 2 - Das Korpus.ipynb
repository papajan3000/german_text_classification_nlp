{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 2 - Das Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Relevanz von Korpus\n",
    "\n",
    "Quelle: https://monkeylearn.com/text-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Klassifikation kann nur durchgeführt werden, wenn man Daten zur Verfügung hat, die man klassifizieren möchte. Das braucht man mindestens zwei Dinge: Einen Text und die Klasse dieses Textes. Eine Klasse kann alles mögliche sein, zum Beispiel ... oder die Bewertung eines Films basiernd auf einer Rezension.<br> Hier ein Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Note</th>\n",
       "      <th>Rezension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dieser Film war so genial!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>6</td>\n",
       "      <td>Schlechtester Film aller Zeiten!!!!1!!!1!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>3</td>\n",
       "      <td>Er war schon okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ich will den Film für den Rest meines Lebens j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r5</th>\n",
       "      <td>2</td>\n",
       "      <td>Richtig guter Film mit kleineren Schwächen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r6</th>\n",
       "      <td>4</td>\n",
       "      <td>Naja, gibt besseres, aber auch schlechteres, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r7</th>\n",
       "      <td>5</td>\n",
       "      <td>Bis auf die Songauswahl war der Film zum Kotzen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Note                                          Rezension\n",
       "r1     1                         Dieser Film war so genial!\n",
       "r2     6         Schlechtester Film aller Zeiten!!!!1!!!1!!\n",
       "r3     3                                  Er war schon okay\n",
       "r4     1  Ich will den Film für den Rest meines Lebens j...\n",
       "r5     2         Richtig guter Film mit kleineren Schwächen\n",
       "r6     4  Naja, gibt besseres, aber auch schlechteres, w...\n",
       "r7     5    Bis auf die Songauswahl war der Film zum Kotzen"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"r1\": [1, \"Dieser Film war so genial!\"], \n",
    "     \"r2\": [6, \"Schlechtester Film aller Zeiten!!!!1!!!1!!\"],\n",
    "     \"r3\": [3, \"Er war schon okay\"],\n",
    "     \"r4\": [1, \"Ich will den Film für den Rest meines Lebens jeden Tag gucken :O\"],\n",
    "     \"r5\": [2, \"Richtig guter Film mit kleineren Schwächen\"],\n",
    "     \"r6\": [4, \"Naja, gibt besseres, aber auch schlechteres, wenn auch nicht viel...\"],\n",
    "     \"r7\": [5, \"Bis auf die Songauswahl war der Film zum Kotzen\"]}\n",
    "df = pd.DataFrame.from_dict(d, orient=\"index\", columns=[\"Note\", \"Rezension\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Datensatz ist nicht besonders groß. Eine Textklassifizierung wäre hier nicht nötig, da dies von Menschen schneller erledigt werden kann. Interessant wird es jedoch, wenn die Datensätze größer werden. Dort können durch Textklassifizierungs-Verfahren automatisch neue Texte Klassen zugeordnet werden, basiernd auf Datensätze, die ein Modell zuvor gelernt hat (AF). Dazu brauch man jedoch einen Datensatz. Dies ist oft ein schwieriger Punkt, vor allem in der deutschen Sprache, da die meisten vorgefertigten Datensätze, die wir für die Textklassifikation nutzen können, nur auf englisch vorliegen. In dieser Tutorial-Reihe werden wir uns einen deutschen Datensatz angucken, den ich selbst erstellt habe. Er ist eine verbesserte Version eines Datensatzes, der im Zuge des \"Word Embeddings\"-Seminars an der Julius-Maximilians-Universität entstanden ist. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbau des Wikipedia-Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um mit Datensätzen zu arbeiten, ist es hilfreich, sich genauer mit dem Datensatz auseinanderzusetzen. Dazu laden wir die ersten paar Einträge des \"wikicorpus.csv\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>length</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fernsehserie nach Staat</td>\n",
       "      <td>107</td>\n",
       "      <td>Tāmar und Schawqīya (arabisch تامر وشوقية, DMG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fernsehserie nach Staat</td>\n",
       "      <td>518</td>\n",
       "      <td>Achtung: Streng geheim! (Originaltitel: Missio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Fernsehserie nach Staat</td>\n",
       "      <td>877</td>\n",
       "      <td>Alien Surfgirls ist eine australische Jugendse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fernsehserie nach Staat</td>\n",
       "      <td>1199</td>\n",
       "      <td>All Saints ist eine australische Fernsehserie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Fernsehserie nach Staat</td>\n",
       "      <td>142</td>\n",
       "      <td>Alle lieben Diggy ist eine australische Zeiche...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 category  length  \\\n",
       "0   0  Fernsehserie nach Staat     107   \n",
       "1   1  Fernsehserie nach Staat     518   \n",
       "2   2  Fernsehserie nach Staat     877   \n",
       "3   3  Fernsehserie nach Staat    1199   \n",
       "4   4  Fernsehserie nach Staat     142   \n",
       "\n",
       "                                                text  \n",
       "0  Tāmar und Schawqīya (arabisch تامر وشوقية, DMG...  \n",
       "1  Achtung: Streng geheim! (Originaltitel: Missio...  \n",
       "2  Alien Surfgirls ist eine australische Jugendse...  \n",
       "3  All Saints ist eine australische Fernsehserie ...  \n",
       "4  Alle lieben Diggy ist eine australische Zeiche...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv(\"tutorialdata/wikicorpus.csv\")\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jede Zeile unseres Datensatz repräsentiert einen Artikel von Wikipedia. Jeder Artikel hat 4 Eigenschaften, repräsentiert durch die Spalten: Eine ID (<b>\"id\"</b>), eine Kategorie (<b>\"category\"</b>, eine Länge (<b>\"length\"</b>) und der Artikel selber (<b>\"text\"</b>\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
