{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 9 - XGBoost & CARTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Kapitelübersicht <a class=\"anchor\" id=\"9-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Bis jetzt hatten wir probabilistische Klassifizierungsverfahren wie Logistic Regression und Naive Bayes sowie die Kernel-Methode SVM kennengelernt. Eine letzte wichtige Art von Klassifizierungsmethoden sind die sogenannten <b>decision trees</b> (= Entscheidungsbäume).\n",
    "\n",
    "<b>Abschnittsübersicht</b><br>\n",
    "\n",
    "[9.1. Kapitelübersicht](#9-1)<br>\n",
    "\n",
    "Am Ende dieses Kapitel werden wir folgende Themen behandelt und/oder vertieft haben:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Decision trees (CARTs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Decision trees</b> (deutsch: Entscheidungsbäume) sind geordnete und gerichtete Bäume und dienen der Darstellung von Entscheidungsregeln. Oft werden diese Verfahren auch als <b>CART</b> (= Classification and Regression Trees) bezeichnet, welches ein Algorithmus für decision trees für Klassifikation und Regression ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exkurs:</b> Baum (Datenstruktur)\n",
    "    \n",
    "<b>Bäume</b> sind Datenstrukturen, mit der sich hierarchische Strukturen abbilden lassen. Sie besitzen <b>Knoten</b> (englisch: nodes) und <b>Kanten</b> (englisch: edges). Der erste Knoten nennt sich <b>Wurzel</b> (englisch: root). In dem folgenden Beispiel ist \"CD\" die Wurzel. Von ihr aus gehen Kanten zu anderen Knoten wie \"Rock\", \"Folk\", \"Jazz\" und \"Klassik\". Untergeordnete Knoten nennt man auch <b>Kindknoten</b> (englisch: child nodes) und übergeordnete Knoten <b>Elternknoten</b> (englisch: parent nodes). \"Rock\", \"Folk\", \"Jazz\" und \"Klassik\" sind die Kindknoten von \"CD\" und \"CD\" ist der Elternknoten von \"Rock\", \"Folk\", \"Jazz\" und \"Klassik\". Die Kindknoten von \"Rock\" nennt man <b>Blätter</b> (englisch: leaves), da diese selbst keine Kindknoten besitzen.<br>\n",
    "\n",
    "<img src=\"https://wvsg.schulen2.regensburg.de/joomla/images/Faecher/Informatik/Informatik_11/Bilder/2_1_Von_der_Liste_zum_Baum/baum_allg.png\" alt=\"Tree\" width=\"450px\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://de.wikipedia.org/wiki/CART_(Algorithmus)\n",
    "- https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/\n",
    "- https://de.wikipedia.org/wiki/Entscheidungsbaum\n",
    "- https://de.wikipedia.org/wiki/Bin%C3%A4rbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Korpus laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufteilung in Trainings- und Testdatensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "labels = LabelEncoder().fit_transform(corpus[\"category\"])\n",
    "vector  = TfidfVectorizer().fit_transform(corpus[\"text\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "classes = corpus[\"category\"].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-improve-machine-learning-results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Aufgabe:</b> XGBoost Paper lesen\n",
    "  \n",
    "Machine Learning ist ein Feld ist, in dem viel geforscht wird und es ständig neue Errungenschaften gibt. Diese Errungenschaften werden in Form von wissenschaftlichen Papers veröffentlicht. Implementierungen wie in Scikit learn erfolgen erst Jahre später, im Falle von XGBoost steht eine direkte Implementierung wie von Verfahren wie Naive Bayes oder Logistic Regression noch aus (Stand: 05.09.2019). Um die aktuellesten Verfahren nutzen zu können, müssen neue Machine Learning Verfahren entweder selbst implementiert werden oder auf noch nicht perfektionierte(?) Implementierungen zurückgegriffen werden. Neben fehlenden Implementierungen ist ein weiteres Problem das Fehlen von Guides oder Tutorials. Deshalb ist das Lesen von wissenschaftlichen Papers und der Umgang mit diesen eine Fähigkeit, die für eine Arbeit im Bereich des Machine Learnings unabdingbar ist.<br>\n",
    "  \n",
    "Lesen Sie zum Einstieg das <a href=\"https://arxiv.org/abs/1603.02754\">Paper</a> zu XGBoost. Versuchen Sie, wichtige Errungenschaften, Details und Formeln nachzuvollziehen und zu verstehen. Machen Sie sich Notizen und schlagen Sie Unbekanntes nach. Lassen Sie sich nicht von den Formeln abschrecken, Sie müssen nicht alles 100% verstehen AF!). Der Vorteil bei diesem Paper ist, dass es sehr verständliche Beispiele bietet.\n",
    "\n",
    "\n",
    "Wenn nicht alles sofort verständlich ist, ist das kein Problem, da die wichtigsten Punkte in diesem Abschnitt nochmal erläutert werden. XGBoost ist aber komplexer als andere Klassifikationsverfahren, weshalb Vorwissen in Form des Papers hilfreich für das Verständnis und die Übung vom Lesen von wissenschaftlichen Papers ist (AF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# XGBoost\n",
    "xgb_classifier = XGBClassifier()\n",
    "xgb = xgb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der F1-score für die Klassifizierung mit XGBoost ist 0.888.\n"
     ]
    }
   ],
   "source": [
    "# F1-score des Testdatensatzes\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "xgb_f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"Der F1-score für die Klassifizierung mit XGBoost ist \"\n",
    "      + f\"{str(np.around(xgb_f1, decimals=3))}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Mittelwert der cross validation bei der  Klassifizierung  mit XGBoost ist 0.873.\n",
      "\n",
      "CPU times: user 35min 48s, sys: 396 ms, total: 35min 49s\n",
      "Wall time: 35min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cross validation des Trainingsdatensatzes\n",
    "xgb_scores = cross_val_score(xgb_classifier, vector, labels, cv=3)\n",
    "xgb_mean = np.mean(xgb_scores)\n",
    "\n",
    "print(\"Der Mittelwert der cross validation bei der  Klassifizierung \" \n",
    "      + f\" mit XGBoost ist {str(np.around(xgb_mean, decimals=3))}.\"\n",
    "      + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Dokumentation: https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- xgboost mit scikit learn: https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n",
    "- xgboost vs sklearn gradient boosting: https://stats.stackexchange.com/questions/282459/xgboost-vs-python-sklearn-gradient-boosted-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICH: kein GridSearch machen, zu langsam (siehe medium \"catboost vs light gbm vs xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
