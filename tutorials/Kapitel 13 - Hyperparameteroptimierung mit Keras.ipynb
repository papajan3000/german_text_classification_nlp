{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 13 - Hyperparameteroptimierung mit Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if gpu is available\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1. Kapitelübersicht <a class=\"anchor\" id=\"13-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "<b>Abschnittsübersicht</b><br>\n",
    "\n",
    "[13.1. Kapitelübersicht](#13-1)<br>\n",
    "\n",
    "\n",
    "Am Ende dieses Kapitel werden wir folgende Themen behandelt und/oder vertieft haben:\n",
    "- Alternativer Aufbau von Neuronalen Netzen in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2. Hyperparameteroptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEHR? Wir befolgen nun den Code des <a href=\"https://github.com/maxpumperla/hyperas\">hyperas-Beispiel</a>, indem wir das Laden des Korpus, das Encoding der Kategorien, die Vektorisierung der Artikel und die Aufteilung in Training-, Validierungs- und Testdatensätze in eine Funktion `data` packen(?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    \n",
    "    corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vector = vectorizer.fit_transform(corpus[\"text\"])\n",
    "    labels = LabelEncoder().fit_transform(corpus[\"category\"])\n",
    "    vocab = vectorizer.vocabulary_\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(vector, \n",
    "                                                            labels, \n",
    "                                                            test_size=0.4, \n",
    "                                                            train_size=0.6,\n",
    "                                                            random_state=42)\n",
    "    X_val = X_test[:1200]\n",
    "    X_test = X_test[1200:]\n",
    "\n",
    "    y_val = y_test[:1200]\n",
    "    y_test = y_test[1200:]\n",
    "\n",
    "    y_val = to_categorical(y_val)\n",
    "    y_test = to_categorical(y_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun definieren wir eine Funktion `create_model`, in der unser Neuronales Netz steht(?). Der Aufbau ist etwas anders, als wir es im letzten Kapitel gesehen haben (AF?). Die Aktivierungsfunktion definieren wir hier in einer eigenen Zeile, um den Code übersichtlicher zu gestalten. Anstatt die Werte beim Dropout, beim Dense-Layer oder bei der batch-size direkt anzugeben, packen(?) wir verschiedene Werte in eine Liste und ummanteln(?) diese mit `{{choice()}}`. MEHR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICH: persönliche Empfehlung, niedrige Batch size (zu fehlern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperas.distributions import uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "def create_model(X_train, y_train, X_val, y_val, X_test, y_test, vocab, labels):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(Dense({{choice([16, 32, 64])}}, input_shape=(len(vocab),)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([16, 32, 64])}}))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}})) #{{choice([0.2, 0.3])}}\n",
    "              \n",
    "    if {{choice(['three', 'four'])}} == 'four':\n",
    "        model.add(Dense({{choice([16, 32, 64])}}))\n",
    "\n",
    "        model.add(Dropout({{uniform(0, 1)}}))\n",
    "        model.add(Activation('relu'))          \n",
    "              \n",
    "    model.add(Dense(len(np.unique(labels))))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = Adam(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    rmsprop = RMSprop(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    sgd = SGD(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "   \n",
    "    choiceval = {{choice(['adam', 'sgd', 'rmsprop'])}}\n",
    "    \n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    elif choiceval == 'rmsprop':\n",
    "        optim = rmsprop\n",
    "    else:\n",
    "        optim = sgd\n",
    "    \n",
    "\n",
    "    model.compile(optimizer=optim,\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=2)\n",
    "              \n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import models\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import layers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam, RMSprop, SGD\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils.np_utils import to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import regularizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import f1_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [16, 32, 64]),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense_1': hp.choice('Dense_1', [16, 32, 64]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'Dropout_2': hp.choice('Dropout_2', [0.2, 0.3]),\n",
      "        'Dropout_3': hp.choice('Dropout_3', ['three', 'four']),\n",
      "        'Dense_2': hp.choice('Dense_2', [16, 32, 64]),\n",
      "        'Dropout_4': hp.uniform('Dropout_4', 0, 1),\n",
      "        'lr': hp.choice('lr', [10**-3, 10**-2, 10**-1]),\n",
      "        'lr_1': hp.choice('lr_1', [10**-3, 10**-2, 10**-1]),\n",
      "        'lr_2': hp.choice('lr_2', [10**-3, 10**-2, 10**-1]),\n",
      "        'choiceval': hp.choice('choiceval', ['adam', 'sgd', 'rmsprop']),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: \n",
      "  3: corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\")\n",
      "  4: \n",
      "  5: vectorizer = TfidfVectorizer()\n",
      "  6: vector = vectorizer.fit_transform(corpus[\"text\"])\n",
      "  7: labels = LabelEncoder().fit_transform(corpus[\"category\"])\n",
      "  8: vocab = vectorizer.vocabulary_\n",
      "  9: \n",
      " 10: X_train, X_test, y_train, y_test = train_test_split(vector, \n",
      " 11:                                                         labels, \n",
      " 12:                                                         test_size=0.4, \n",
      " 13:                                                         train_size=0.6,\n",
      " 14:                                                         random_state=42)\n",
      " 15: X_val = X_test[:1200]\n",
      " 16: X_test = X_test[1200:]\n",
      " 17: \n",
      " 18: y_val = y_test[:1200]\n",
      " 19: y_test = y_test[1200:]\n",
      " 20: \n",
      " 21: y_val = to_categorical(y_val)\n",
      " 22: y_test = to_categorical(y_test)\n",
      " 23: y_train = to_categorical(y_train)\n",
      " 24: \n",
      " 25: \n",
      " 26: \n",
      " 27: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     model = models.Sequential()\n",
      "   5:     model.add(Dense(space['Dense'], input_shape=(len(vocab),)))\n",
      "   6:     model.add(Activation('relu'))\n",
      "   7:     model.add(Dropout(space['Dropout']))\n",
      "   8:     model.add(Dense(space['Dense_1']))\n",
      "   9:     model.add(Activation('relu'))\n",
      "  10:     model.add(Dropout(space['Dropout_1'])) #space['Dropout_2']\n",
      "  11:               \n",
      "  12:     if space['Dropout_3'] == 'four':\n",
      "  13:         model.add(Dense(space['Dense_2']))\n",
      "  14: \n",
      "  15:         model.add(Dropout(space['Dropout_4']))\n",
      "  16:         model.add(Activation('relu'))          \n",
      "  17:               \n",
      "  18:     model.add(Dense(len(np.unique(labels))))\n",
      "  19:     model.add(Activation('softmax'))\n",
      "  20:     \n",
      "  21:     adam = Adam(lr=space['lr'])\n",
      "  22:     rmsprop = RMSprop(lr=space['lr_1'])\n",
      "  23:     sgd = SGD(lr=space['lr_2'])\n",
      "  24:    \n",
      "  25:     choiceval = space['choiceval']\n",
      "  26:     \n",
      "  27:     if choiceval == 'adam':\n",
      "  28:         optim = adam\n",
      "  29:     elif choiceval == 'rmsprop':\n",
      "  30:         optim = rmsprop\n",
      "  31:     else:\n",
      "  32:         optim = sgd\n",
      "  33:     \n",
      "  34: \n",
      "  35:     model.compile(optimizer=optim,\n",
      "  36:                   loss=\"categorical_crossentropy\",\n",
      "  37:                   metrics=[\"accuracy\"])\n",
      "  38:     \n",
      "  39:     history = model.fit(X_train,\n",
      "  40:                         y_train,\n",
      "  41:                         epochs=50,\n",
      "  42:                         batch_size=32,\n",
      "  43:                         validation_data=(X_val, y_val),\n",
      "  44:                         verbose=2)\n",
      "  45:               \n",
      "  46:     score = model.evaluate(X_test, y_test, verbose=0)\n",
      "  47:     accuracy = score[1]\n",
      "  48:     return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}\n",
      "  49: \n",
      "Train on 3600 samples, validate on 1200 samples     \n",
      "Epoch 1/50                                          \n",
      " - 10s - loss: 3.4010 - acc: 0.0333 - val_loss: 3.3471 - val_acc: 0.0533\n",
      "\n",
      "Epoch 2/50                                          \n",
      " - 9s - loss: 3.3312 - acc: 0.0556 - val_loss: 3.2413 - val_acc: 0.1125\n",
      "\n",
      "Epoch 3/50                                          \n",
      " - 10s - loss: 3.2350 - acc: 0.0756 - val_loss: 3.1630 - val_acc: 0.1483\n",
      "\n",
      "Epoch 4/50                                          \n",
      " - 9s - loss: 3.1583 - acc: 0.0964 - val_loss: 3.1260 - val_acc: 0.1042\n",
      "\n",
      "Epoch 5/50                                          \n",
      " - 9s - loss: 3.1020 - acc: 0.0992 - val_loss: 3.0052 - val_acc: 0.1592\n",
      "\n",
      "Epoch 6/50                                          \n",
      " - 9s - loss: 3.0485 - acc: 0.1069 - val_loss: 2.9523 - val_acc: 0.1617\n",
      "\n",
      "Epoch 7/50                                          \n",
      " - 9s - loss: 2.9981 - acc: 0.1242 - val_loss: 2.9830 - val_acc: 0.1167\n",
      "\n",
      "Epoch 8/50                                          \n",
      " - 9s - loss: 2.9736 - acc: 0.1208 - val_loss: 2.8702 - val_acc: 0.1358\n",
      "\n",
      "Epoch 9/50                                          \n",
      " - 9s - loss: 2.9025 - acc: 0.1417 - val_loss: 2.8592 - val_acc: 0.1167\n",
      "\n",
      "Epoch 10/50                                         \n",
      " - 9s - loss: 2.8981 - acc: 0.1411 - val_loss: 2.8309 - val_acc: 0.1333\n",
      "\n",
      "Epoch 11/50                                         \n",
      " - 9s - loss: 2.8626 - acc: 0.1450 - val_loss: 2.8041 - val_acc: 0.1533\n",
      "\n",
      "Epoch 12/50                                         \n",
      " - 9s - loss: 2.8526 - acc: 0.1533 - val_loss: 2.7470 - val_acc: 0.1608\n",
      "\n",
      "Epoch 13/50                                         \n",
      " - 9s - loss: 2.8531 - acc: 0.1497 - val_loss: 2.7345 - val_acc: 0.1667\n",
      "\n",
      "Epoch 14/50                                         \n",
      " - 9s - loss: 2.8125 - acc: 0.1622 - val_loss: 2.7825 - val_acc: 0.1400\n",
      "\n",
      "Epoch 15/50                                         \n",
      " - 9s - loss: 2.7958 - acc: 0.1631 - val_loss: 2.6802 - val_acc: 0.1708\n",
      "\n",
      "Epoch 16/50                                         \n",
      " - 9s - loss: 2.8556 - acc: 0.1656 - val_loss: 2.7000 - val_acc: 0.1558\n",
      "\n",
      "Epoch 17/50                                         \n",
      " - 9s - loss: 2.7923 - acc: 0.1703 - val_loss: 2.6853 - val_acc: 0.1450\n",
      "\n",
      "Epoch 18/50                                         \n",
      " - 9s - loss: 2.7827 - acc: 0.1697 - val_loss: 2.7233 - val_acc: 0.1475\n",
      "\n",
      "Epoch 19/50                                         \n",
      " - 9s - loss: 2.7698 - acc: 0.1733 - val_loss: 2.6894 - val_acc: 0.1475\n",
      "\n",
      "Epoch 20/50                                         \n",
      " - 9s - loss: 2.8103 - acc: 0.1667 - val_loss: 2.6298 - val_acc: 0.1567\n",
      "\n",
      "Epoch 21/50                                         \n",
      " - 9s - loss: 2.8279 - acc: 0.1700 - val_loss: 2.7005 - val_acc: 0.1517\n",
      "\n",
      "Epoch 22/50                                         \n",
      " - 9s - loss: 2.8133 - acc: 0.1725 - val_loss: 2.6135 - val_acc: 0.1708\n",
      "\n",
      "Epoch 23/50                                         \n",
      " - 9s - loss: 2.7728 - acc: 0.1794 - val_loss: 2.7109 - val_acc: 0.1733\n",
      "\n",
      "Epoch 24/50                                         \n",
      " - 9s - loss: 2.7977 - acc: 0.1833 - val_loss: 2.6090 - val_acc: 0.2092\n",
      "\n",
      "Epoch 25/50                                         \n",
      " - 9s - loss: 2.7966 - acc: 0.1872 - val_loss: 2.5826 - val_acc: 0.2067\n",
      "\n",
      "Epoch 26/50                                         \n",
      " - 9s - loss: 2.7869 - acc: 0.1828 - val_loss: 2.5864 - val_acc: 0.1742\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50                                         \n",
      " - 9s - loss: 2.8479 - acc: 0.1647 - val_loss: 2.5766 - val_acc: 0.2000\n",
      "\n",
      "Epoch 28/50                                         \n",
      " - 9s - loss: 2.8557 - acc: 0.1725 - val_loss: 2.6390 - val_acc: 0.1592\n",
      "\n",
      "Epoch 29/50                                         \n",
      " - 9s - loss: 2.7665 - acc: 0.1794 - val_loss: 2.6068 - val_acc: 0.1683\n",
      "\n",
      "Epoch 30/50                                         \n",
      " - 9s - loss: 2.7724 - acc: 0.1911 - val_loss: 2.6065 - val_acc: 0.1908\n",
      "\n",
      "Epoch 31/50                                         \n",
      " - 9s - loss: 2.7733 - acc: 0.1906 - val_loss: 2.5989 - val_acc: 0.1958\n",
      "\n",
      "Epoch 32/50                                         \n",
      " - 9s - loss: 2.7915 - acc: 0.1853 - val_loss: 2.6226 - val_acc: 0.1733\n",
      "\n",
      "Epoch 33/50                                         \n",
      " - 9s - loss: 2.8185 - acc: 0.1742 - val_loss: 2.6038 - val_acc: 0.1708\n",
      "\n",
      "Epoch 34/50                                         \n",
      " - 9s - loss: 2.8645 - acc: 0.1703 - val_loss: 2.6199 - val_acc: 0.1783\n",
      "\n",
      "Epoch 35/50                                         \n",
      " - 9s - loss: 2.8168 - acc: 0.1833 - val_loss: 2.5950 - val_acc: 0.1800\n",
      "\n",
      "Epoch 36/50                                         \n",
      " - 9s - loss: 2.8068 - acc: 0.1889 - val_loss: 2.5798 - val_acc: 0.1633\n",
      "\n",
      "Epoch 37/50                                         \n",
      " - 9s - loss: 2.8858 - acc: 0.1764 - val_loss: 2.5877 - val_acc: 0.1867\n",
      "\n",
      "Epoch 38/50                                         \n",
      " - 9s - loss: 2.8485 - acc: 0.1850 - val_loss: 2.6421 - val_acc: 0.1650\n",
      "\n",
      "Epoch 39/50                                         \n",
      " - 9s - loss: 2.8507 - acc: 0.1717 - val_loss: 2.5905 - val_acc: 0.1858\n",
      "\n",
      "Epoch 40/50                                         \n",
      " - 9s - loss: 2.8286 - acc: 0.1792 - val_loss: 2.6141 - val_acc: 0.1758\n",
      "\n",
      "Epoch 41/50                                         \n",
      " - 9s - loss: 2.8511 - acc: 0.1844 - val_loss: 2.6622 - val_acc: 0.1808\n",
      "\n",
      "Epoch 42/50                                         \n",
      " - 9s - loss: 2.8626 - acc: 0.1742 - val_loss: 2.7004 - val_acc: 0.1417\n",
      "\n",
      "Epoch 43/50                                         \n",
      " - 9s - loss: 2.8419 - acc: 0.1858 - val_loss: 2.6065 - val_acc: 0.1758\n",
      "\n",
      "Epoch 44/50                                         \n",
      " - 9s - loss: 2.8745 - acc: 0.1686 - val_loss: 2.6000 - val_acc: 0.1725\n",
      "\n",
      "Epoch 45/50                                         \n",
      " - 9s - loss: 2.8744 - acc: 0.1747 - val_loss: 2.5809 - val_acc: 0.1867\n",
      "\n",
      "Epoch 46/50                                         \n",
      " - 9s - loss: 2.8631 - acc: 0.1797 - val_loss: 2.6395 - val_acc: 0.1700\n",
      "\n",
      "Epoch 47/50                                         \n",
      " - 9s - loss: 2.8549 - acc: 0.1850 - val_loss: 2.6595 - val_acc: 0.1767\n",
      "\n",
      "Epoch 48/50                                         \n",
      " - 9s - loss: 2.8712 - acc: 0.1756 - val_loss: 2.6344 - val_acc: 0.1958\n",
      "\n",
      "Epoch 49/50                                         \n",
      " - 9s - loss: 2.7978 - acc: 0.1875 - val_loss: 2.6388 - val_acc: 0.2033\n",
      "\n",
      "Epoch 50/50                                         \n",
      " - 9s - loss: 2.8972 - acc: 0.1714 - val_loss: 2.6241 - val_acc: 0.2008\n",
      "\n",
      "Train on 3600 samples, validate on 1200 samples                                   \n",
      "Epoch 1/50                                                                        \n",
      " - 10s - loss: 3.4054 - acc: 0.0311 - val_loss: 3.4076 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 2/50                                                                        \n",
      " - 10s - loss: 3.4010 - acc: 0.0317 - val_loss: 3.4074 - val_acc: 0.0450          \n",
      "\n",
      "Epoch 3/50                                                                        \n",
      " - 10s - loss: 3.3999 - acc: 0.0361 - val_loss: 3.4078 - val_acc: 0.0492          \n",
      "\n",
      "Epoch 4/50                                                                        \n",
      " - 10s - loss: 3.4011 - acc: 0.0294 - val_loss: 3.4105 - val_acc: 0.0342          \n",
      "\n",
      "Epoch 5/50                                                                        \n",
      " - 10s - loss: 3.4067 - acc: 0.0361 - val_loss: 3.4120 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 6/50                                                                        \n",
      " - 10s - loss: 3.4025 - acc: 0.0347 - val_loss: 3.4131 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 7/50                                                                        \n",
      " - 10s - loss: 3.4013 - acc: 0.0303 - val_loss: 3.4113 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 8/50                                                                        \n",
      " - 10s - loss: 3.4005 - acc: 0.0364 - val_loss: 3.4009 - val_acc: 0.0550          \n",
      "\n",
      "Epoch 9/50                                                                        \n",
      " - 10s - loss: 3.4040 - acc: 0.0292 - val_loss: 3.4100 - val_acc: 0.0358          \n",
      "\n",
      "Epoch 10/50                                                                       \n",
      " - 10s - loss: 3.4019 - acc: 0.0300 - val_loss: 3.4108 - val_acc: 0.0367          \n",
      "\n",
      "Epoch 11/50                                                                       \n",
      " - 10s - loss: 3.3993 - acc: 0.0353 - val_loss: 3.4101 - val_acc: 0.0383          \n",
      "\n",
      "Epoch 12/50                                                                       \n",
      " - 10s - loss: 3.4008 - acc: 0.0358 - val_loss: 3.4092 - val_acc: 0.0392          \n",
      "\n",
      "Epoch 13/50                                                                       \n",
      " - 10s - loss: 3.3994 - acc: 0.0347 - val_loss: 3.4083 - val_acc: 0.0383          \n",
      "\n",
      "Epoch 14/50                                                                       \n",
      " - 10s - loss: 3.3997 - acc: 0.0331 - val_loss: 3.4092 - val_acc: 0.0325          \n",
      "\n",
      "Epoch 15/50                                                                       \n",
      " - 10s - loss: 3.4007 - acc: 0.0306 - val_loss: 3.4096 - val_acc: 0.0333          \n",
      "\n",
      "Epoch 16/50                                                                       \n",
      " - 10s - loss: 3.4016 - acc: 0.0344 - val_loss: 3.4108 - val_acc: 0.0275          \n",
      "\n",
      "Epoch 17/50                                                                       \n",
      " - 10s - loss: 3.4010 - acc: 0.0372 - val_loss: 3.4103 - val_acc: 0.0300          \n",
      "\n",
      "Epoch 18/50                                                                       \n",
      " - 10s - loss: 3.4023 - acc: 0.0347 - val_loss: 3.4101 - val_acc: 0.0425          \n",
      "\n",
      "Epoch 19/50                                                                       \n",
      " - 10s - loss: 3.4020 - acc: 0.0303 - val_loss: 3.4116 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 20/50                                                                       \n",
      " - 10s - loss: 3.4025 - acc: 0.0333 - val_loss: 3.4117 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 21/50                                                                       \n",
      " - 10s - loss: 3.4028 - acc: 0.0300 - val_loss: 3.4113 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 22/50                                                                       \n",
      " - 10s - loss: 3.4027 - acc: 0.0339 - val_loss: 3.4125 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 23/50                                                                       \n",
      " - 10s - loss: 3.4027 - acc: 0.0289 - val_loss: 3.4111 - val_acc: 0.0292          \n",
      "\n",
      "Epoch 24/50                                                                       \n",
      " - 10s - loss: 3.4022 - acc: 0.0339 - val_loss: 3.4111 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 25/50                                                                       \n",
      " - 10s - loss: 3.4029 - acc: 0.0333 - val_loss: 3.4124 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 26/50                                                                       \n",
      " - 10s - loss: 3.4030 - acc: 0.0286 - val_loss: 3.4103 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 27/50                                                                       \n",
      " - 10s - loss: 3.4031 - acc: 0.0317 - val_loss: 3.4119 - val_acc: 0.0292          \n",
      "\n",
      "Epoch 28/50                                                                       \n",
      " - 10s - loss: 3.4025 - acc: 0.0347 - val_loss: 3.4105 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 29/50                                                                       \n",
      " - 10s - loss: 3.4026 - acc: 0.0325 - val_loss: 3.4114 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 30/50                                                                       \n",
      " - 10s - loss: 3.4034 - acc: 0.0333 - val_loss: 3.4116 - val_acc: 0.0258          \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50                                                                       \n",
      " - 10s - loss: 3.4027 - acc: 0.0350 - val_loss: 3.4106 - val_acc: 0.0292          \n",
      "\n",
      "Epoch 32/50                                                                       \n",
      " - 10s - loss: 3.4030 - acc: 0.0314 - val_loss: 3.4106 - val_acc: 0.0217          \n",
      "\n",
      "Epoch 33/50                                                                       \n",
      " - 10s - loss: 3.4029 - acc: 0.0308 - val_loss: 3.4109 - val_acc: 0.0217          \n",
      "\n",
      "Epoch 34/50                                                                       \n",
      " - 10s - loss: 3.4027 - acc: 0.0322 - val_loss: 3.4109 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 35/50                                                                       \n",
      " - 10s - loss: 3.4029 - acc: 0.0303 - val_loss: 3.4106 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 36/50                                                                       \n",
      " - 10s - loss: 3.4026 - acc: 0.0342 - val_loss: 3.4119 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 37/50                                                                       \n",
      " - 10s - loss: 3.4030 - acc: 0.0336 - val_loss: 3.4117 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 38/50                                                                       \n",
      " - 10s - loss: 3.4028 - acc: 0.0347 - val_loss: 3.4117 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 39/50                                                                       \n",
      " - 10s - loss: 3.4030 - acc: 0.0311 - val_loss: 3.4125 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 40/50                                                                       \n",
      " - 10s - loss: 3.4025 - acc: 0.0333 - val_loss: 3.4120 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 41/50                                                                       \n",
      " - 10s - loss: 3.4034 - acc: 0.0311 - val_loss: 3.4118 - val_acc: 0.0217          \n",
      "\n",
      "Epoch 42/50                                                                       \n",
      " - 10s - loss: 3.4021 - acc: 0.0322 - val_loss: 3.4121 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 43/50                                                                       \n",
      " - 10s - loss: 3.4030 - acc: 0.0342 - val_loss: 3.4111 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 44/50                                                                       \n",
      " - 10s - loss: 3.4029 - acc: 0.0336 - val_loss: 3.4108 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 45/50                                                                       \n",
      " - 10s - loss: 3.4028 - acc: 0.0333 - val_loss: 3.4117 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 46/50                                                                       \n",
      " - 10s - loss: 3.4033 - acc: 0.0297 - val_loss: 3.4122 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 47/50                                                                       \n",
      " - 10s - loss: 3.4027 - acc: 0.0303 - val_loss: 3.4112 - val_acc: 0.0217          \n",
      "\n",
      "Epoch 48/50                                                                       \n",
      " - 10s - loss: 3.4032 - acc: 0.0325 - val_loss: 3.4098 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 49/50                                                                       \n",
      " - 10s - loss: 3.4029 - acc: 0.0325 - val_loss: 3.4109 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 50/50                                                                       \n",
      " - 10s - loss: 3.4028 - acc: 0.0328 - val_loss: 3.4117 - val_acc: 0.0258          \n",
      "\n",
      "Train on 3600 samples, validate on 1200 samples                                   \n",
      "Epoch 1/50                                                                        \n",
      " - 12s - loss: 4.9006 - acc: 0.0364 - val_loss: 15.5170 - val_acc: 0.0292         \n",
      "\n",
      "Epoch 2/50                                                                        \n",
      " - 12s - loss: 4.5225 - acc: 0.0322 - val_loss: 15.5589 - val_acc: 0.0292         \n",
      "\n",
      "Epoch 3/50                                                                        \n",
      " - 12s - loss: 4.1080 - acc: 0.0283 - val_loss: 15.5808 - val_acc: 0.0333         \n",
      "\n",
      "Epoch 4/50                                                                        \n",
      " - 12s - loss: 4.1364 - acc: 0.0336 - val_loss: 15.6406 - val_acc: 0.0250         \n",
      "\n",
      "Epoch 5/50                                                                        \n",
      " - 12s - loss: 4.1480 - acc: 0.0289 - val_loss: 15.5808 - val_acc: 0.0333         \n",
      "\n",
      "Epoch 6/50                                                                        \n",
      " - 12s - loss: 4.0714 - acc: 0.0311 - val_loss: 15.5808 - val_acc: 0.0333         \n",
      "\n",
      "Epoch 7/50                                                                        \n",
      " - 12s - loss: 4.0100 - acc: 0.0289 - val_loss: 15.5808 - val_acc: 0.0333         \n",
      "\n",
      "Epoch 8/50                                                                        \n",
      " - 12s - loss: 4.0234 - acc: 0.0356 - val_loss: 15.5808 - val_acc: 0.0333         \n",
      "\n",
      "Epoch 9/50                                                                        \n",
      " - 12s - loss: 4.0000 - acc: 0.0331 - val_loss: 15.5808 - val_acc: 0.0333         \n",
      "\n",
      "Epoch 10/50                                                                       \n",
      " - 12s - loss: 3.9640 - acc: 0.0319 - val_loss: 15.5808 - val_acc: 0.0333         \n",
      "\n",
      "Epoch 11/50                                                                       \n",
      " - 12s - loss: 3.8544 - acc: 0.0325 - val_loss: 3.4325 - val_acc: 0.0267          \n",
      "\n",
      "Epoch 12/50                                                                       \n",
      " - 12s - loss: 3.7327 - acc: 0.0322 - val_loss: 3.4473 - val_acc: 0.0333          \n",
      "\n",
      "Epoch 13/50                                                                       \n",
      " - 12s - loss: 3.7484 - acc: 0.0322 - val_loss: 3.4460 - val_acc: 0.0283          \n",
      "\n",
      "Epoch 14/50                                                                       \n",
      " - 12s - loss: 3.7027 - acc: 0.0333 - val_loss: 3.4381 - val_acc: 0.0267          \n",
      "\n",
      "Epoch 15/50                                                                       \n",
      " - 12s - loss: 3.7215 - acc: 0.0289 - val_loss: 3.4313 - val_acc: 0.0358          \n",
      "\n",
      "Epoch 16/50                                                                       \n",
      " - 12s - loss: 3.8052 - acc: 0.0369 - val_loss: 3.4500 - val_acc: 0.0358          \n",
      "\n",
      "Epoch 17/50                                                                       \n",
      " - 12s - loss: 3.7930 - acc: 0.0336 - val_loss: 3.4377 - val_acc: 0.0292          \n",
      "\n",
      "Epoch 18/50                                                                       \n",
      " - 12s - loss: 3.7734 - acc: 0.0325 - val_loss: 3.4346 - val_acc: 0.0342          \n",
      "\n",
      "Epoch 19/50                                                                       \n",
      " - 12s - loss: 3.8206 - acc: 0.0353 - val_loss: 3.4438 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 20/50                                                                       \n",
      " - 12s - loss: 3.7631 - acc: 0.0297 - val_loss: 3.4426 - val_acc: 0.0350          \n",
      "\n",
      "Epoch 21/50                                                                       \n",
      " - 12s - loss: 3.8000 - acc: 0.0300 - val_loss: 3.4279 - val_acc: 0.0375          \n",
      "\n",
      "Epoch 22/50                                                                       \n",
      " - 12s - loss: 3.7264 - acc: 0.0286 - val_loss: 3.4314 - val_acc: 0.0300          \n",
      "\n",
      "Epoch 23/50                                                                       \n",
      " - 12s - loss: 3.7002 - acc: 0.0350 - val_loss: 3.4456 - val_acc: 0.0408          \n",
      "\n",
      "Epoch 24/50                                                                       \n",
      " - 12s - loss: 3.7312 - acc: 0.0342 - val_loss: 3.4296 - val_acc: 0.0283          \n",
      "\n",
      "Epoch 25/50                                                                       \n",
      " - 12s - loss: 3.6844 - acc: 0.0317 - val_loss: 3.4516 - val_acc: 0.0350          \n",
      "\n",
      "Epoch 26/50                                                                       \n",
      " - 12s - loss: 3.6245 - acc: 0.0333 - val_loss: 3.4405 - val_acc: 0.0367          \n",
      "\n",
      "Epoch 27/50                                                                       \n",
      " - 12s - loss: 3.7667 - acc: 0.0319 - val_loss: 12.4422 - val_acc: 0.0325         \n",
      "\n",
      "Epoch 28/50                                                                       \n",
      " - 12s - loss: 3.7731 - acc: 0.0314 - val_loss: 10.8274 - val_acc: 0.0400         \n",
      "\n",
      "Epoch 29/50                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 3.7427 - acc: 0.0289 - val_loss: 8.2250 - val_acc: 0.0550          \n",
      "\n",
      "Epoch 30/50                                                                       \n",
      " - 12s - loss: 3.6917 - acc: 0.0336 - val_loss: 3.4373 - val_acc: 0.0325          \n",
      "\n",
      "Epoch 31/50                                                                       \n",
      " - 12s - loss: 3.7230 - acc: 0.0364 - val_loss: 3.4233 - val_acc: 0.0342          \n",
      "\n",
      "Epoch 32/50                                                                       \n",
      " - 12s - loss: 3.5637 - acc: 0.0325 - val_loss: 3.4419 - val_acc: 0.0292          \n",
      "\n",
      "Epoch 33/50                                                                       \n",
      " - 12s - loss: 3.5390 - acc: 0.0350 - val_loss: 3.4422 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 34/50                                                                       \n",
      " - 12s - loss: 3.5288 - acc: 0.0342 - val_loss: 3.4515 - val_acc: 0.0300          \n",
      "\n",
      "Epoch 35/50                                                                       \n",
      " - 12s - loss: 3.5905 - acc: 0.0311 - val_loss: 15.4868 - val_acc: 0.0392         \n",
      "\n",
      "Epoch 36/50                                                                       \n",
      " - 12s - loss: 3.6544 - acc: 0.0325 - val_loss: 15.4868 - val_acc: 0.0392         \n",
      "\n",
      "Epoch 37/50                                                                       \n",
      " - 12s - loss: 3.6539 - acc: 0.0333 - val_loss: 15.4868 - val_acc: 0.0392         \n",
      "\n",
      "Epoch 38/50                                                                       \n",
      " - 12s - loss: 3.7768 - acc: 0.0256 - val_loss: 15.4868 - val_acc: 0.0392         \n",
      "\n",
      "Epoch 39/50                                                                       \n",
      " - 12s - loss: 3.6288 - acc: 0.0361 - val_loss: 3.4253 - val_acc: 0.0292          \n",
      "\n",
      "Epoch 40/50                                                                       \n",
      " - 12s - loss: 3.5761 - acc: 0.0303 - val_loss: 3.4367 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 41/50                                                                       \n",
      " - 12s - loss: 3.5871 - acc: 0.0311 - val_loss: 3.4418 - val_acc: 0.0292          \n",
      "\n",
      "Epoch 42/50                                                                       \n",
      " - 12s - loss: 3.6341 - acc: 0.0322 - val_loss: 3.4436 - val_acc: 0.0217          \n",
      "\n",
      "Epoch 43/50                                                                       \n",
      " - 12s - loss: 3.6192 - acc: 0.0317 - val_loss: 3.4302 - val_acc: 0.0258          \n",
      "\n",
      "Epoch 44/50                                                                       \n",
      " - 12s - loss: 3.6807 - acc: 0.0342 - val_loss: 3.4489 - val_acc: 0.0283          \n",
      "\n",
      "Epoch 45/50                                                                       \n",
      " - 12s - loss: 3.6264 - acc: 0.0342 - val_loss: 3.4199 - val_acc: 0.0317          \n",
      "\n",
      "Epoch 46/50                                                                       \n",
      " - 12s - loss: 3.5966 - acc: 0.0339 - val_loss: 3.4176 - val_acc: 0.0342          \n",
      "\n",
      "Epoch 47/50                                                                       \n",
      " - 12s - loss: 3.6694 - acc: 0.0311 - val_loss: 3.4392 - val_acc: 0.0333          \n",
      "\n",
      "Epoch 48/50                                                                       \n",
      " - 12s - loss: 3.6142 - acc: 0.0375 - val_loss: 3.4251 - val_acc: 0.0250          \n",
      "\n",
      "Epoch 49/50                                                                       \n",
      " - 12s - loss: 3.6824 - acc: 0.0314 - val_loss: 3.4394 - val_acc: 0.0283          \n",
      "\n",
      "Epoch 50/50                                                                       \n",
      " - 12s - loss: 3.6343 - acc: 0.0292 - val_loss: 3.4330 - val_acc: 0.0375          \n",
      "\n",
      "Train on 3600 samples, validate on 1200 samples                                   \n",
      "Epoch 1/50                                                                        \n",
      " - 10s - loss: 3.4012 - acc: 0.0367 - val_loss: 3.4014 - val_acc: 0.0275          \n",
      "\n",
      "Epoch 2/50                                                                        \n",
      " - 9s - loss: 3.4001 - acc: 0.0442 - val_loss: 3.4019 - val_acc: 0.0392           \n",
      "\n",
      "Epoch 3/50                                                                        \n",
      " - 9s - loss: 3.3995 - acc: 0.0433 - val_loss: 3.4017 - val_acc: 0.0433           \n",
      "\n",
      "Epoch 4/50                                                                        \n",
      " - 9s - loss: 3.3984 - acc: 0.0514 - val_loss: 3.4015 - val_acc: 0.0433           \n",
      "\n",
      "Epoch 5/50                                                                        \n",
      " - 9s - loss: 3.3974 - acc: 0.0533 - val_loss: 3.4011 - val_acc: 0.0433           \n",
      "\n",
      "Epoch 6/50                                                                        \n",
      " - 9s - loss: 3.3962 - acc: 0.0542 - val_loss: 3.4011 - val_acc: 0.0367           \n",
      "\n",
      "Epoch 7/50                                                                        \n",
      " - 9s - loss: 3.3953 - acc: 0.0525 - val_loss: 3.4005 - val_acc: 0.0383           \n",
      "\n",
      "Epoch 8/50                                                                        \n",
      " - 9s - loss: 3.3941 - acc: 0.0539 - val_loss: 3.3997 - val_acc: 0.0492           \n",
      "\n",
      "Epoch 9/50                                                                        \n",
      " - 9s - loss: 3.3929 - acc: 0.0594 - val_loss: 3.3990 - val_acc: 0.0483           \n",
      "\n",
      "Epoch 10/50                                                                       \n",
      " - 9s - loss: 3.3912 - acc: 0.0608 - val_loss: 3.3984 - val_acc: 0.0508           \n",
      "\n",
      "Epoch 11/50                                                                       \n",
      " 10%|█         | 3/30 [27:35<3:51:51, 515.24s/it, best loss: -0.21166666666666667]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=30,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='Kapitel 13 - Hyperparameteroptimierung mit Keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "1200/1200 [==============================] - 2s 2ms/step\n",
      "[0.3268358302116394, 0.935]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 2, 'Dense_1': 1, 'Dense_2': 1, 'Dense_3': 1, 'Dropout': 1, 'Dropout_1': 0, 'Dropout_2': 0, 'Dropout_3': 1, 'optimizer': 0}\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOM when allocating tensor with shape[281396,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
    "\t [[Node: training_20/SGD/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](SGD_15/momentum/read, training_20/SGD/Variable/read)]]\n",
    "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\")\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vector = vectorizer.fit_transform(corpus[\"text\"])\n",
    "labels = LabelEncoder().fit_transform(corpus[\"category\"])\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, \n",
    "                                                        labels, \n",
    "                                                        test_size=0.4, \n",
    "                                                        train_size=0.6,\n",
    "                                                        random_state=42)\n",
    "X_val = X_test[:1200]\n",
    "X_test = X_test[1200:]\n",
    "\n",
    "y_val = y_test[:1200]\n",
    "y_test = y_test[1200:]\n",
    "\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3600 samples, validate on 1200 samples\n",
      "Epoch 1/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 3.3352 - acc: 0.1100 - val_loss: 3.1883 - val_acc: 0.2942\n",
      "Epoch 2/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 2.9586 - acc: 0.2236 - val_loss: 2.6675 - val_acc: 0.4450\n",
      "Epoch 3/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 2.4472 - acc: 0.3258 - val_loss: 2.0908 - val_acc: 0.6250\n",
      "Epoch 4/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 2.0015 - acc: 0.4183 - val_loss: 1.6045 - val_acc: 0.7933\n",
      "Epoch 5/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 1.6164 - acc: 0.5356 - val_loss: 1.2182 - val_acc: 0.8350\n",
      "Epoch 6/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 1.3183 - acc: 0.6144 - val_loss: 0.9609 - val_acc: 0.8667\n",
      "Epoch 7/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 1.1431 - acc: 0.6414 - val_loss: 0.7862 - val_acc: 0.8900\n",
      "Epoch 8/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.9449 - acc: 0.7175 - val_loss: 0.6523 - val_acc: 0.8942\n",
      "Epoch 9/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.8254 - acc: 0.7475 - val_loss: 0.5647 - val_acc: 0.8967\n",
      "Epoch 10/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.7212 - acc: 0.7789 - val_loss: 0.5006 - val_acc: 0.9025\n",
      "Epoch 11/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.6431 - acc: 0.8081 - val_loss: 0.4505 - val_acc: 0.9092\n",
      "Epoch 12/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.5652 - acc: 0.8228 - val_loss: 0.4147 - val_acc: 0.9117\n",
      "Epoch 13/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.5103 - acc: 0.8406 - val_loss: 0.3885 - val_acc: 0.9158\n",
      "Epoch 14/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.4661 - acc: 0.8533 - val_loss: 0.3654 - val_acc: 0.9142\n",
      "Epoch 15/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.4058 - acc: 0.8736 - val_loss: 0.3571 - val_acc: 0.9158\n",
      "Epoch 16/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.4000 - acc: 0.8775 - val_loss: 0.3460 - val_acc: 0.9175\n",
      "Epoch 17/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.3644 - acc: 0.8844 - val_loss: 0.3394 - val_acc: 0.9200\n",
      "Epoch 18/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.3322 - acc: 0.8978 - val_loss: 0.3298 - val_acc: 0.9183\n",
      "Epoch 19/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.3312 - acc: 0.8961 - val_loss: 0.3254 - val_acc: 0.9183\n",
      "Epoch 20/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.3047 - acc: 0.9050 - val_loss: 0.3310 - val_acc: 0.9200\n",
      "Epoch 21/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2888 - acc: 0.9092 - val_loss: 0.3239 - val_acc: 0.9225\n",
      "Epoch 22/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2786 - acc: 0.9153 - val_loss: 0.3340 - val_acc: 0.9175\n",
      "Epoch 23/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2528 - acc: 0.9192 - val_loss: 0.3214 - val_acc: 0.9208\n",
      "Epoch 24/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2421 - acc: 0.9258 - val_loss: 0.3289 - val_acc: 0.9192\n",
      "Epoch 25/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2364 - acc: 0.9286 - val_loss: 0.3296 - val_acc: 0.9192\n",
      "Epoch 26/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2365 - acc: 0.9242 - val_loss: 0.3217 - val_acc: 0.9217\n",
      "Epoch 27/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2085 - acc: 0.9364 - val_loss: 0.3182 - val_acc: 0.9217\n",
      "Epoch 28/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2081 - acc: 0.9392 - val_loss: 0.3196 - val_acc: 0.9258\n",
      "Epoch 29/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2025 - acc: 0.9336 - val_loss: 0.3135 - val_acc: 0.9217\n",
      "Epoch 30/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1857 - acc: 0.9386 - val_loss: 0.3201 - val_acc: 0.9267\n",
      "Epoch 31/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2060 - acc: 0.9283 - val_loss: 0.3132 - val_acc: 0.9217\n",
      "Epoch 32/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.2065 - acc: 0.9308 - val_loss: 0.3287 - val_acc: 0.9192\n",
      "Epoch 33/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1662 - acc: 0.9464 - val_loss: 0.3275 - val_acc: 0.9217\n",
      "Epoch 34/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1764 - acc: 0.9453 - val_loss: 0.3281 - val_acc: 0.9242\n",
      "Epoch 35/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1735 - acc: 0.9458 - val_loss: 0.3337 - val_acc: 0.9225\n",
      "Epoch 36/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1780 - acc: 0.9406 - val_loss: 0.3305 - val_acc: 0.9217\n",
      "Epoch 37/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1611 - acc: 0.9486 - val_loss: 0.3227 - val_acc: 0.9208\n",
      "Epoch 38/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1486 - acc: 0.9528 - val_loss: 0.3267 - val_acc: 0.9208\n",
      "Epoch 39/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1473 - acc: 0.9547 - val_loss: 0.3417 - val_acc: 0.9200\n",
      "Epoch 40/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1637 - acc: 0.9414 - val_loss: 0.3350 - val_acc: 0.9175\n",
      "Epoch 41/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1429 - acc: 0.9522 - val_loss: 0.3375 - val_acc: 0.9217\n",
      "Epoch 42/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1379 - acc: 0.9556 - val_loss: 0.3373 - val_acc: 0.9217\n",
      "Epoch 43/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1388 - acc: 0.9600 - val_loss: 0.3443 - val_acc: 0.9183\n",
      "Epoch 44/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1312 - acc: 0.9556 - val_loss: 0.3517 - val_acc: 0.9208\n",
      "Epoch 45/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1494 - acc: 0.9486 - val_loss: 0.3484 - val_acc: 0.9167\n",
      "Epoch 46/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1433 - acc: 0.9525 - val_loss: 0.3458 - val_acc: 0.9200\n",
      "Epoch 47/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1270 - acc: 0.9572 - val_loss: 0.3518 - val_acc: 0.9192\n",
      "Epoch 48/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1224 - acc: 0.9608 - val_loss: 0.3566 - val_acc: 0.9200\n",
      "Epoch 49/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1134 - acc: 0.9622 - val_loss: 0.3463 - val_acc: 0.9192\n",
      "Epoch 50/50\n",
      "3600/3600 [==============================] - 10s 3ms/step - loss: 0.1374 - acc: 0.9547 - val_loss: 0.3528 - val_acc: 0.9225\n",
      "CPU times: user 4min 27s, sys: 3min 42s, total: 8min 9s\n",
      "Wall time: 8min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\", input_shape=(len(vocab),)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(len(np.unique(labels)), activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   batch_size=64,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1_keras = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average=\"micro\")\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"Train_acc: {np.around(np.mean(history.history['acc']), decimals=3)}\")\n",
    "    print(f\"Val_acc: {np.around(np.mean(history.history['val_acc']), decimals=3)}\")\n",
    "    print(f\"Test_acc: {np.around(test_acc, decimals=3)}\") \n",
    "    print(f\"F1-score: {str(np.around(f1_keras, decimals=3))}\")\n",
    "          \n",
    "def plot_results(history):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"ro\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.clf() #clears the figure\n",
    "\n",
    "    acc = history.history[\"acc\"]\n",
    "    val_acc = history.history[\"val_acc\"]\n",
    "\n",
    "    plt.plot(epochs, acc, \"b\", label=\"Training acc\")\n",
    "    plt.plot(epochs, val_acc, \"ro\", label=\"Validation acc\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Acc\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt4VNW5x/HvSwTCTVBARJAEtcpdIPEGWkDA47UeW6xibKu1peVo1WpPy9FWrS31br3UXqittRK1Hj1earXWC1VpvQUEFJBKNSiCEhACEVAC7/lj7YQhTJJJMjuTTH6f59nPzKzZs+fdk8x+Z62191rm7oiIiAC0y3QAIiLScigpiIhINSUFERGppqQgIiLVlBRERKSakoKIiFRTUpC0MrMcM6swswHpXDeTzOwgM0v7udtmNsnMShMeLzOzY1JZtxHvdaeZXdbY19ex3Z+a2R/SvV3JnD0yHYBklplVJDzsDHwKbI8ef8vdixuyPXffDnRN97ptgbsfko7tmNk3gLPdfXzCtr+Rjm1L9lNSaOPcvfqgHP0S/Ya7P1Pb+ma2h7tXNkdsItL81HwkdYqaB/5kZveZ2SbgbDM7ysxeNrMNZrbazG4zs/bR+nuYmZtZfvR4dvT8k2a2ycxeMrOBDV03ev4EM/uXmZWb2e1m9g8zO6eWuFOJ8VtmttzM1pvZbQmvzTGzn5vZOjN7Bzi+js/ncjO7v0bZHWZ2c3T/G2a2NNqff0e/4mvb1kozGx/d72xm90SxLQYKaqz7QzN7J9ruYjP7QlQ+HPgFcEzUNLc24bO9KuH13472fZ2ZPWJmfVP5bOpjZqdF8Wwws+fM7JCE5y4zs1VmttHM3krY1yPNbH5U/pGZ3ZDq+0kM3F2LFtwdoBSYVKPsp8BnwCmEHxGdgMOAIwg1zQOAfwEXROvvATiQHz2eDawFCoH2wJ+A2Y1Ydx9gE3Bq9NwlwDbgnFr2JZUYHwW6A/nAx1X7DlwALAb6Az2BF8JXJen7HABUAF0Str0GKIwenxKtY8CxwBZgRPTcJKA0YVsrgfHR/RuBvwN7AXnAkhrrfhnoG/1Nzopi6BM99w3g7zXinA1cFd0/LopxJJAL/BJ4LpXPJsn+/xT4Q3R/cBTHsdHf6DJgWXR/KLAC2DdadyBwQHT/NWBqdL8bcESmvwtteVFNQVIx193/7O473H2Lu7/m7q+4e6W7vwPMAsbV8foH3b3E3bcBxYSDUUPXPRlY4O6PRs/9nJBAkkoxxmvcvdzdSwkH4Kr3+jLwc3df6e7rgGvreJ93gDcJyQpgMrDe3Uui5//s7u948BzwLJC0M7mGLwM/dff17r6C8Os/8X0fcPfV0d/kXkJCL0xhuwBFwJ3uvsDdtwIzgHFm1j9hndo+m7qcCTzm7s9Ff6NrCYnlCKCSkICGRk2Q70afHYTk/jkz6+num9z9lRT3Q2KgpCCpeD/xgZkNMrO/mNmHZrYRuBroVcfrP0y4v5m6O5drW3e/xDjc3Qm/rJNKMcaU3ovwC7cu9wJTo/tnRY+r4jjZzF4xs4/NbAPhV3pdn1WVvnXFYGbnmNnCqJlmAzAoxe1C2L/q7bn7RmA90C9hnYb8zWrb7g7C36ifuy8DLiX8HdZEzZH7RqueCwwBlpnZq2Z2Yor7ITFQUpBU1Dwd8zeEX8cHufuewBWE5pE4rSY05wBgZsauB7GamhLjamD/hMf1nTL7ADDJzPoRagz3RjF2Ah4EriE07fQA/pZiHB/WFoOZHQD8CpgO9Iy2+1bCdus7fXYVoUmqanvdCM1UH6QQV0O2247wN/sAwN1nu/tYQtNRDuFzwd2XufuZhCbCm4CHzCy3ibFIIykpSGN0A8qBT8xsMPCtZnjPx4HRZnaKme0BXAT0jinGB4CLzayfmfUEflDXyu7+ITAX+AOwzN3fjp7qCHQAyoDtZnYyMLEBMVxmZj0sXMdxQcJzXQkH/jJCfvwmoaZQ5SOgf1XHehL3AeeZ2Qgz60g4OL/o7rXWvBoQ8xfMbHz03v9N6Ad6xcwGm9mE6P22RMsOwg58xcx6RTWL8mjfdjQxFmkkJQVpjEuBrxG+8L8hdAjHyt0/As4AbgbWAQcCrxOuq0h3jL8itP2/QegEfTCF19xL6Diubjpy9w3Ad4GHCZ21UwjJLRVXEmospcCTwB8TtrsIuB14NVrnECCxHf5p4G3gIzNLbAaqev1fCc04D0evH0DoZ2gSd19M+Mx/RUhYxwNfiPoXOgLXE/qBPiTUTC6PXnoisNTC2W03Ame4+2dNjUcax0LTrEjrYmY5hOaKKe7+YqbjEckWqilIq2Fmx0fNKR2BHxHOWnk1w2GJZJXYkoKZ5UZnEiyMLmb5cZJ1zjGzMjNbEC26FF/qcjTwDqFp4j+A09y9tuYjEWmE2JqPorNDurh7RdTpNBe4yN1fTljnHMJFPhfUshkREWlGsY19FJ1HXjXYWvtoUQeGiEgLFuuAeFFn4DzgIOCOWq5U/JKZfZ4wDMF33f39miuY2TRgGkCXLl0KBg0aVHMVERGpw7x589a6e12ncQPNdPaRmfUgnP72HXd/M6G8J1Dh7p+a2bcIp6IdW9e2CgsLvaSkJN6ARUSyjJnNc/d6h0JplrOPovO151BjtEl3X5fQUXgnNUaCFBGR5hXn2Ue9oxpC1eX+kwmX4ieu0zfh4ReApXHFIyIi9YuzT6EvcHfUr9AOeMDdHzezq4ESd38MuDAaB76ScMXnOTHGIyIi9Wh1VzSrT0GkeW3bto2VK1eydevWTIciKcjNzaV///60b7/r0Fep9iloOk4RqdPKlSvp1q0b+fn5hMuPpKVyd9atW8fKlSsZOHBg/S9IQsNciEidtm7dSs+ePZUQWgEzo2fPnk2q1SkpiEi9lBBaj6b+rdpMUli8GC69FLZsyXQkIiItV5tJCqWlcPPN8I9/ZDoSEWmIdevWMXLkSEaOHMm+++5Lv379qh9/9llq0y6ce+65LFu2rM517rjjDoqLi9MRMkcffTQLFixIy7aaW5vpaB43Dtq3h6efhkmTMh2NiKSqZ8+e1QfYq666iq5du/K9731vl3XcHXenXbvkv3Pvuuuuet/n/PPPb3qwWaDN1BS6doWjjoJnnsl0JCKSDsuXL2fIkCEUFRUxdOhQVq9ezbRp0ygsLGTo0KFcffXV1etW/XKvrKykR48ezJgxg0MPPZSjjjqKNWvWAPDDH/6QW265pXr9GTNmcPjhh3PIIYfwz3/+E4BPPvmEL33pSwwZMoQpU6ZQWFhYb41g9uzZDB8+nGHDhnHZZZcBUFlZyVe+8pXq8ttuuw2An//85wwZMoQRI0Zw9tlnp/0zS0WbqSkATJ4MV1wBa9dCr16Zjkak9bn4Ykh3q8jIkRAdixvsrbfe4o9//COFheH0+2uvvZa9996byspKJkyYwJQpUxgyZMgurykvL2fcuHFce+21XHLJJfz+979nxowZu23b3Xn11Vd57LHHuPrqq/nrX//K7bffzr777stDDz3EwoULGT16dJ3xrVy5kh/+8IeUlJTQvXt3Jk2axOOPP07v3r1Zu3Ytb7zxBgAbNmwA4Prrr2fFihV06NChuqy5tZmaAoRmI3d49tlMRyIi6XDggQdWJwSA++67j9GjRzN69GiWLl3KkiVLdntNp06dOOGEEwAoKCigtLQ06ba/+MUv7rbO3LlzOfPMMwE49NBDGTp0aJ3xvfLKKxx77LH06tWL9u3bc9ZZZ/HCCy9w0EEHsWzZMi688EKeeuopunfvDsDQoUM5++yzKS4u3u3is+bSpmoKhYXQvXvoVzjjjExHI9L6NPYXfVy6dOlSff/tt9/m1ltv5dVXX6VHjx6cffbZSc/X79ChQ/X9nJwcKisrk267Y8eO9a7TWD179mTRokU8+eST3HHHHTz00EPMmjWLp556iueff57HHnuMn/3sZyxatIicnJy0vnd92kZNobgY8vPZo0M7/vVZPp0fLqaVje4hIvXYuHEj3bp1Y88992T16tU89dRTaX+PsWPH8sADDwDwxhtvJK2JJDriiCOYM2cO69ato7Kykvvvv59x48ZRVlaGu3P66adz9dVXM3/+fLZv387KlSs59thjuf7661m7di2bN29O+z7UJ/trCsXFMG0aRB/uPltWcM2WaXx4M/S9tCjDwYlIuowePZohQ4YwaNAg8vLyGDt2bNrf4zvf+Q5f/epXGTJkSPVS1fSTTP/+/fnJT37C+PHjcXdOOeUUTjrpJObPn895552Hu2NmXHfddVRWVnLWWWexadMmduzYwfe+9z26deuW9n2oT/YPiJefDytW7Fa8ca889vy4NG1xiWSrpUuXMnjw4EyH0SJUVlZSWVlJbm4ub7/9Nscddxxvv/02e+zRsn5fJ/ubaUC8Ku+9l7S46/rk5SIitamoqGDixIlUVlbi7vzmN79pcQmhqbJrb5IZMCBpTWGlDWC/Ssiyv6eIxKhHjx7Mmzcv02HEKvs7mmfOhM6ddymq7NCZGT4TTcsgIrKr7E8KRUUwaxbk5YEZ5OWx5bZZ3G9FPP10poMTEWlZsj8pQEgMpaWwYweUltLtW0WMHo2SgohIDW0jKSQxaRK89BJs2pTpSEREWo42mxQmT4bKSnj++UxHIiJ1mTBhwm4Xot1yyy1Mnz69ztd17doVgFWrVjFlypSk64wfP576TnG/5ZZbdrmI7MQTT0zLuERXXXUVN954Y5O3k25tNimMHQu5uRo1VSTtohEEaNcu3DZxjoKpU6dy//3371J2//33M3Xq1JRev99++/Hggw82+v1rJoUnnniCHj16NHp7LV2bTQq5ufD5z6tfQSStqkYQWLEijD65YkV43ITEMGXKFP7yl79UT6hTWlrKqlWrOOaYY6qvGxg9ejTDhw/n0Ucf3e31paWlDBs2DIAtW7Zw5plnMnjwYE477TS2JEzFOH369Opht6+88koAbrvtNlatWsWECROYMGECAPn5+axduxaAm2++mWHDhjFs2LDqYbdLS0sZPHgw3/zmNxk6dCjHHXfcLu+TzIIFCzjyyCMZMWIEp512GuvXr69+/6qhtKsG4nv++eerJxkaNWoUm9LdBl41OUW6FyAXeBVYCCwGfpxknY7An4DlwCtAfn3bLSgo8HS5/np3cF+5Mm2bFMk6S5YsSX3lvLzwpaq55OU1KYaTTjrJH3nkEXd3v+aaa/zSSy91d/dt27Z5eXm5u7uXlZX5gQce6Dt27HB39y5duri7+7vvvutDhw51d/ebbrrJzz33XHd3X7hwoefk5Phrr73m7u7r1q1zd/fKykofN26cL1y4MNqlPC8rK0vYxfC4pKTEhw0b5hUVFb5p0yYfMmSIz58/3999913Pycnx119/3d3dTz/9dL/nnnt226crr7zSb7jhBnd3Hz58uP/97393d/cf/ehHftFFF7m7e9++fX3r1q3u7r5+/Xp3dz/55JN97ty57u6+adMm37Zt227bTvY3A0o8hWN3nDWFT4Fj3f1QYCRwvJkdWWOd84D17n4Q8HPguhjj2c3kyeFWTUgiaVLLCAK1lqcosQkpsenI3bnssssYMWIEkyZN4oMPPuCjjz6qdTsvvPBC9eQ1I0aMYMSIEdXPPfDAA4wePZpRo0axePHiege7mzt3LqeddhpdunSha9eufPGLX+TFF18EYODAgYwcORKoe3huCPM7bNiwgXHjxgHwta99jRdeeKE6xqKiImbPnl195fTYsWO55JJLuO2229iwYUPar6iOLSlEyakietg+WmoOtHQqcHd0/0FgoplZXDHVNGIE9O6tJiSRtBkwoGHlKTr11FN59tlnmT9/Pps3b6agoACA4uJiysrKmDdvHgsWLKBPnz5Jh8uuz7vvvsuNN97Is88+y6JFizjppJMatZ0qVcNuQ9OG3v7LX/7C+eefz/z58znssMOorKxkxowZ3HnnnWzZsoWxY8fy1ltvNTrOZGLtUzCzHDNbAKwBnnb3V2qs0g94H8DdK4FyoGeS7UwzsxIzKykrK0tbfO3ahVNTn3kGDaUtkg5JRhCgc+dQ3gRdu3ZlwoQJfP3rX9+lg7m8vJx99tmH9u3bM2fOHFYkGdIm0ec//3nuvfdeAN58800WLVoEhGG3u3TpQvfu3fnoo4948sknq1/TrVu3pO32xxxzDI888gibN2/mk08+4eGHH+aYY45p8L51796dvfbaq7qWcc899zBu3Dh27NjB+++/z4QJE7juuusoLy+noqKCf//73wwfPpwf/OAHHHbYYWlPCrGO/OPu24GRZtYDeNjMhrn7m43YzixgFoRRUtMZ4+TJcN998OabMHx4Orcs0gYVRcPRX355aDIaMCAkhKKmD1M/depUTjvttF3ORCoqKuKUU05h+PDhFBYWMmjQoDq3MX36dM4991wGDx7M4MGDq2schx56KKNGjWLQoEHsv//+uwy7PW3aNI4//nj2228/5syZU10+evRozjnnHA4//HAAvvGNbzBq1Kg6m4pqc/fdd/Ptb3+bzZs3c8ABB3DXXXexfft2zj77bMrLy3F3LrzwQnr06MGPfvQj5syZQ7t27Rg6dGj1LHLp0mxDZ5vZFcBmd78xoewp4Cp3f8nM9gA+BHp7HUE1eOjserz3XhgB4/bb4YIL0rZZkayhobNbn6YMnR1b85GZ9Y5qCJhZJ2AyULOe8xjwtej+FOC5uhJCHPbfH/bZB7J84EMRkZTE2XzUF7jbzHIIyecBd3/czK4mnBr1GPA74B4zWw58DJwZYzxJmcHo0TB/fnO/s4hIyxNbUnD3RcCoJOVXJNzfCpweVwypKigIZyBt2QKdOmU6GpGWx6NpI6Xla2pjS5u9ojlRQQFs3w7RiQgikiA3N5d169Y1+WAj8XN31q1bR25ubqO3oXnHCM1HEJqQjjgis7GItDT9+/dn5cqVpPN0cIlPbm4u/fv3b/TrlRQIZ8317KnOZpFk2rdvz8CBAzMdhjQTNR8ROpsLCpQURESUFCIFBeECtk8/zXQkIiKZo6QQGT06TLrzxhuZjkREJHOUFCLR1e5qQhKRNk1JIZKfD3vtpaQgIm2bkkJEVzaLiCgp7KKgIPQpRLP+iYi0OUoKCQoKQkJ4s8GDe4uIZAclheLi0KHQrh2nfTefqRSrCUlE2qy2nRSKi2HaNFixAtxpv2oFdzKNdvcXZzoyEZGMaNtJ4fLLYfPmXYo6s5kTXrw8QwGJiGRW204K772XtLjPZ++xbVszxyIi0gK07aQwYEDS4vcYwJIlzRyLiEgL0LaTwsyZ0LnzLkU7cjtzGTN1EZuItEltOykUFcGsWZCXF65ey8uD387i8W5FOgNJRNokzadQVBSWSDtg1G813IWItE1tu6ZQi4ICWLgwjJoqItKWKCkkUVAAW7bAW29lOhIRkeYVW1Iws/3NbI6ZLTGzxWZ2UZJ1xptZuZktiJYr4oqnIarmbFYTkoi0NXHWFCqBS919CHAkcL6ZDUmy3ovuPjJaro4xnpQdfDB06aKkICJtT2xJwd1Xu/v86P4mYCnQL673S6ecHBg1SsNoi0jb0yx9CmaWD4wCXkny9FFmttDMnjSzobW8fpqZlZhZSVlZWYyR7jR6NLz+Omzf3ixvJyLSIsSeFMysK/AQcLG7b6zx9Hwgz90PBW4HHkm2DXef5e6F7l7Yu3fveAOOFBSEYZGWLWuWtxMRaRFiTQpm1p6QEIrd/f9qPu/uG929Irr/BNDezHrFGVOqquZsVhOSiLQlcZ59ZMDvgKXufnMt6+wbrYeZHR7Fsy6umBpi0KAwAkZJSaYjERFpPnFe0TwW+ArwhpktiMouAwYAuPuvgSnAdDOrBLYAZ7q7xxhTynJyoLAQXn4505GIiDSf2JKCu88FrJ51fgH8Iq4YmmrMGLjppnAhW6dOmY5GRCR+uqK5DmPGwLZtakISkbZDSaEORx0Vbv/5z8zGISLSXJQU6tCrFxxyiJKCiLQdSgr1GDMmJIWW0f0tIhIvJYV6jBkDa9fC8uWZjkREJH5KCvUYMybc/uMfmY1DRKQ5KCnUY9Ag6NFD/Qoi0jYoKdSjXbtwFpKSgoi0BUoKKRgzBhYvhg0bMh2JiEi8lBRSMHZsuNWQFyKS7ZQUUnDYYWEsJDUhiUi2U1JIQdeucOihOgNJRLKfkkKKxoyBV16ByspMRyIiEh8lhRSNGQOffAJvvJHpSERE4qOkkKKqi9jUryAi2UxJIUUDBsB++ykpiEh2U1JIkVk4NVVJQUSymZJCbYqLIT8/XNKcnw/FxYwZA6WlsGpVhmMTEYmJkkIyxcUwbRqsWBHGzF6xAqZN4+SNxYBqCyKSvZQUkrn8cti8edeyzZs58HeXk5urpCAi2UtJIZn33ktabO+/x2GHKSmISPZSUkhmwIBay8eMgfnzYcuW5g1JRKQ5xJYUzGx/M5tjZkvMbLGZXZRkHTOz28xsuZktMrPRccXTIDNnQufOu5Z17gwzZzJmDGzbBvPmZSY0EZE4xVlTqAQudfchwJHA+WY2pMY6JwCfi5ZpwK9ijCd1RUUwaxbk5YVzUfPywuOiIo46KqyiJiQRyUZ7xLVhd18NrI7ubzKzpUA/YEnCaqcCf3R3B142sx5m1jd6bWYVFYWlht694eCDNTieiGSnZulTMLN8YBTwSo2n+gHvJzxeGZXVfP00Mysxs5KysrK4wkzZ0UfDCy/A9u2ZjkREJL1iTwpm1hV4CLjY3Tc2ZhvuPsvdC929sHfv3ukNsBEmTgyzsL3+eqYjERFJr1iTgpm1JySEYnf/vySrfADsn/C4f1TWoh17bLh99tnMxiEikm5xnn1kwO+Ape5+cy2rPQZ8NToL6UigvEX0J9Rj331h2DB45plMRyIikl6xdTQDY4GvAG+Y2YKo7DJgAIC7/xp4AjgRWA5sBs6NMZ60mjgRfvMb2LoVcnMzHY2ISHrEefbRXMDqWceB8+OKIU4TJ8Ktt8JLL8GECZmORkQkPXRFcyONGwc5OWpCEpHsoqTQSHvuCYcfrs5mEckuSgpNMHEivPYalJdnOhIRkfRIKSmY2YFm1jG6P97MLjSzHvGG1vJNmgQ7dsDf/57pSERE0iPVmsJDwHYzOwiYRbi24N7YomoljjwSOnVSE5KIZI9Uk8IOd68ETgNud/f/BvrGF1br0LEjHHOMkoKIZI9Uk8I2M5sKfA14PCprH09IrcukSbBkieZtFpHskGpSOBc4Cpjp7u+a2UDgnvjCaj0mTgy3zz2X2ThERNIhpaTg7kvc/UJ3v8/M9gK6uft1McfWKowcCXvvrSYkEckOqZ599Hcz29PM9gbmA781s9rGM2pT2rULA+Q98wy4ZzoaEZGmSbX5qHs07PUXCZPiHAFMii+s1mXiRFi5Et5+O9ORiIg0TapJYQ8z6wt8mZ0dzRKp6ldQE5KItHapJoWrgaeAf7v7a2Z2AKDfxZGDDoIBAzQOkoi0fimNkuru/wv8b8Ljd4AvxRVUa2MWaguPPBKm6MzJyXREIiKNk2pHc38ze9jM1kTLQ2bWP+7gWpOJE2H9eliwoP51RURaqlSbj+4izJK2X7T8OSpre4qLIT8/nHaUnx8eo34FEckOqSaF3u5+l7tXRssfgN4xxtUyFRfDtGmwYkU4/3TFivC4uJh994WhQ9WvICKtW6pJYZ2ZnW1mOdFyNrAuzsBapMsvh82bdy3bvDmUE2oLL764+yoiIq1Fqknh64TTUT8EVgNTgHNiiqnleu+9OstPPTXM2fyXvzRjTCIiaZTqMBcr3P0L7t7b3fdx9/+kLZ59NGBAneXjxkGfPvDAA80Yk4hIGjVl5rVL0hZFazFzJnTuvGtZ586hnHAq6pQpoaZQUZGB+EREmqgpScHSFkVrUVQEs2ZBXl64OCEvLzwuKqpe5YwzYMsW+POfMxiniEgjNSUp1Dn8m5n9Prqm4c1anh9vZuVmtiBarmhCLM2nqAhKS8M8nKWluyQEgLFjoV8/+NOfMhKdiEiT1HlFs5ltIvnB34BO9Wz7D8AvgD/Wsc6L7n5yPdtpVdq1g9NPh1/+EsrLoXv3TEckIpK6OmsK7t7N3fdMsnRz9zoTiru/AHyc1mhbiS9/GT77DB59NNORiIg0TFOaj9LhKDNbaGZPmtnQ2lYys2lmVmJmJWVlZc0ZX6MceWQ4IUlNSCLS2mQyKcwH8tz9UOB24JHaVnT3We5e6O6FvXu3/AupzUJt4W9/g4/bZF1JRFqrjCUFd9/o7hXR/SeA9mbWK1PxpNsZZ0BlJTz8cKYjERFJXcaSgpnta2YW3T88iiVrhs4oKIADDtCFbCLSuqQ0n0JjmNl9wHigl5mtBK4E2gO4+68JQ2VMN7NKYAtwpnv2zHJsFmoL118PZWXQClq9RESw1nYcLiws9JKSkkyHkZKFC2HkSPj1r+Fb38p0NCLSlpnZPHcvrG+9TJ99lNVGjIBDDtFZSCLSeigpxKiqCen55+HDDzMdjYhI/ZQUYnbGGWFEjAcfzHQkIiL1U1KI2ZAhMGyYmpBEpHVQUmgGZ5wBc+eG2TtFRFoyJYVm8NWvQseO8KMfZToSEZG6KSk0gwED4NJL4Z574OWXMx2NiEjtlBSayf/8D/TtCxddFDqeRURaIiWFdCkuhvz8MKFCfn54nKBrV7juOnj1VZg9OyMRiojUS0khHYqLYdq00JPsHm6nTdstMRQVwRFHwIwZsGlThmIVEamDkkI6XH45bN68a9nmzaE8Qbt2cOutsHo1XHNNM8YnIpIiJYV0eO+9lMuPOCKcjXTTTfDOOzHHJSLSQEoK6TBgQIPKr7kG2reH730vxphERBpBSSEdZs6Ezp13LevcOZQnsd9+cNllYQKeZ59thvhERFKkpJAORUUwaxbk5YVR8PLywuOiolpfcskl4SSliy8OM7SJiLQESgrpUlQEpaXhIoTS0joTAkBubuhXePNN+N3vmiVCEZF6KSlk0GmnwZgx8JOfwNatmY5GRERJIaPMQkL44IPQ2iQikmlKChk2YQKMGwc/+9nulzqIiDQ3JYUMq6otfPQR/OpXmY5GRNo6JYUW4JhjYPJkuPZaqKjIdDQi0pbFlhTM7PdmtsbM3qzleTOz28xsuZktMrPRccV/AF7RAAATMklEQVTSGvzkJ7B2Ldx+e6YjEZG2LM6awh+A4+t4/gTgc9EyDWjTjSdHHAEnnQQ33ADl5ZmORkTaqtiSgru/AHxcxyqnAn/04GWgh5n1jSue1uDHP4b168OgeSIimZDJPoV+wPsJj1dGZdmlnnkWEhUUwH/+J9x8c0gOIiLNrVV0NJvZNDMrMbOSsrKyTIeTuhTnWUj04x+H5qObbmrGOEVEIplMCh8A+yc87h+V7cbdZ7l7obsX9u7du1mCS4sU51lINGIEfPnLoQlp7dqY4xMRqSGTSeEx4KvRWUhHAuXuvjqD8aRfA+ZZSHTVVfDJJ3DllekPSUSkLnGeknof8BJwiJmtNLPzzOzbZvbtaJUngHeA5cBvgf+KK5aMaeA8C1UGD4aLLoJf/hLuvDOGuEREarFHXBt296n1PO/A+XG9f4swc2boQ0hsQqpjnoVEN9wAb70F06fDwIEwcWKMcYqIRFpFR3Or1Yh5FqrssQfcfz8ccghMmRIShIhI3Cz8YG89CgsLvaSkJNNhNJvSUjj8cNhzT3jlFejZM9MRiUhrZGbz3L2wvvVUU2jh8vPh0Udh5Ur44hfh008zHZGIZDMlhVbgqKPgrrvghRfgW98KlzyIiMQhto5mSa+pU+Ff/wqnqx58MFx2WaYjEpFspJpCJjVgCAyAK64IfdSXXw533NEsEYpIG6OaQqZUDYFRdbpq1RAYUOvZSWahGamiAi64ADp0gG9+s5niFZE2QTWFTGnEEBgA7dvDn/4EJ5wQ+hfuvjvGGEWkzVFSyJRGDoEB0LEjPPRQuKDt618P1zOIiKSDkkKmNHIIjCqdOoVTVY8+Gs4+OyQJEZGmUlLIlJkzw5AXiVIcAiNx9ccfDxe3nXkm/PnPaY5RRNocJYVMacIQGIm6dYMnn4RRo+BLXwpnJek6BhFpLA1zkSU2bAj55Ikn4KyzQn7p0iXTUYlIS6FhLlqzBl6/ANCjR2g++ulP4b77QpOSBtETkYZSUmhpGjGFZ5V27cIZrU89BWvWwGGHwf/+bzPELCJZQ0mhpWnk9QuJJk+G+fNh2LAwted3vwvbtqU5ThHJSkoKLU0Trl9ItP/+8Pzz8J3vwC23wPjx8EHSGbBFRHZSUmhpmnj9QqIOHeC220Ifw8KF4QylZ59tYnwiktWUFFqauq5faEQHNIRrGF57DXr1guOOC5vasSPtkYtIFlBSaGlqu34BGt0BDTB4MLz6akgQP/whnHIKfPxxjPshIq2SrlNoLfLzQyKoKS8vzNmZInf41a/g4othv/3CqKsTJqQtShFpoXSdQrZJUwe0GfzXf8HcueH+scfCiSfCG2+kIUYRafViTQpmdryZLTOz5WY2I8nz55hZmZktiJZvxBlPq1ZXB3Qj+hoOPxyWLIHrroOXXoJDD4VzzmlwjhGRLBNbUjCzHOAO4ARgCDDVzIYkWfVP7j4yWu6MK55Wr7YO6BNPbHRfQ6dO8P3vw7//DZdeGobgPvjgUKb+BpG2Kc6awuHAcnd/x90/A+4HTo3x/bJbbR3QTzzR5Ivd9t4bbrgBli2DM86AG28M1zmcf34oE5G2I86k0A94P+Hxyqispi+Z2SIze9DM9k+2ITObZmYlZlZSVlYWR6ytQ1FR6FTesSPcFhXV39fQgKalvLwwk9vChSE53HknDBoUKiN/+5tGXxVpCzLd0fxnIN/dRwBPA0knl3T3We5e6O6FvXv3btYAW7z6+hoa0bQ0fDj8/vchr/z4x2HIjP/4Dxg6NJRv3x7DfohIixBnUvgASPzl3z8qq+bu69z90+jhnUBBjPFkp7oudqtrHKUUahB9+sAVV4RccvfdkJsL550HRxwBL78c2x6JSAbFmRReAz5nZgPNrANwJvBY4gpm1jfh4ReApTHGk53qmqyntqalqhpDijWIjh3hq1+FefPg3nth9Wo46qgwP/SaNTHum4g0u9iSgrtXAhcATxEO9g+4+2Izu9rMvhCtdqGZLTazhcCFwDlxxZPVkvU1QO1NSzk5japBmMHUqWGehu9/H+65J5ytdPvtUFkZw36JSLPTFc3ZrKpPITEBdO68e0JIVPP5zp13DrNx+eWh9jFgAMycyVsFRXznO/DMM3DggXDQQdC9+85lzz3DmU2TJ4fkISKZk+oVzbh7q1oKCgpcGmD2bPe8PHezcFv1ODQc7brk5CQv79nTvXPnXcs6d3afPdt3zJ7tFb3yfDvmqzrk+SX7zvY+fdw7ddp19YIC95tucl+5MsOfh0h9kn1n6iqPezuNfU0NQImncIzN+EG+oYuSQhrMnp38IJ8sIdS11JEs3N23/WG2b+uX5zuihDGV2W7m/pPBs33j3nm+own/4E3a9yZ+udq8uD/Durbf0ANtY8qT/U9Pn177/3qybTVmO7XFVdu2Gvi5KylI3RpSg2joUrW9Gv/I23M7+8uF0/0T27X8s/adfd3ttXy5aou1rvLanqvryxX3ezd2Ww35+zVm/XQdNNP1Gda3/YYcaBtans5adM+eDdtOLd+ZOreVl1f//0kCJQVpuIb+U9a2VH3JG/ClWENP39xu1/eu7NjZPzhtuld2bMQvt4bsR21f7MYcVNJ14KrvIBvnr9bGHDTT9RnWdQBs6AG7oeVVn1tD/tfTtdT1nanrNQ2gpCCN05CDSl1f4AZ+uXbUUr6N5F/g7e3q+GKnq8bTmINKug5cdTXNNfTA3NBfrek8aDb0PWpbzOI/YDfix0za/qca89mqpqCkkFENreqn6ctVW7Kotdws9FXEefDI5IGrtf2aTed+N0dNoaG1qnTVPhuT7NWnoKTQIqWrw66Bv2Z31FJTeJc8X2F5SZ/7bM+evr1TzL+k03Xgqm1J54E5nQfNdH2GdR0Am6NPob7/6bj7qRq6rQZQUpDMS8eXqwFf7MqOnf2pr832uybP9i01+icq6OxTme1Tme3vEk6hXds1z1++cLaX/yrN/QBxt61nss8kxr9fSgfAuM8+Suf/eaa3VYOSgrQ+MZwBtMPMt/XP83d+Otsff9x91iz3K65wP/549y5ddh6PfrD/bF/XLZw+u6VPnq++abZv3ty0947tLJzGvCaTZ0Q1x4FZ6pVqUtAVzdJmbdsGr70Gc+aE5R//gK1bd11nr72gXz/o23fnVdqJt127hhFBajILs9mNGpX8+ZQUF+92FXn1ECbpfI20Cale0aykIBL59NMwC90HH+y6rFoFH34IGzdCeXm4rahIbZu9e4dhPo47Lix9+9b/GpE4pJoU9miOYERag44dYciQsNRn+3bYtCksyXz2WZj7+qmnwgRF994bykeMCGNEme2+dOwYaiCJS/fu0LNnmOxowICwXm3WrAkj2S5YEBJXsg6GQw6BM8+Ebt0a/vlI26CagkjMduyARYtCgnj66TD0eNXXLvGA/emn4WC+cWPyiYy6doXBg3cmroED4V//gpKSkAzeT5jnsH37XRNOu3bhPbZsgS5d4KyzwliJBQV1JxrJHmo+Emmlqg7eVU1Va9bA0qWwZAksXhxuV63auf7BB4eDe9UyalSoYSTb7iuvhEFv778/vMeoUSE5TJ4Ma9eG7a5aFRLXqlWhrH37UIvJzQ23HTtChw6h/+WTT0JT2ief7Fz69Amz9A0ZEm4HD959HihpfkoKIllswwZ491044IDkCaA+5eWhSes3vwlzcteUkwP77gu9eoW5Mj79dOeydWtoHsvNDbWOLl1CLaZLF+jUKSSTZctCRz6EmsjAgaHpKi8vTNOReNunT/LOePeQnJYu3ZkUly6F5ctDU9phh0FhYbj93Oea0KHfAJ99Fj6bnJz43yvdlBREpF7uoflp4cLQCb7ffmHp1atpB75t20Kn/eLFO5fly8Mkf+vW7b5+1YF2jz123q+s3LVDv3v3UOs46KCQEOfPD7UdCP0vBQUh0XTtGvpMunXbeb9Dh9CMV7Vs3x5uc3LCnB89e4Z97tkzPG7XLjTHLVwYmv6qln/9K7yuW7cQT48eO2/79w/xVTXx9euXvqa5ioowBW7fvqH21RhKCiLSIlVUhORQWhpuP/ooJIDt28NSdb9du5AAqg6y++6760G2sjLUHF57LSS2kpJQs6g6AWDHjsbHmJu76+nJBxwQThIYNiwkkg0bQm2rvDzc37Ah7M/69Ttf061bOEFg4MCQnGou3brBPvuEmlKfPuFMtY4dw2vLymDu3LC8+GJIgNu3w4UXwq23Nm6flBREpM1yDwf1ioqQIKqafdq127lU1UY+/jj0naxbt3PZuDE0SVUlgj33TO09E/t/qpq93n9/Z99LRUXykwiq9OgRkkXVSQO5uXDEEXDMMXD00WFu9FRiSUanpIpIm2UW+jc6dQq/wOuSn5++96z61T9+fPJ13EOCqqgItYw1a0JN6aOPdt5fvx6GDw+JoKBgZ+2huSgpiIg0k6rrUTp2DP0XBxyQ6Yh21wz99SIi0looKYiISLVYk4KZHW9my8xsuZnNSPJ8RzP7U/T8K2aWH2c8IiJSt9iSgpnlAHcAJwBDgKlmVnNUmfOA9e5+EPBz4Lq44hERkfrFWVM4HFju7u+4+2fA/cCpNdY5Fbg7uv8gMNFMI7GIiGRKnEmhH5AwRBcro7Kk67h7JVAO9Ky5ITObZmYlZlZSVlYWU7giItIqOprdfZa7F7p7Ye/6TjoWEZFGizMpfADsn/C4f1SWdB0z2wPoDiQZGUVERJpDnBevvQZ8zswGEg7+ZwJn1VjnMeBrwEvAFOA5r2fcjXnz5q01sxX1vHcvYG2jom7dtN9tT1vdd+13w+WlslJsScHdK83sAuApIAf4vbsvNrOrCRNIPwb8DrjHzJYDHxMSR33brbf9yMxKUhnjI9tov9uetrrv2u/4xDrMhbs/ATxRo+yKhPtbgdPjjEFERFLXKjqaRUSkeWRrUpiV6QAyRPvd9rTVfdd+x6TVzacgIiLxydaagoiINIKSgoiIVMu6pFDfyKzZwsx+b2ZrzOzNhLK9zexpM3s7ut0rkzHGwcz2N7M5ZrbEzBab2UVReVbvu5nlmtmrZrYw2u8fR+UDoxGGl0cjDnfIdKxxMLMcM3vdzB6PHmf9fptZqZm9YWYLzKwkKov9/zyrkkKKI7Nmiz8Ax9comwE86+6fA56NHmebSuBSdx8CHAmcH/2Ns33fPwWOdfdDgZHA8WZ2JGFk4Z9HIw2vJ4w8nI0uApYmPG4r+z3B3UcmXJsQ+/95ViUFUhuZNSu4+wuEC/4SJY46ezfwn80aVDNw99XuPj+6v4lwoOhHlu+7BxXRw/bR4sCxhBGGIQv3G8DM+gMnAXdGj402sN+1iP3/PNuSQiojs2azPu6+Orr/IdAnk8HELZqUaRTwCm1g36MmlAXAGuBp4N/AhmiEYcje//dbgO8DO6LHPWkb++3A38xsnplNi8pi/z+P9YpmyRx3dzPL2vONzawr8BBwsbtvTJyGI1v33d23AyPNrAfwMDAowyHFzsxOBta4+zwzG5/peJrZ0e7+gZntAzxtZm8lPhnX/3m21RRSGZk1m31kZn0Bots1GY4nFmbWnpAQit39/6LiNrHvAO6+AZgDHAX0iEYYhuz8fx8LfMHMSgnNwccCt5L9+427fxDdriH8CDicZvg/z7akUD0ya3Q2wpmEkVjbiqpRZ4luH81gLLGI2pN/Byx195sTnsrqfTez3lENATPrBEwm9KfMIYwwDFm43+7+P+7e393zCd/n59y9iCzfbzPrYmbdqu4DxwFv0gz/51l3RbOZnUhog6wamXVmhkOKhZndB4wnDKX7EXAl8AjwADAAWAF82d1rdka3amZ2NPAi8AY725gvI/QrZO2+m9kIQsdiDuHH3APufrWZHUD4Bb038Dpwtrt/mrlI4xM1H33P3U/O9v2O9u/h6OEewL3uPtPMehLz/3nWJQUREWm8bGs+EhGRJlBSEBGRakoKIiJSTUlBRESqKSmIiEg1JQWRiJltj0akrFrSNtiYmeUnjmgr0lJpmAuRnba4+8hMByGSSaopiNQjGtf++mhs+1fN7KCoPN/MnjOzRWb2rJkNiMr7mNnD0dwHC81sTLSpHDP7bTQfwt+iK5Mxswuj+SEWmdn9GdpNEUBJQSRRpxrNR2ckPFfu7sOBXxCumAe4Hbjb3UcAxcBtUfltwPPR3AejgcVR+eeAO9x9KLAB+FJUPgMYFW3n23HtnEgqdEWzSMTMKty9a5LyUsIEN+9Eg/F96O49zWwt0Nfdt0Xlq929l5mVAf0Th12Ihvl+OpocBTP7AdDe3X9qZn8FKgjDlDySMG+CSLNTTUEkNV7L/YZIHJtnOzv79E4izBg4GngtYfRPkWanpCCSmjMSbl+K7v+TMHInQBFhoD4I0yROh+qJcbrXtlEzawfs7+5zgB8A3YHdaisizUW/SER26hTNbFblr+5edVrqXma2iPBrf2pU9h3gLjP7b6AMODcqvwiYZWbnEWoE04HVJJcDzI4ShwG3RfMliGSE+hRE6hH1KRS6+9pMxyISNzUfiYhINdUURESkmmoKIiJSTUlBRESqKSmIiEg1JQUREammpCAiItX+H2G76hK71H7RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 2s 2ms/step\n",
      "\n",
      "Results:\n",
      "Train_acc: 0.841\n",
      "Val_acc: 0.885\n",
      "Test_acc: 0.922\n",
      "F1-score: 0.922\n"
     ]
    }
   ],
   "source": [
    "plot_results(history)\n",
    "evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
