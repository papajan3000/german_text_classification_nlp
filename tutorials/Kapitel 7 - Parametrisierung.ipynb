{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 7 - Parametrisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Kapitelübersicht <a class=\"anchor\" id=\"7-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "<b>Abschnittsübersicht</b><br>\n",
    "\n",
    "[7.1. Kapitelübersicht](#7-1)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Parameter in Scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO<br>\n",
    "Bis jetzt hatten wir nur die standard parameter von scikit learn bei unseren klassifizierungsverfahren genutzt. selbst hatten wir keine parameter übergeben. durch gezieltes parameter tuning können klassifizierungsverfahren jedoch noch einmal verbessert werden. in diesem abschnitt werden wir uns zunächst erneut die verfahren naive bayes und log reg angucken und deren parameter in der dokumentation. intuitionen hatten wir schon in den einzelnen Kapiteln besprochen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1. Parameter von Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren wir zunächst ein weiteres Mal das <b>Multinomial Naive Bayes</b> Klassifizierungsverfahren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.read_csv(\"tutorialdata/corpora/wikicorpus_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Mittelwert der cross validation bei der  Klassifizierung  mit Multinomial Naive Bayes ist 0.859.\n",
      "\n",
      "Der F1-score für die Klassifizierung mit Multinomial Naive Bayes ist 0.87.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "labels = LabelEncoder().fit_transform(corpus[\"category\"])\n",
    "vector  = TfidfVectorizer().fit_transform(corpus[\"text\"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "mnb_classifier = MultinomialNB()\n",
    "mnb = mnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# cross validation des Trainingsdatensatzes\n",
    "mnb_scores = cross_val_score(mnb_classifier, vector, labels, cv=3)\n",
    "mnb_mean = np.mean(mnb_scores)\n",
    "\n",
    "print(\"Der Mittelwert der cross validation bei der  Klassifizierung \" \n",
    "      + f\" mit Multinomial Naive Bayes ist {str(np.around(mnb_mean, decimals=3))}.\"\n",
    "      + \"\\n\")\n",
    "\n",
    "\n",
    "# F1-score des Testdatensatzes\n",
    "y_pred = mnb_classifier.predict(X_test)\n",
    "mnb_f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"Der F1-score für die Klassifizierung mit Multinomial Naive Bayes ist \"\n",
    "      + f\"{str(np.around(mnb_f1, decimals=3))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns zunächst die möglichen Parameter von Multinomial Naive Bayes in der <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">Dokumentation</a> an. Es gibt drei Parameter:\n",
    "- `alpha` (default = 1.0)\n",
    "- `fit_prior` (default = True)\n",
    "- `class_prior` (default = None)<br>\n",
    "\n",
    "Wir werden uns nur `alpha` anschauen. Ist `alpha = 1`, wir <b>Laplace Smoothing</b> angewandt (siehe Kapitel 3), d.h. jede Worthäufigkeit wird um 1 erhöht. Ist `alpha < 1`, wird <b>Lidstone Smoothing</b> angewandt, das im Grunde das Gleiche ist. Ist `alpha = 0`, wird gar kein Smoothing angewandt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO hier anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns zunächst die möglichen Parameter von Multinomial Naive Bayes in der <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">Dokumentation</a> an. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "alphas = np.array([0.000001, 0.00001, 0.0001, 0.001, 0.01, \n",
    "                0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "parameters = {'alpha': alphas, \n",
    "              'fit_prior' : [True, False], \n",
    "              'class_prior ' : [None, [.1,.9],[.2, .8]]}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=mnb_classifier, param_grid=dict(alpha=alphas), cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
